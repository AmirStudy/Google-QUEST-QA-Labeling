# Google QUEST Q&A Labeling - Planning
 
## Working cycle:
1. Read competition information and relevant content to feel comfortable with the problem. Create a hypothesis based on the problem.
2. Initial data exploration to feel comfortable with the problem and the data.
3. Build the first implementation (baseline).
4. Loop through [Analyze -> Approach(model) -> Implement -> Evaluate].

## 1. Literature review (read some kernels and relevant content related to the competition).
- ### Relevant content:
  - [Encoder-decoders in Transformers: a hybrid pre-trained architecture for seq2seq](https://medium.com/huggingface/encoder-decoders-in-transformers-a-hybrid-pre-trained-architecture-for-seq2seq-af4d7bf14bb8)
  - [Universal Sentence Encoder - TF Hub](https://tfhub.dev/google/universal-sentence-encoder/4)
  - [Semantic Similarity with TF-Hub Universal Encoder - Colab](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb)
  - [Multilingual Universal Sentence Encoder for Semantic Retrieval](https://ai.googleblog.com/2019/07/multilingual-universal-sentence-encoder.html)
  - [Universal Sentence Encoder - Paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf)
  - [BERT - Input](https://huggingface.co/transformers/model_doc/bert.html#bertmodel)

- ### Kernels:
 
- ### Insights:
 - #### Positive Insights
 - #### Negative Insights
