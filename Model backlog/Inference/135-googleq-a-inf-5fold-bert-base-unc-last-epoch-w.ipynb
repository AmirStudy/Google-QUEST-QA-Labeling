{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import warnings\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D, SpatialDropout1D, Concatenate\n",
    "from googleqa_utilityscript import *\n",
    "from googleqa_map_utilityscript import *\n",
    "import bert_tokenization as tokenization\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to predict:\n",
      "/kaggle/input/135bert-base-last/135-BERT_base_uncased_model_fold_1_last_epoch.h5\n",
      "/kaggle/input/135bert-base-last/135-BERT_base_uncased_model_fold_2_last_epoch.h5\n",
      "/kaggle/input/135bert-base-last/135-BERT_base_uncased_model_fold_3_last_epoch.h5\n",
      "/kaggle/input/135bert-base-last/135-BERT_base_uncased_model_fold_4_last_epoch.h5\n",
      "/kaggle/input/135bert-base-last/135-BERT_base_uncased_model_fold_5_last_epoch.h5\n",
      "Test samples: 476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BERT_PATH = '/kaggle/input/tf-hub-bert-base/bert_base_uncased'\n",
    "VOCAB_PATH = BERT_PATH + '/assets/vocab.txt'\n",
    "model_path_list = glob.glob('/kaggle/input/135bert-base-last/' + '*.h5')\n",
    "model_path_list.sort()\n",
    "print('Models to predict:')\n",
    "print(*model_path_list, sep = \"\\n\")\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "question_target_cols = ['question_asker_intent_understanding','question_body_critical', 'question_conversational', \n",
    "                        'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                        'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', \n",
    "                        'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                        'question_type_compare', 'question_type_consequence', 'question_type_definition', \n",
    "                        'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                        'question_type_reason_explanation', 'question_type_spelling', 'question_well_written']\n",
    "answer_target_cols = ['answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                      'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', \n",
    "                      'answer_type_reason_explanation', 'answer_well_written']\n",
    "target_cols = question_target_cols + answer_target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['question_title', 'question_body', 'answer']\n",
    "\n",
    "# for feature in text_features:\n",
    "#     # Lower\n",
    "#     test[feature] = test[feature].apply(lambda x: x.lower())\n",
    "#     # Map misspellings\n",
    "#     test[feature] = test[feature].apply(lambda x: map_misspellings(x))\n",
    "#     # Map contractions\n",
    "#     test[feature] = test[feature].apply(lambda x: map_contraction(x))\n",
    "#     # Trim text\n",
    "#     test[feature] = test[feature].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "N_CLASS = len(target_cols)\n",
    "MAX_SEQUENCE_LENGTH = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(VOCAB_PATH, do_lower_case=True)\n",
    "\n",
    "# Test features\n",
    "X_test = compute_input_arays(test, text_features, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    input_word_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    segment_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids')\n",
    "\n",
    "    bert_layer = KerasLayer(BERT_PATH, trainable=False)\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_masks, segment_ids])\n",
    "\n",
    "    x = GlobalAveragePooling1D()(sequence_output)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(N_CLASS, activation=\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "    model = Model(inputs=[input_word_ids, input_masks, segment_ids], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.zeros((len(test), N_CLASS))\n",
    "weights = [.3, .2, .1, .1, .3]\n",
    "\n",
    "for index, model_path in enumerate(model_path_list):\n",
    "    model = model_fn()\n",
    "    model.load_weights(model_path)\n",
    "    Y_test += model.predict(X_test) * weights[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.895536</td>\n",
       "      <td>0.555735</td>\n",
       "      <td>0.322475</td>\n",
       "      <td>0.380108</td>\n",
       "      <td>0.635984</td>\n",
       "      <td>0.471719</td>\n",
       "      <td>0.656469</td>\n",
       "      <td>0.625424</td>\n",
       "      <td>0.721950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894331</td>\n",
       "      <td>0.857040</td>\n",
       "      <td>0.519965</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>0.919175</td>\n",
       "      <td>0.733459</td>\n",
       "      <td>0.074201</td>\n",
       "      <td>0.059778</td>\n",
       "      <td>0.763274</td>\n",
       "      <td>0.877482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.566569</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.840240</td>\n",
       "      <td>0.820373</td>\n",
       "      <td>0.957518</td>\n",
       "      <td>0.596275</td>\n",
       "      <td>0.506407</td>\n",
       "      <td>0.033690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732552</td>\n",
       "      <td>0.957699</td>\n",
       "      <td>0.669121</td>\n",
       "      <td>0.975998</td>\n",
       "      <td>0.984432</td>\n",
       "      <td>0.880605</td>\n",
       "      <td>0.926036</td>\n",
       "      <td>0.070481</td>\n",
       "      <td>0.045227</td>\n",
       "      <td>0.894294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.918739</td>\n",
       "      <td>0.661961</td>\n",
       "      <td>0.018679</td>\n",
       "      <td>0.756351</td>\n",
       "      <td>0.925140</td>\n",
       "      <td>0.957413</td>\n",
       "      <td>0.585662</td>\n",
       "      <td>0.522341</td>\n",
       "      <td>0.227406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853483</td>\n",
       "      <td>0.940579</td>\n",
       "      <td>0.607729</td>\n",
       "      <td>0.973370</td>\n",
       "      <td>0.972470</td>\n",
       "      <td>0.849647</td>\n",
       "      <td>0.110504</td>\n",
       "      <td>0.094520</td>\n",
       "      <td>0.878850</td>\n",
       "      <td>0.898942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.898074</td>\n",
       "      <td>0.423668</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>0.712666</td>\n",
       "      <td>0.820665</td>\n",
       "      <td>0.911964</td>\n",
       "      <td>0.516980</td>\n",
       "      <td>0.424555</td>\n",
       "      <td>0.088527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753760</td>\n",
       "      <td>0.945499</td>\n",
       "      <td>0.665480</td>\n",
       "      <td>0.975789</td>\n",
       "      <td>0.982685</td>\n",
       "      <td>0.895975</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.196019</td>\n",
       "      <td>0.406849</td>\n",
       "      <td>0.899190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.903802</td>\n",
       "      <td>0.390666</td>\n",
       "      <td>0.039749</td>\n",
       "      <td>0.817033</td>\n",
       "      <td>0.778240</td>\n",
       "      <td>0.858819</td>\n",
       "      <td>0.631552</td>\n",
       "      <td>0.608585</td>\n",
       "      <td>0.093188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698909</td>\n",
       "      <td>0.902946</td>\n",
       "      <td>0.615498</td>\n",
       "      <td>0.951958</td>\n",
       "      <td>0.943384</td>\n",
       "      <td>0.798314</td>\n",
       "      <td>0.175539</td>\n",
       "      <td>0.125746</td>\n",
       "      <td>0.537280</td>\n",
       "      <td>0.885585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.895536                0.555735   \n",
       "1     46                             0.901822                0.566569   \n",
       "2     70                             0.918739                0.661961   \n",
       "3    132                             0.898074                0.423668   \n",
       "4    200                             0.903802                0.390666   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.322475                      0.380108   \n",
       "1                 0.003445                      0.840240   \n",
       "2                 0.018679                      0.756351   \n",
       "3                 0.004068                      0.712666   \n",
       "4                 0.039749                      0.817033   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.635984                               0.471719   \n",
       "1               0.820373                               0.957518   \n",
       "2               0.925140                               0.957413   \n",
       "3               0.820665                               0.911964   \n",
       "4               0.778240                               0.858819   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.656469                       0.625424   \n",
       "1                         0.596275                       0.506407   \n",
       "2                         0.585662                       0.522341   \n",
       "3                         0.516980                       0.424555   \n",
       "4                         0.631552                       0.608585   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.721950  ...               0.894331        0.857040   \n",
       "1               0.033690  ...               0.732552        0.957699   \n",
       "2               0.227406  ...               0.853483        0.940579   \n",
       "3               0.088527  ...               0.753760        0.945499   \n",
       "4               0.093188  ...               0.698909        0.902946   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.519965          0.932292          0.919175   \n",
       "1                     0.669121          0.975998          0.984432   \n",
       "2                     0.607729          0.973370          0.972470   \n",
       "3                     0.665480          0.975789          0.982685   \n",
       "4                     0.615498          0.951958          0.943384   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.733459                  0.074201               0.059778   \n",
       "1             0.880605                  0.926036               0.070481   \n",
       "2             0.849647                  0.110504               0.094520   \n",
       "3             0.895975                  0.854000               0.196019   \n",
       "4             0.798314                  0.175539               0.125746   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.763274             0.877482  \n",
       "1                        0.045227             0.894294  \n",
       "2                        0.878850             0.898942  \n",
       "3                        0.406849             0.899190  \n",
       "4                        0.537280             0.885585  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5029.186975</td>\n",
       "      <td>0.891994</td>\n",
       "      <td>0.589385</td>\n",
       "      <td>0.039110</td>\n",
       "      <td>0.701933</td>\n",
       "      <td>0.835598</td>\n",
       "      <td>0.845021</td>\n",
       "      <td>0.578338</td>\n",
       "      <td>0.500195</td>\n",
       "      <td>0.232175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822656</td>\n",
       "      <td>0.924092</td>\n",
       "      <td>0.651918</td>\n",
       "      <td>0.961975</td>\n",
       "      <td>0.965686</td>\n",
       "      <td>0.852940</td>\n",
       "      <td>0.505005</td>\n",
       "      <td>0.143444</td>\n",
       "      <td>0.489232</td>\n",
       "      <td>0.900773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2812.670060</td>\n",
       "      <td>0.046781</td>\n",
       "      <td>0.129700</td>\n",
       "      <td>0.077553</td>\n",
       "      <td>0.123516</td>\n",
       "      <td>0.101595</td>\n",
       "      <td>0.138607</td>\n",
       "      <td>0.053288</td>\n",
       "      <td>0.091335</td>\n",
       "      <td>0.197455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076730</td>\n",
       "      <td>0.031847</td>\n",
       "      <td>0.047906</td>\n",
       "      <td>0.014756</td>\n",
       "      <td>0.017109</td>\n",
       "      <td>0.047625</td>\n",
       "      <td>0.325125</td>\n",
       "      <td>0.076047</td>\n",
       "      <td>0.283907</td>\n",
       "      <td>0.023034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.753068</td>\n",
       "      <td>0.351450</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.201682</td>\n",
       "      <td>0.372178</td>\n",
       "      <td>0.184568</td>\n",
       "      <td>0.446370</td>\n",
       "      <td>0.338075</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572062</td>\n",
       "      <td>0.807332</td>\n",
       "      <td>0.519965</td>\n",
       "      <td>0.908791</td>\n",
       "      <td>0.873343</td>\n",
       "      <td>0.703558</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>0.802288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2572.000000</td>\n",
       "      <td>0.859300</td>\n",
       "      <td>0.473100</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.629407</td>\n",
       "      <td>0.789672</td>\n",
       "      <td>0.813827</td>\n",
       "      <td>0.539730</td>\n",
       "      <td>0.432949</td>\n",
       "      <td>0.075290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762441</td>\n",
       "      <td>0.906778</td>\n",
       "      <td>0.618854</td>\n",
       "      <td>0.952332</td>\n",
       "      <td>0.956982</td>\n",
       "      <td>0.825065</td>\n",
       "      <td>0.161955</td>\n",
       "      <td>0.090070</td>\n",
       "      <td>0.242369</td>\n",
       "      <td>0.886035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5093.000000</td>\n",
       "      <td>0.892093</td>\n",
       "      <td>0.584871</td>\n",
       "      <td>0.010805</td>\n",
       "      <td>0.701824</td>\n",
       "      <td>0.849253</td>\n",
       "      <td>0.897441</td>\n",
       "      <td>0.570311</td>\n",
       "      <td>0.478114</td>\n",
       "      <td>0.161380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824134</td>\n",
       "      <td>0.930322</td>\n",
       "      <td>0.652570</td>\n",
       "      <td>0.964221</td>\n",
       "      <td>0.969579</td>\n",
       "      <td>0.858558</td>\n",
       "      <td>0.563220</td>\n",
       "      <td>0.139412</td>\n",
       "      <td>0.466014</td>\n",
       "      <td>0.902515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7482.000000</td>\n",
       "      <td>0.928578</td>\n",
       "      <td>0.685630</td>\n",
       "      <td>0.028497</td>\n",
       "      <td>0.785195</td>\n",
       "      <td>0.908950</td>\n",
       "      <td>0.932091</td>\n",
       "      <td>0.612673</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.350386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888580</td>\n",
       "      <td>0.947306</td>\n",
       "      <td>0.683774</td>\n",
       "      <td>0.972454</td>\n",
       "      <td>0.977805</td>\n",
       "      <td>0.886692</td>\n",
       "      <td>0.807932</td>\n",
       "      <td>0.192743</td>\n",
       "      <td>0.733659</td>\n",
       "      <td>0.916019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9640.000000</td>\n",
       "      <td>0.984840</td>\n",
       "      <td>0.927453</td>\n",
       "      <td>0.589520</td>\n",
       "      <td>0.979659</td>\n",
       "      <td>0.986447</td>\n",
       "      <td>0.982007</td>\n",
       "      <td>0.733354</td>\n",
       "      <td>0.798037</td>\n",
       "      <td>0.871310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967778</td>\n",
       "      <td>0.986830</td>\n",
       "      <td>0.824299</td>\n",
       "      <td>0.991248</td>\n",
       "      <td>0.993644</td>\n",
       "      <td>0.973432</td>\n",
       "      <td>0.969983</td>\n",
       "      <td>0.389829</td>\n",
       "      <td>0.992685</td>\n",
       "      <td>0.956264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qa_id  question_asker_intent_understanding  \\\n",
       "count   476.000000                           476.000000   \n",
       "mean   5029.186975                             0.891994   \n",
       "std    2812.670060                             0.046781   \n",
       "min      39.000000                             0.753068   \n",
       "25%    2572.000000                             0.859300   \n",
       "50%    5093.000000                             0.892093   \n",
       "75%    7482.000000                             0.928578   \n",
       "max    9640.000000                             0.984840   \n",
       "\n",
       "       question_body_critical  question_conversational  \\\n",
       "count              476.000000               476.000000   \n",
       "mean                 0.589385                 0.039110   \n",
       "std                  0.129700                 0.077553   \n",
       "min                  0.351450                 0.001195   \n",
       "25%                  0.473100                 0.006324   \n",
       "50%                  0.584871                 0.010805   \n",
       "75%                  0.685630                 0.028497   \n",
       "max                  0.927453                 0.589520   \n",
       "\n",
       "       question_expect_short_answer  question_fact_seeking  \\\n",
       "count                    476.000000             476.000000   \n",
       "mean                       0.701933               0.835598   \n",
       "std                        0.123516               0.101595   \n",
       "min                        0.201682               0.372178   \n",
       "25%                        0.629407               0.789672   \n",
       "50%                        0.701824               0.849253   \n",
       "75%                        0.785195               0.908950   \n",
       "max                        0.979659               0.986447   \n",
       "\n",
       "       question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "count                             476.000000                       476.000000   \n",
       "mean                                0.845021                         0.578338   \n",
       "std                                 0.138607                         0.053288   \n",
       "min                                 0.184568                         0.446370   \n",
       "25%                                 0.813827                         0.539730   \n",
       "50%                                 0.897441                         0.570311   \n",
       "75%                                 0.932091                         0.612673   \n",
       "max                                 0.982007                         0.733354   \n",
       "\n",
       "       question_interestingness_self  question_multi_intent  ...  \\\n",
       "count                     476.000000             476.000000  ...   \n",
       "mean                        0.500195               0.232175  ...   \n",
       "std                         0.091335               0.197455  ...   \n",
       "min                         0.338075               0.001847  ...   \n",
       "25%                         0.432949               0.075290  ...   \n",
       "50%                         0.478114               0.161380  ...   \n",
       "75%                         0.545454               0.350386  ...   \n",
       "max                         0.798037               0.871310  ...   \n",
       "\n",
       "       question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "count             476.000000      476.000000                   476.000000   \n",
       "mean                0.822656        0.924092                     0.651918   \n",
       "std                 0.076730        0.031847                     0.047906   \n",
       "min                 0.572062        0.807332                     0.519965   \n",
       "25%                 0.762441        0.906778                     0.618854   \n",
       "50%                 0.824134        0.930322                     0.652570   \n",
       "75%                 0.888580        0.947306                     0.683774   \n",
       "max                 0.967778        0.986830                     0.824299   \n",
       "\n",
       "       answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "count        476.000000        476.000000           476.000000   \n",
       "mean           0.961975          0.965686             0.852940   \n",
       "std            0.014756          0.017109             0.047625   \n",
       "min            0.908791          0.873343             0.703558   \n",
       "25%            0.952332          0.956982             0.825065   \n",
       "50%            0.964221          0.969579             0.858558   \n",
       "75%            0.972454          0.977805             0.886692   \n",
       "max            0.991248          0.993644             0.973432   \n",
       "\n",
       "       answer_type_instructions  answer_type_procedure  \\\n",
       "count                476.000000             476.000000   \n",
       "mean                   0.505005               0.143444   \n",
       "std                    0.325125               0.076047   \n",
       "min                    0.003000               0.003318   \n",
       "25%                    0.161955               0.090070   \n",
       "50%                    0.563220               0.139412   \n",
       "75%                    0.807932               0.192743   \n",
       "max                    0.969983               0.389829   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                      476.000000           476.000000  \n",
       "mean                         0.489232             0.900773  \n",
       "std                          0.283907             0.023034  \n",
       "min                          0.018122             0.802288  \n",
       "25%                          0.242369             0.886035  \n",
       "50%                          0.466014             0.902515  \n",
       "75%                          0.733659             0.916019  \n",
       "max                          0.992685             0.956264  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "submission[target_cols] = Y_test\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "display(submission.head())\n",
    "display(submission.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
