{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import warnings\n",
    "from joblib import load\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import Model, optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Dropout, Concatenate, BatchNormalization, Activation, Average, Add, Reshape\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Embedding, LSTM, Conv1D, SpatialDropout1D, Bidirectional, Flatten\n",
    "from googleqa_utilityscript import *\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "module_url = '/kaggle/input/universalsentenceencodermodels/universal-sentence-encoder-models/use'\n",
    "encoder_path = '/kaggle/input/pickled-glove840b300d-for-10sec-loading/glove.840B.300d.pkl'\n",
    "model_path = '/kaggle/input/76-googleq-a-train-glove-2lstm-avg/model.h5'\n",
    "tokenizer_path = '/kaggle/input/76-googleq-a-train-glove-2lstm-avg/tokenizer.joblib'\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "question_target_cols = ['question_asker_intent_understanding','question_body_critical', 'question_conversational', \n",
    "                        'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                        'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', \n",
    "                        'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                        'question_type_compare', 'question_type_consequence', 'question_type_definition', \n",
    "                        'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                        'question_type_reason_explanation', 'question_type_spelling', 'question_well_written']\n",
    "answer_target_cols = ['answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                      'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', \n",
    "                      'answer_type_reason_explanation', 'answer_well_written']\n",
    "target_cols = question_target_cols + answer_target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['question_title', 'question_body', 'answer']\n",
    "    \n",
    "for feature in text_features:\n",
    "    # Map contractions\n",
    "    test[feature] = test[feature].apply(lambda x: map_contraction(x))\n",
    "    # Trim text\n",
    "    test[feature] = test[feature].apply(lambda x: x.strip())\n",
    "\n",
    "for feature in text_features:\n",
    "    test[feature + '_uncased'] = test[feature]\n",
    "\n",
    "for feature in text_features:\n",
    "    # Lower\n",
    "    test[feature] = test[feature].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "EMBEDDDING_SIZE = 512\n",
    "N_CLASS = len(target_cols)\n",
    "MAX_FEATURES = 20000\n",
    "TITLE_MAX_LEN = 30\n",
    "BODY_MAX_LEN = 200\n",
    "ANSWER_MAX_LEN = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load(tokenizer_path)\n",
    "\n",
    "# Test features\n",
    "# X_test_title = test['question_title']\n",
    "# X_test_body = test['question_body']\n",
    "# X_test_answer = test['answer']\n",
    "X_test_title_seq = test['question_title_uncased']\n",
    "X_test_body_seq = test['question_body_uncased']\n",
    "X_test_answer_seq = test['answer_uncased']\n",
    "\n",
    "# Tokenize the sentences\n",
    "X_test_title_seq = tokenizer.texts_to_sequences(X_test_title_seq)\n",
    "X_test_body_seq = tokenizer.texts_to_sequences(X_test_body_seq)\n",
    "X_test_answer_seq = tokenizer.texts_to_sequences(X_test_answer_seq)\n",
    "\n",
    "# Pad the sentences\n",
    "X_test_title_seq = pad_sequences(X_test_title_seq, maxlen=TITLE_MAX_LEN)\n",
    "X_test_body_seq = pad_sequences(X_test_body_seq, maxlen=BODY_MAX_LEN)\n",
    "X_test_answer_seq = pad_sequences(X_test_answer_seq, maxlen=ANSWER_MAX_LEN)\n",
    "\n",
    "X_test = [X_test_title_seq, X_test_body_seq, X_test_answer_seq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "use_embed = hub.load(module_url)\n",
    "\n",
    "def USEEmbedding(x):\n",
    "    return use_embed(tf.squeeze(tf.cast(x, tf.string)))\n",
    "\n",
    "def encoder_block(input_layer):\n",
    "    encoder = Lambda(USEEmbedding, output_shape=(EMBEDDDING_SIZE,))(input_layer)\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n unknown words (GloVe):  3306\n"
     ]
    }
   ],
   "source": [
    "glove_embedding_matrix, glove_unknown_words = build_matrix(tokenizer.word_index, encoder_path, MAX_FEATURES)\n",
    "print('n unknown words (GloVe): ', len(glove_unknown_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_title_seq (InputLayer)    [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_body_seq (InputLayer)     [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_answer_seq (InputLayer)   [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 300)      17424600    input_title_seq[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 300)     17424600    input_body_seq[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 200, 300)     17424600    input_answer_seq[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 30, 128)      219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 200, 128)     219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 200, 128)     219648      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 30, 64)       49408       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 200, 64)      49408       lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 200, 64)      49408       lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 64)           0           lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 192)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 192)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          98816       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 30)           15390       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 53,195,174\n",
      "Trainable params: 921,374\n",
      "Non-trainable params: 52,273,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Title sequence\n",
    "input_title_seq = Input(shape=(TITLE_MAX_LEN,), dtype=tf.float32, name='input_title_seq')\n",
    "title = Embedding(*glove_embedding_matrix.shape, weights=[glove_embedding_matrix], trainable=False)(input_title_seq)\n",
    "title = LSTM(128, kernel_initializer='lecun_normal', recurrent_dropout=0.5, return_sequences=True)(title)\n",
    "title = LSTM(64, kernel_initializer='lecun_normal', recurrent_dropout=0.5, return_sequences=True)(title)\n",
    "title_out = GlobalAveragePooling1D()(title)\n",
    "\n",
    "# Body sequence\n",
    "input_body_seq = Input(shape=(BODY_MAX_LEN,), dtype=tf.float32, name='input_body_seq')\n",
    "body = Embedding(*glove_embedding_matrix.shape, weights=[glove_embedding_matrix], trainable=False)(input_body_seq)\n",
    "body = LSTM(128, kernel_initializer='lecun_normal', recurrent_dropout=0.5, return_sequences=True)(body)\n",
    "body = LSTM(64, kernel_initializer='lecun_normal', recurrent_dropout=0.5, return_sequences=True)(body)\n",
    "body_out = GlobalAveragePooling1D()(body)\n",
    "\n",
    "# Answer sequence\n",
    "input_answer_seq = Input(shape=(ANSWER_MAX_LEN,), dtype=tf.float32, name='input_answer_seq')\n",
    "answer = Embedding(*glove_embedding_matrix.shape, weights=[glove_embedding_matrix], trainable=False)(input_answer_seq)\n",
    "answer = LSTM(128, kernel_initializer='lecun_normal', recurrent_dropout=0.5, return_sequences=True)(answer)\n",
    "answer = LSTM(64, kernel_initializer='lecun_normal', recurrent_dropout=0.5, return_sequences=True)(answer)\n",
    "answer_out = GlobalAveragePooling1D()(answer)\n",
    "\n",
    "\n",
    "# Output\n",
    "x = Concatenate()([title_out, body_out, answer_out])\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu', kernel_initializer='lecun_normal')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(N_CLASS, activation='sigmoid', kernel_initializer='lecun_normal', name='output')(x)\n",
    "model = Model(inputs=[input_title_seq, input_body_seq, input_answer_seq], outputs=[output])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.845900</td>\n",
       "      <td>0.522226</td>\n",
       "      <td>0.225039</td>\n",
       "      <td>0.494419</td>\n",
       "      <td>0.636590</td>\n",
       "      <td>0.583505</td>\n",
       "      <td>0.605955</td>\n",
       "      <td>0.559891</td>\n",
       "      <td>0.480402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.827262</td>\n",
       "      <td>0.836274</td>\n",
       "      <td>0.588894</td>\n",
       "      <td>0.910318</td>\n",
       "      <td>0.923164</td>\n",
       "      <td>0.734918</td>\n",
       "      <td>0.126437</td>\n",
       "      <td>0.094631</td>\n",
       "      <td>0.769347</td>\n",
       "      <td>0.879171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.853400</td>\n",
       "      <td>0.516930</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>0.696933</td>\n",
       "      <td>0.747516</td>\n",
       "      <td>0.859460</td>\n",
       "      <td>0.546341</td>\n",
       "      <td>0.451765</td>\n",
       "      <td>0.171406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713173</td>\n",
       "      <td>0.903863</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.947735</td>\n",
       "      <td>0.954348</td>\n",
       "      <td>0.809716</td>\n",
       "      <td>0.839808</td>\n",
       "      <td>0.188719</td>\n",
       "      <td>0.171151</td>\n",
       "      <td>0.863371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.873925</td>\n",
       "      <td>0.656031</td>\n",
       "      <td>0.055601</td>\n",
       "      <td>0.708412</td>\n",
       "      <td>0.864876</td>\n",
       "      <td>0.865246</td>\n",
       "      <td>0.595965</td>\n",
       "      <td>0.540998</td>\n",
       "      <td>0.415727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864087</td>\n",
       "      <td>0.873809</td>\n",
       "      <td>0.599273</td>\n",
       "      <td>0.932557</td>\n",
       "      <td>0.936535</td>\n",
       "      <td>0.797698</td>\n",
       "      <td>0.111274</td>\n",
       "      <td>0.085681</td>\n",
       "      <td>0.752444</td>\n",
       "      <td>0.877198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.852251</td>\n",
       "      <td>0.456007</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.761315</td>\n",
       "      <td>0.770422</td>\n",
       "      <td>0.928229</td>\n",
       "      <td>0.537299</td>\n",
       "      <td>0.422107</td>\n",
       "      <td>0.168413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708583</td>\n",
       "      <td>0.953921</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.975064</td>\n",
       "      <td>0.987513</td>\n",
       "      <td>0.890655</td>\n",
       "      <td>0.845066</td>\n",
       "      <td>0.178833</td>\n",
       "      <td>0.645454</td>\n",
       "      <td>0.909874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.846349</td>\n",
       "      <td>0.499356</td>\n",
       "      <td>0.028656</td>\n",
       "      <td>0.673217</td>\n",
       "      <td>0.811848</td>\n",
       "      <td>0.832910</td>\n",
       "      <td>0.573394</td>\n",
       "      <td>0.491101</td>\n",
       "      <td>0.316007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740371</td>\n",
       "      <td>0.881707</td>\n",
       "      <td>0.613124</td>\n",
       "      <td>0.939128</td>\n",
       "      <td>0.942893</td>\n",
       "      <td>0.789696</td>\n",
       "      <td>0.479620</td>\n",
       "      <td>0.174569</td>\n",
       "      <td>0.511875</td>\n",
       "      <td>0.882739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.845900                0.522226   \n",
       "1     46                             0.853400                0.516930   \n",
       "2     70                             0.873925                0.656031   \n",
       "3    132                             0.852251                0.456007   \n",
       "4    200                             0.846349                0.499356   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.225039                      0.494419   \n",
       "1                 0.008348                      0.696933   \n",
       "2                 0.055601                      0.708412   \n",
       "3                 0.003020                      0.761315   \n",
       "4                 0.028656                      0.673217   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.636590                               0.583505   \n",
       "1               0.747516                               0.859460   \n",
       "2               0.864876                               0.865246   \n",
       "3               0.770422                               0.928229   \n",
       "4               0.811848                               0.832910   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.605955                       0.559891   \n",
       "1                         0.546341                       0.451765   \n",
       "2                         0.595965                       0.540998   \n",
       "3                         0.537299                       0.422107   \n",
       "4                         0.573394                       0.491101   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.480402  ...               0.827262        0.836274   \n",
       "1               0.171406  ...               0.713173        0.903863   \n",
       "2               0.415727  ...               0.864087        0.873809   \n",
       "3               0.168413  ...               0.708583        0.953921   \n",
       "4               0.316007  ...               0.740371        0.881707   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.588894          0.910318          0.923164   \n",
       "1                     0.611431          0.947735          0.954348   \n",
       "2                     0.599273          0.932557          0.936535   \n",
       "3                     0.681900          0.975064          0.987513   \n",
       "4                     0.613124          0.939128          0.942893   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.734918                  0.126437               0.094631   \n",
       "1             0.809716                  0.839808               0.188719   \n",
       "2             0.797698                  0.111274               0.085681   \n",
       "3             0.890655                  0.845066               0.178833   \n",
       "4             0.789696                  0.479620               0.174569   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.769347             0.879171  \n",
       "1                        0.171151             0.863371  \n",
       "2                        0.752444             0.877198  \n",
       "3                        0.645454             0.909874  \n",
       "4                        0.511875             0.882739  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5029.186975</td>\n",
       "      <td>0.864611</td>\n",
       "      <td>0.565332</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>0.676801</td>\n",
       "      <td>0.766866</td>\n",
       "      <td>0.809119</td>\n",
       "      <td>0.572139</td>\n",
       "      <td>0.491588</td>\n",
       "      <td>0.258165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768375</td>\n",
       "      <td>0.913713</td>\n",
       "      <td>0.641420</td>\n",
       "      <td>0.951237</td>\n",
       "      <td>0.961477</td>\n",
       "      <td>0.836702</td>\n",
       "      <td>0.545300</td>\n",
       "      <td>0.158831</td>\n",
       "      <td>0.490611</td>\n",
       "      <td>0.888082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2812.670060</td>\n",
       "      <td>0.049093</td>\n",
       "      <td>0.120906</td>\n",
       "      <td>0.095245</td>\n",
       "      <td>0.113026</td>\n",
       "      <td>0.117225</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>0.041359</td>\n",
       "      <td>0.068901</td>\n",
       "      <td>0.127297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086540</td>\n",
       "      <td>0.029476</td>\n",
       "      <td>0.033548</td>\n",
       "      <td>0.019491</td>\n",
       "      <td>0.019275</td>\n",
       "      <td>0.041231</td>\n",
       "      <td>0.303033</td>\n",
       "      <td>0.070943</td>\n",
       "      <td>0.248872</td>\n",
       "      <td>0.026474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.655451</td>\n",
       "      <td>0.360006</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.164630</td>\n",
       "      <td>0.143845</td>\n",
       "      <td>0.050873</td>\n",
       "      <td>0.488049</td>\n",
       "      <td>0.382756</td>\n",
       "      <td>0.041413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578293</td>\n",
       "      <td>0.780902</td>\n",
       "      <td>0.559364</td>\n",
       "      <td>0.803577</td>\n",
       "      <td>0.852746</td>\n",
       "      <td>0.693902</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.057444</td>\n",
       "      <td>0.756371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2572.000000</td>\n",
       "      <td>0.831753</td>\n",
       "      <td>0.460665</td>\n",
       "      <td>0.006093</td>\n",
       "      <td>0.613143</td>\n",
       "      <td>0.716206</td>\n",
       "      <td>0.778352</td>\n",
       "      <td>0.540687</td>\n",
       "      <td>0.440366</td>\n",
       "      <td>0.155095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699728</td>\n",
       "      <td>0.896717</td>\n",
       "      <td>0.616423</td>\n",
       "      <td>0.942102</td>\n",
       "      <td>0.952453</td>\n",
       "      <td>0.811034</td>\n",
       "      <td>0.273502</td>\n",
       "      <td>0.108313</td>\n",
       "      <td>0.281766</td>\n",
       "      <td>0.872330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5093.000000</td>\n",
       "      <td>0.866378</td>\n",
       "      <td>0.546013</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>0.692805</td>\n",
       "      <td>0.783960</td>\n",
       "      <td>0.867760</td>\n",
       "      <td>0.567296</td>\n",
       "      <td>0.472887</td>\n",
       "      <td>0.240639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.766624</td>\n",
       "      <td>0.916276</td>\n",
       "      <td>0.636875</td>\n",
       "      <td>0.953585</td>\n",
       "      <td>0.963857</td>\n",
       "      <td>0.839102</td>\n",
       "      <td>0.642882</td>\n",
       "      <td>0.159481</td>\n",
       "      <td>0.467388</td>\n",
       "      <td>0.889005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7482.000000</td>\n",
       "      <td>0.901438</td>\n",
       "      <td>0.662942</td>\n",
       "      <td>0.048130</td>\n",
       "      <td>0.753945</td>\n",
       "      <td>0.834027</td>\n",
       "      <td>0.903941</td>\n",
       "      <td>0.596546</td>\n",
       "      <td>0.532815</td>\n",
       "      <td>0.337481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841340</td>\n",
       "      <td>0.933852</td>\n",
       "      <td>0.663419</td>\n",
       "      <td>0.963455</td>\n",
       "      <td>0.974451</td>\n",
       "      <td>0.865883</td>\n",
       "      <td>0.809053</td>\n",
       "      <td>0.208605</td>\n",
       "      <td>0.687132</td>\n",
       "      <td>0.905722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9640.000000</td>\n",
       "      <td>0.980189</td>\n",
       "      <td>0.891875</td>\n",
       "      <td>0.769598</td>\n",
       "      <td>0.901308</td>\n",
       "      <td>0.985876</td>\n",
       "      <td>0.972625</td>\n",
       "      <td>0.723131</td>\n",
       "      <td>0.763452</td>\n",
       "      <td>0.635349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969062</td>\n",
       "      <td>0.978080</td>\n",
       "      <td>0.740559</td>\n",
       "      <td>0.988534</td>\n",
       "      <td>0.993799</td>\n",
       "      <td>0.938850</td>\n",
       "      <td>0.978087</td>\n",
       "      <td>0.369058</td>\n",
       "      <td>0.983564</td>\n",
       "      <td>0.970600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qa_id  question_asker_intent_understanding  \\\n",
       "count   476.000000                           476.000000   \n",
       "mean   5029.186975                             0.864611   \n",
       "std    2812.670060                             0.049093   \n",
       "min      39.000000                             0.655451   \n",
       "25%    2572.000000                             0.831753   \n",
       "50%    5093.000000                             0.866378   \n",
       "75%    7482.000000                             0.901438   \n",
       "max    9640.000000                             0.980189   \n",
       "\n",
       "       question_body_critical  question_conversational  \\\n",
       "count              476.000000               476.000000   \n",
       "mean                 0.565332                 0.050795   \n",
       "std                  0.120906                 0.095245   \n",
       "min                  0.360006                 0.000409   \n",
       "25%                  0.460665                 0.006093   \n",
       "50%                  0.546013                 0.015237   \n",
       "75%                  0.662942                 0.048130   \n",
       "max                  0.891875                 0.769598   \n",
       "\n",
       "       question_expect_short_answer  question_fact_seeking  \\\n",
       "count                    476.000000             476.000000   \n",
       "mean                       0.676801               0.766866   \n",
       "std                        0.113026               0.117225   \n",
       "min                        0.164630               0.143845   \n",
       "25%                        0.613143               0.716206   \n",
       "50%                        0.692805               0.783960   \n",
       "75%                        0.753945               0.834027   \n",
       "max                        0.901308               0.985876   \n",
       "\n",
       "       question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "count                             476.000000                       476.000000   \n",
       "mean                                0.809119                         0.572139   \n",
       "std                                 0.156064                         0.041359   \n",
       "min                                 0.050873                         0.488049   \n",
       "25%                                 0.778352                         0.540687   \n",
       "50%                                 0.867760                         0.567296   \n",
       "75%                                 0.903941                         0.596546   \n",
       "max                                 0.972625                         0.723131   \n",
       "\n",
       "       question_interestingness_self  question_multi_intent  ...  \\\n",
       "count                     476.000000             476.000000  ...   \n",
       "mean                        0.491588               0.258165  ...   \n",
       "std                         0.068901               0.127297  ...   \n",
       "min                         0.382756               0.041413  ...   \n",
       "25%                         0.440366               0.155095  ...   \n",
       "50%                         0.472887               0.240639  ...   \n",
       "75%                         0.532815               0.337481  ...   \n",
       "max                         0.763452               0.635349  ...   \n",
       "\n",
       "       question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "count             476.000000      476.000000                   476.000000   \n",
       "mean                0.768375        0.913713                     0.641420   \n",
       "std                 0.086540        0.029476                     0.033548   \n",
       "min                 0.578293        0.780902                     0.559364   \n",
       "25%                 0.699728        0.896717                     0.616423   \n",
       "50%                 0.766624        0.916276                     0.636875   \n",
       "75%                 0.841340        0.933852                     0.663419   \n",
       "max                 0.969062        0.978080                     0.740559   \n",
       "\n",
       "       answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "count        476.000000        476.000000           476.000000   \n",
       "mean           0.951237          0.961477             0.836702   \n",
       "std            0.019491          0.019275             0.041231   \n",
       "min            0.803577          0.852746             0.693902   \n",
       "25%            0.942102          0.952453             0.811034   \n",
       "50%            0.953585          0.963857             0.839102   \n",
       "75%            0.963455          0.974451             0.865883   \n",
       "max            0.988534          0.993799             0.938850   \n",
       "\n",
       "       answer_type_instructions  answer_type_procedure  \\\n",
       "count                476.000000             476.000000   \n",
       "mean                   0.545300               0.158831   \n",
       "std                    0.303033               0.070943   \n",
       "min                    0.000661               0.002990   \n",
       "25%                    0.273502               0.108313   \n",
       "50%                    0.642882               0.159481   \n",
       "75%                    0.809053               0.208605   \n",
       "max                    0.978087               0.369058   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                      476.000000           476.000000  \n",
       "mean                         0.490611             0.888082  \n",
       "std                          0.248872             0.026474  \n",
       "min                          0.057444             0.756371  \n",
       "25%                          0.281766             0.872330  \n",
       "50%                          0.467388             0.889005  \n",
       "75%                          0.687132             0.905722  \n",
       "max                          0.983564             0.970600  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "submission[target_cols] = Y_test\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "display(submission.head())\n",
    "display(submission.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
