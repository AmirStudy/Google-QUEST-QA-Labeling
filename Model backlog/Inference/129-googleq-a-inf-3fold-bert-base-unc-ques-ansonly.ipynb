{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import warnings\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D, SpatialDropout1D, Concatenate\n",
    "from googleqa_utilityscript import *\n",
    "from googleqa_map_utilityscript import *\n",
    "import bert_tokenization as tokenization\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to predict: ['/kaggle/input/129-googleq-a-train-3fold-bert-base-unc-question/model_fold_1_question.h5', '/kaggle/input/129-googleq-a-train-3fold-bert-base-unc-question/model_fold_2_question.h5', '/kaggle/input/129-googleq-a-train-3fold-bert-base-unc-question/model_fold_3_question.h5', '/kaggle/input/129-googleq-a-train-3fold-bert-base-unc-answeronly/model_fold_1_answer.h5', '/kaggle/input/129-googleq-a-train-3fold-bert-base-unc-answeronly/model_fold_2_answer.h5', '/kaggle/input/129-googleq-a-train-3fold-bert-base-unc-answeronly/model_fold_3_answer.h5']\n",
      "Test samples: 476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BERT_PATH = '/kaggle/input/tf-hub-bert-base/bert_base_uncased'\n",
    "VOCAB_PATH = BERT_PATH + '/assets/vocab.txt'\n",
    "model_question_path_list = glob.glob('/kaggle/input/129-googleq-a-train-3fold-bert-base-unc-question/' + '*question.h5')\n",
    "model_answer_path_list = glob.glob('/kaggle/input/129-googleq-a-train-3fold-bert-base-unc-answeronly/' + '*answer.h5')\n",
    "model_question_path_list.sort()\n",
    "model_answer_path_list.sort()\n",
    "print('Models to predict:', model_question_path_list + model_answer_path_list)\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "question_target_cols = ['question_asker_intent_understanding','question_body_critical', 'question_conversational', \n",
    "                        'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                        'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', \n",
    "                        'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                        'question_type_compare', 'question_type_consequence', 'question_type_definition', \n",
    "                        'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                        'question_type_reason_explanation', 'question_type_spelling', 'question_well_written']\n",
    "answer_target_cols = ['answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                      'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', \n",
    "                      'answer_type_reason_explanation', 'answer_well_written']\n",
    "target_cols = question_target_cols + answer_target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['question_title', 'question_body', 'answer']\n",
    "text_features_question = ['question_title', 'question_body']\n",
    "text_features_answer = 'answer'\n",
    "\n",
    "# for feature in text_features:\n",
    "#     # Lower\n",
    "#     test[feature] = test[feature].apply(lambda x: x.lower())\n",
    "#     # Map misspellings\n",
    "#     test[feature] = test[feature].apply(lambda x: map_misspellings(x))\n",
    "#     # Map contractions\n",
    "#     test[feature] = test[feature].apply(lambda x: map_contraction(x))\n",
    "#     # Trim text\n",
    "#     test[feature] = test[feature].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "N_CLASS = len(target_cols)\n",
    "N_CLASS_QUESTION = len(question_target_cols)\n",
    "N_CLASS_ANSWER = len(answer_target_cols)\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "MAX_LENGTH_TITLE = 30\n",
    "MAX_LENGTH_QUESTION = 479\n",
    "MAX_LENGTH_ANSWER = 510"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(VOCAB_PATH, do_lower_case=True)\n",
    "\n",
    "# Test features\n",
    "X_test_question = compute_input_arays_2(test, text_features_question, tokenizer, MAX_SEQUENCE_LENGTH, \n",
    "                                        MAX_LENGTH_TITLE, MAX_LENGTH_QUESTION, ignore_first_sep=False)\n",
    "X_test_answer = compute_input_arays_1(test, text_features_answer, tokenizer, MAX_SEQUENCE_LENGTH, \n",
    "                                      MAX_LENGTH_ANSWER, ignore_first_sep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def question_model_fn():\n",
    "    input_word_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    segment_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids')\n",
    "\n",
    "    bert_layer = KerasLayer(BERT_PATH, trainable=True)\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_masks, segment_ids])\n",
    "\n",
    "    x = GlobalAveragePooling1D()(sequence_output)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(N_CLASS_QUESTION, activation=\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "    model = Model(inputs=[input_word_ids, input_masks, segment_ids], outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def answer_model_fn():\n",
    "    input_word_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    segment_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids')\n",
    "\n",
    "    bert_layer = KerasLayer(BERT_PATH, trainable=True)\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_masks, segment_ids])\n",
    "\n",
    "    x = GlobalAveragePooling1D()(sequence_output)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(N_CLASS_ANSWER, activation=\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "    model = Model(inputs=[input_word_ids, input_masks, segment_ids], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.zeros((len(test), N_CLASS))\n",
    "\n",
    "for index, model_path in enumerate(model_question_path_list):\n",
    "    model_question = question_model_fn()\n",
    "    model_answer = answer_model_fn()\n",
    "    model_question.load_weights(model_path)\n",
    "    model_answer.load_weights(model_answer_path_list[index])\n",
    "    \n",
    "    question_preds = model_question.predict(X_test_question)\n",
    "    answer_preds = model_answer.predict(X_test_answer)\n",
    "    Y_test += np.hstack([question_preds, answer_preds]) / len(model_question_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.935369</td>\n",
       "      <td>0.613000</td>\n",
       "      <td>0.157765</td>\n",
       "      <td>0.565073</td>\n",
       "      <td>0.625069</td>\n",
       "      <td>0.521756</td>\n",
       "      <td>0.662141</td>\n",
       "      <td>0.635480</td>\n",
       "      <td>0.645434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883141</td>\n",
       "      <td>0.926070</td>\n",
       "      <td>0.591048</td>\n",
       "      <td>0.955719</td>\n",
       "      <td>0.961784</td>\n",
       "      <td>0.849487</td>\n",
       "      <td>0.033994</td>\n",
       "      <td>0.063539</td>\n",
       "      <td>0.832078</td>\n",
       "      <td>0.889269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.840001</td>\n",
       "      <td>0.510596</td>\n",
       "      <td>0.011727</td>\n",
       "      <td>0.761377</td>\n",
       "      <td>0.716234</td>\n",
       "      <td>0.896264</td>\n",
       "      <td>0.550075</td>\n",
       "      <td>0.419652</td>\n",
       "      <td>0.134163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602531</td>\n",
       "      <td>0.940935</td>\n",
       "      <td>0.672303</td>\n",
       "      <td>0.974305</td>\n",
       "      <td>0.981091</td>\n",
       "      <td>0.883509</td>\n",
       "      <td>0.933075</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.061981</td>\n",
       "      <td>0.886651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.870393</td>\n",
       "      <td>0.582569</td>\n",
       "      <td>0.033468</td>\n",
       "      <td>0.737148</td>\n",
       "      <td>0.821371</td>\n",
       "      <td>0.860227</td>\n",
       "      <td>0.589866</td>\n",
       "      <td>0.506232</td>\n",
       "      <td>0.202224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812536</td>\n",
       "      <td>0.938154</td>\n",
       "      <td>0.610027</td>\n",
       "      <td>0.974604</td>\n",
       "      <td>0.971250</td>\n",
       "      <td>0.857755</td>\n",
       "      <td>0.070243</td>\n",
       "      <td>0.079184</td>\n",
       "      <td>0.917807</td>\n",
       "      <td>0.882611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.850551</td>\n",
       "      <td>0.415217</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.719844</td>\n",
       "      <td>0.749118</td>\n",
       "      <td>0.903134</td>\n",
       "      <td>0.525262</td>\n",
       "      <td>0.401060</td>\n",
       "      <td>0.162609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658481</td>\n",
       "      <td>0.952358</td>\n",
       "      <td>0.698954</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.985931</td>\n",
       "      <td>0.908319</td>\n",
       "      <td>0.808967</td>\n",
       "      <td>0.162779</td>\n",
       "      <td>0.604611</td>\n",
       "      <td>0.893952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.887118</td>\n",
       "      <td>0.414602</td>\n",
       "      <td>0.050023</td>\n",
       "      <td>0.777806</td>\n",
       "      <td>0.762347</td>\n",
       "      <td>0.849908</td>\n",
       "      <td>0.653987</td>\n",
       "      <td>0.561541</td>\n",
       "      <td>0.142866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.624554</td>\n",
       "      <td>0.883307</td>\n",
       "      <td>0.647215</td>\n",
       "      <td>0.946776</td>\n",
       "      <td>0.948658</td>\n",
       "      <td>0.811269</td>\n",
       "      <td>0.229443</td>\n",
       "      <td>0.136856</td>\n",
       "      <td>0.467765</td>\n",
       "      <td>0.900068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.935369                0.613000   \n",
       "1     46                             0.840001                0.510596   \n",
       "2     70                             0.870393                0.582569   \n",
       "3    132                             0.850551                0.415217   \n",
       "4    200                             0.887118                0.414602   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.157765                      0.565073   \n",
       "1                 0.011727                      0.761377   \n",
       "2                 0.033468                      0.737148   \n",
       "3                 0.007202                      0.719844   \n",
       "4                 0.050023                      0.777806   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.625069                               0.521756   \n",
       "1               0.716234                               0.896264   \n",
       "2               0.821371                               0.860227   \n",
       "3               0.749118                               0.903134   \n",
       "4               0.762347                               0.849908   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.662141                       0.635480   \n",
       "1                         0.550075                       0.419652   \n",
       "2                         0.589866                       0.506232   \n",
       "3                         0.525262                       0.401060   \n",
       "4                         0.653987                       0.561541   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.645434  ...               0.883141        0.926070   \n",
       "1               0.134163  ...               0.602531        0.940935   \n",
       "2               0.202224  ...               0.812536        0.938154   \n",
       "3               0.162609  ...               0.658481        0.952358   \n",
       "4               0.142866  ...               0.624554        0.883307   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.591048          0.955719          0.961784   \n",
       "1                     0.672303          0.974305          0.981091   \n",
       "2                     0.610027          0.974604          0.971250   \n",
       "3                     0.698954          0.977031          0.985931   \n",
       "4                     0.647215          0.946776          0.948658   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.849487                  0.033994               0.063539   \n",
       "1             0.883509                  0.933075               0.105300   \n",
       "2             0.857755                  0.070243               0.079184   \n",
       "3             0.908319                  0.808967               0.162779   \n",
       "4             0.811269                  0.229443               0.136856   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.832078             0.889269  \n",
       "1                        0.061981             0.886651  \n",
       "2                        0.917807             0.882611  \n",
       "3                        0.604611             0.893952  \n",
       "4                        0.467765             0.900068  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5029.186975</td>\n",
       "      <td>0.874672</td>\n",
       "      <td>0.542978</td>\n",
       "      <td>0.037522</td>\n",
       "      <td>0.717718</td>\n",
       "      <td>0.775777</td>\n",
       "      <td>0.820432</td>\n",
       "      <td>0.572588</td>\n",
       "      <td>0.470350</td>\n",
       "      <td>0.264392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.932470</td>\n",
       "      <td>0.660940</td>\n",
       "      <td>0.966181</td>\n",
       "      <td>0.973309</td>\n",
       "      <td>0.875430</td>\n",
       "      <td>0.529510</td>\n",
       "      <td>0.130247</td>\n",
       "      <td>0.491861</td>\n",
       "      <td>0.903843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2812.670060</td>\n",
       "      <td>0.040972</td>\n",
       "      <td>0.110307</td>\n",
       "      <td>0.048577</td>\n",
       "      <td>0.080031</td>\n",
       "      <td>0.082910</td>\n",
       "      <td>0.117182</td>\n",
       "      <td>0.051574</td>\n",
       "      <td>0.086376</td>\n",
       "      <td>0.187798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081894</td>\n",
       "      <td>0.030519</td>\n",
       "      <td>0.045850</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>0.015180</td>\n",
       "      <td>0.044237</td>\n",
       "      <td>0.325972</td>\n",
       "      <td>0.052866</td>\n",
       "      <td>0.283292</td>\n",
       "      <td>0.028186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.751233</td>\n",
       "      <td>0.348220</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.316731</td>\n",
       "      <td>0.493862</td>\n",
       "      <td>0.360521</td>\n",
       "      <td>0.481009</td>\n",
       "      <td>0.336215</td>\n",
       "      <td>0.024126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577080</td>\n",
       "      <td>0.743172</td>\n",
       "      <td>0.472188</td>\n",
       "      <td>0.866134</td>\n",
       "      <td>0.898190</td>\n",
       "      <td>0.611544</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.027655</td>\n",
       "      <td>0.749860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2572.000000</td>\n",
       "      <td>0.844301</td>\n",
       "      <td>0.451128</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>0.673397</td>\n",
       "      <td>0.733564</td>\n",
       "      <td>0.782945</td>\n",
       "      <td>0.530048</td>\n",
       "      <td>0.404944</td>\n",
       "      <td>0.114498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695342</td>\n",
       "      <td>0.920078</td>\n",
       "      <td>0.631582</td>\n",
       "      <td>0.960427</td>\n",
       "      <td>0.967812</td>\n",
       "      <td>0.852754</td>\n",
       "      <td>0.230091</td>\n",
       "      <td>0.091380</td>\n",
       "      <td>0.237232</td>\n",
       "      <td>0.888916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5093.000000</td>\n",
       "      <td>0.874199</td>\n",
       "      <td>0.532720</td>\n",
       "      <td>0.016775</td>\n",
       "      <td>0.725954</td>\n",
       "      <td>0.773395</td>\n",
       "      <td>0.863577</td>\n",
       "      <td>0.565573</td>\n",
       "      <td>0.441043</td>\n",
       "      <td>0.200618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761933</td>\n",
       "      <td>0.939261</td>\n",
       "      <td>0.660816</td>\n",
       "      <td>0.969092</td>\n",
       "      <td>0.977850</td>\n",
       "      <td>0.884863</td>\n",
       "      <td>0.582392</td>\n",
       "      <td>0.127851</td>\n",
       "      <td>0.474052</td>\n",
       "      <td>0.907733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7482.000000</td>\n",
       "      <td>0.905224</td>\n",
       "      <td>0.627846</td>\n",
       "      <td>0.041727</td>\n",
       "      <td>0.764682</td>\n",
       "      <td>0.831170</td>\n",
       "      <td>0.899042</td>\n",
       "      <td>0.609763</td>\n",
       "      <td>0.512959</td>\n",
       "      <td>0.387128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832497</td>\n",
       "      <td>0.954096</td>\n",
       "      <td>0.686137</td>\n",
       "      <td>0.975955</td>\n",
       "      <td>0.983668</td>\n",
       "      <td>0.906159</td>\n",
       "      <td>0.839550</td>\n",
       "      <td>0.163300</td>\n",
       "      <td>0.763110</td>\n",
       "      <td>0.922755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9640.000000</td>\n",
       "      <td>0.960932</td>\n",
       "      <td>0.839610</td>\n",
       "      <td>0.332040</td>\n",
       "      <td>0.921182</td>\n",
       "      <td>0.956516</td>\n",
       "      <td>0.953418</td>\n",
       "      <td>0.714501</td>\n",
       "      <td>0.762564</td>\n",
       "      <td>0.833807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915278</td>\n",
       "      <td>0.974841</td>\n",
       "      <td>0.794932</td>\n",
       "      <td>0.989181</td>\n",
       "      <td>0.991120</td>\n",
       "      <td>0.948636</td>\n",
       "      <td>0.966241</td>\n",
       "      <td>0.313752</td>\n",
       "      <td>0.976121</td>\n",
       "      <td>0.950988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qa_id  question_asker_intent_understanding  \\\n",
       "count   476.000000                           476.000000   \n",
       "mean   5029.186975                             0.874672   \n",
       "std    2812.670060                             0.040972   \n",
       "min      39.000000                             0.751233   \n",
       "25%    2572.000000                             0.844301   \n",
       "50%    5093.000000                             0.874199   \n",
       "75%    7482.000000                             0.905224   \n",
       "max    9640.000000                             0.960932   \n",
       "\n",
       "       question_body_critical  question_conversational  \\\n",
       "count              476.000000               476.000000   \n",
       "mean                 0.542978                 0.037522   \n",
       "std                  0.110307                 0.048577   \n",
       "min                  0.348220                 0.004598   \n",
       "25%                  0.451128                 0.010530   \n",
       "50%                  0.532720                 0.016775   \n",
       "75%                  0.627846                 0.041727   \n",
       "max                  0.839610                 0.332040   \n",
       "\n",
       "       question_expect_short_answer  question_fact_seeking  \\\n",
       "count                    476.000000             476.000000   \n",
       "mean                       0.717718               0.775777   \n",
       "std                        0.080031               0.082910   \n",
       "min                        0.316731               0.493862   \n",
       "25%                        0.673397               0.733564   \n",
       "50%                        0.725954               0.773395   \n",
       "75%                        0.764682               0.831170   \n",
       "max                        0.921182               0.956516   \n",
       "\n",
       "       question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "count                             476.000000                       476.000000   \n",
       "mean                                0.820432                         0.572588   \n",
       "std                                 0.117182                         0.051574   \n",
       "min                                 0.360521                         0.481009   \n",
       "25%                                 0.782945                         0.530048   \n",
       "50%                                 0.863577                         0.565573   \n",
       "75%                                 0.899042                         0.609763   \n",
       "max                                 0.953418                         0.714501   \n",
       "\n",
       "       question_interestingness_self  question_multi_intent  ...  \\\n",
       "count                     476.000000             476.000000  ...   \n",
       "mean                        0.470350               0.264392  ...   \n",
       "std                         0.086376               0.187798  ...   \n",
       "min                         0.336215               0.024126  ...   \n",
       "25%                         0.404944               0.114498  ...   \n",
       "50%                         0.441043               0.200618  ...   \n",
       "75%                         0.512959               0.387128  ...   \n",
       "max                         0.762564               0.833807  ...   \n",
       "\n",
       "       question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "count             476.000000      476.000000                   476.000000   \n",
       "mean                0.761111        0.932470                     0.660940   \n",
       "std                 0.081894        0.030519                     0.045850   \n",
       "min                 0.577080        0.743172                     0.472188   \n",
       "25%                 0.695342        0.920078                     0.631582   \n",
       "50%                 0.761933        0.939261                     0.660816   \n",
       "75%                 0.832497        0.954096                     0.686137   \n",
       "max                 0.915278        0.974841                     0.794932   \n",
       "\n",
       "       answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "count        476.000000        476.000000           476.000000   \n",
       "mean           0.966181          0.973309             0.875430   \n",
       "std            0.013841          0.015180             0.044237   \n",
       "min            0.866134          0.898190             0.611544   \n",
       "25%            0.960427          0.967812             0.852754   \n",
       "50%            0.969092          0.977850             0.884863   \n",
       "75%            0.975955          0.983668             0.906159   \n",
       "max            0.989181          0.991120             0.948636   \n",
       "\n",
       "       answer_type_instructions  answer_type_procedure  \\\n",
       "count                476.000000             476.000000   \n",
       "mean                   0.529510               0.130247   \n",
       "std                    0.325972               0.052866   \n",
       "min                    0.005319               0.012336   \n",
       "25%                    0.230091               0.091380   \n",
       "50%                    0.582392               0.127851   \n",
       "75%                    0.839550               0.163300   \n",
       "max                    0.966241               0.313752   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                      476.000000           476.000000  \n",
       "mean                         0.491861             0.903843  \n",
       "std                          0.283292             0.028186  \n",
       "min                          0.027655             0.749860  \n",
       "25%                          0.237232             0.888916  \n",
       "50%                          0.474052             0.907733  \n",
       "75%                          0.763110             0.922755  \n",
       "max                          0.976121             0.950988  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "submission[target_cols] = Y_test\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "display(submission.head())\n",
    "display(submission.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
