{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import warnings\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D, SpatialDropout1D, Concatenate\n",
    "from googleqa_utilityscript import *\n",
    "from googleqa_map_utilityscript import *\n",
    "import bert_tokenization as tokenization\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to predict:\n",
      "/kaggle/input/138bert-base-best/138-BERT_base_uncased_model_fold_1.h5\n",
      "/kaggle/input/138bert-base-best/138-BERT_base_uncased_model_fold_2.h5\n",
      "/kaggle/input/138bert-base-best/138-BERT_base_uncased_model_fold_3.h5\n",
      "/kaggle/input/138bert-base-best/138-BERT_base_uncased_model_fold_4.h5\n",
      "/kaggle/input/138bert-base-best/138-BERT_base_uncased_model_fold_5.h5\n",
      "/kaggle/input/138bert-base-last/138-BERT_base_uncased_model_fold_1_last_epoch.h5\n",
      "/kaggle/input/138bert-base-last/138-BERT_base_uncased_model_fold_2_last_epoch.h5\n",
      "/kaggle/input/138bert-base-last/138-BERT_base_uncased_model_fold_3_last_epoch.h5\n",
      "/kaggle/input/138bert-base-last/138-BERT_base_uncased_model_fold_4_last_epoch.h5\n",
      "/kaggle/input/138bert-base-last/138-BERT_base_uncased_model_fold_5_last_epoch.h5\n",
      "Test samples: 476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BERT_PATH = '/kaggle/input/tf-hub-bert-base/bert_base_uncased'\n",
    "VOCAB_PATH = BERT_PATH + '/assets/vocab.txt'\n",
    "model_path_list = glob.glob('/kaggle/input/138bert-base-best/' + '*.h5')\n",
    "model_path_list += glob.glob('/kaggle/input/138bert-base-last/' + '*.h5')\n",
    "model_path_list.sort()\n",
    "print('Models to predict:')\n",
    "print(*model_path_list, sep = \"\\n\")\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "question_target_cols = ['question_asker_intent_understanding','question_body_critical', 'question_conversational', \n",
    "                        'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                        'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', \n",
    "                        'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                        'question_type_compare', 'question_type_consequence', 'question_type_definition', \n",
    "                        'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                        'question_type_reason_explanation', 'question_type_spelling', 'question_well_written']\n",
    "answer_target_cols = ['answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                      'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', \n",
    "                      'answer_type_reason_explanation', 'answer_well_written']\n",
    "target_cols = question_target_cols + answer_target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "### BERT auxiliar function\n",
    "def _get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_segments(tokens, max_seq_length, ignore_first_sep=True):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if ignore_first_sep:\n",
    "                ignore_first_sep = False \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, tokenizer, max_sequence_length, \n",
    "                t_max_len=30, q_max_len=239, a_max_len=239):\n",
    "    \n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "            \n",
    "\n",
    "        t = t[:t_new_len//2] + t[-t_new_len//2:]\n",
    "        q = q[:q_new_len//2] + q[-q_new_len//2:]\n",
    "        a = a[:a_new_len//2] + a[-a_new_len//2:]\n",
    "\n",
    "    return t, q, a\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, tokenizer, max_sequence_length, ignore_first_sep=True):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    \n",
    "    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "\n",
    "    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n",
    "    input_masks = _get_masks(stoken, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken, max_sequence_length, ignore_first_sep)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "def compute_input_arays(df, columns, tokenizer, max_sequence_length, ignore_first_sep=True):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for _, instance in df[columns].iterrows():\n",
    "        t, q, a = instance.question_title, instance.question_body, instance.answer\n",
    "\n",
    "        t, q, a = _trim_input(t, q, a, tokenizer, max_sequence_length)\n",
    "\n",
    "        ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length, ignore_first_sep)\n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_segments.append(segments)\n",
    "        \n",
    "    return [np.asarray(input_ids, dtype=np.int32), \n",
    "            np.asarray(input_masks, dtype=np.int32), \n",
    "            np.asarray(input_segments, dtype=np.int32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['question_title', 'question_body', 'answer']\n",
    "\n",
    "# for feature in text_features:\n",
    "#     # Lower\n",
    "#     test[feature] = test[feature].apply(lambda x: x.lower())\n",
    "#     # Map misspellings\n",
    "#     test[feature] = test[feature].apply(lambda x: map_misspellings(x))\n",
    "#     # Map contractions\n",
    "#     test[feature] = test[feature].apply(lambda x: map_contraction(x))\n",
    "#     # Trim text\n",
    "#     test[feature] = test[feature].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "N_CLASS = len(target_cols)\n",
    "MAX_SEQUENCE_LENGTH = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(VOCAB_PATH, do_lower_case=True)\n",
    "\n",
    "# Test features\n",
    "X_test = compute_input_arays(test, text_features, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    input_word_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    segment_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids')\n",
    "\n",
    "    bert_layer = KerasLayer(BERT_PATH, trainable=False)\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_masks, segment_ids])\n",
    "\n",
    "    x = GlobalAveragePooling1D()(sequence_output)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(N_CLASS, activation=\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "    model = Model(inputs=[input_word_ids, input_masks, segment_ids], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.zeros((len(test), N_CLASS))\n",
    "\n",
    "for model_path in model_path_list:\n",
    "    model = model_fn()\n",
    "    model.load_weights(model_path)\n",
    "    Y_test += model.predict(X_test) / len(model_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.933394</td>\n",
       "      <td>0.625130</td>\n",
       "      <td>0.256767</td>\n",
       "      <td>0.469691</td>\n",
       "      <td>0.542994</td>\n",
       "      <td>0.495034</td>\n",
       "      <td>0.665732</td>\n",
       "      <td>0.648568</td>\n",
       "      <td>0.591723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870271</td>\n",
       "      <td>0.891900</td>\n",
       "      <td>0.574570</td>\n",
       "      <td>0.955927</td>\n",
       "      <td>0.953310</td>\n",
       "      <td>0.779129</td>\n",
       "      <td>0.068657</td>\n",
       "      <td>0.052935</td>\n",
       "      <td>0.852981</td>\n",
       "      <td>0.908816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.886840</td>\n",
       "      <td>0.515677</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>0.743555</td>\n",
       "      <td>0.778607</td>\n",
       "      <td>0.902366</td>\n",
       "      <td>0.534828</td>\n",
       "      <td>0.482968</td>\n",
       "      <td>0.062081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.726525</td>\n",
       "      <td>0.949428</td>\n",
       "      <td>0.675235</td>\n",
       "      <td>0.971004</td>\n",
       "      <td>0.980996</td>\n",
       "      <td>0.873889</td>\n",
       "      <td>0.910178</td>\n",
       "      <td>0.112686</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.879056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.920815</td>\n",
       "      <td>0.647544</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.767595</td>\n",
       "      <td>0.840374</td>\n",
       "      <td>0.907800</td>\n",
       "      <td>0.583054</td>\n",
       "      <td>0.483784</td>\n",
       "      <td>0.152073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846657</td>\n",
       "      <td>0.936579</td>\n",
       "      <td>0.643716</td>\n",
       "      <td>0.970308</td>\n",
       "      <td>0.973739</td>\n",
       "      <td>0.856315</td>\n",
       "      <td>0.086372</td>\n",
       "      <td>0.060808</td>\n",
       "      <td>0.879798</td>\n",
       "      <td>0.915902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.875012</td>\n",
       "      <td>0.426067</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.706165</td>\n",
       "      <td>0.773423</td>\n",
       "      <td>0.911449</td>\n",
       "      <td>0.534525</td>\n",
       "      <td>0.399634</td>\n",
       "      <td>0.130444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694953</td>\n",
       "      <td>0.956612</td>\n",
       "      <td>0.688367</td>\n",
       "      <td>0.969929</td>\n",
       "      <td>0.982214</td>\n",
       "      <td>0.894272</td>\n",
       "      <td>0.821637</td>\n",
       "      <td>0.183958</td>\n",
       "      <td>0.571124</td>\n",
       "      <td>0.908133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.925923</td>\n",
       "      <td>0.422302</td>\n",
       "      <td>0.060459</td>\n",
       "      <td>0.800709</td>\n",
       "      <td>0.691020</td>\n",
       "      <td>0.756490</td>\n",
       "      <td>0.641554</td>\n",
       "      <td>0.592486</td>\n",
       "      <td>0.105437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705803</td>\n",
       "      <td>0.912714</td>\n",
       "      <td>0.633457</td>\n",
       "      <td>0.966576</td>\n",
       "      <td>0.966648</td>\n",
       "      <td>0.819498</td>\n",
       "      <td>0.133774</td>\n",
       "      <td>0.103345</td>\n",
       "      <td>0.655478</td>\n",
       "      <td>0.906419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.933394                0.625130   \n",
       "1     46                             0.886840                0.515677   \n",
       "2     70                             0.920815                0.647544   \n",
       "3    132                             0.875012                0.426067   \n",
       "4    200                             0.925923                0.422302   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.256767                      0.469691   \n",
       "1                 0.007227                      0.743555   \n",
       "2                 0.036585                      0.767595   \n",
       "3                 0.007581                      0.706165   \n",
       "4                 0.060459                      0.800709   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.542994                               0.495034   \n",
       "1               0.778607                               0.902366   \n",
       "2               0.840374                               0.907800   \n",
       "3               0.773423                               0.911449   \n",
       "4               0.691020                               0.756490   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.665732                       0.648568   \n",
       "1                         0.534828                       0.482968   \n",
       "2                         0.583054                       0.483784   \n",
       "3                         0.534525                       0.399634   \n",
       "4                         0.641554                       0.592486   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.591723  ...               0.870271        0.891900   \n",
       "1               0.062081  ...               0.726525        0.949428   \n",
       "2               0.152073  ...               0.846657        0.936579   \n",
       "3               0.130444  ...               0.694953        0.956612   \n",
       "4               0.105437  ...               0.705803        0.912714   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.574570          0.955927          0.953310   \n",
       "1                     0.675235          0.971004          0.980996   \n",
       "2                     0.643716          0.970308          0.973739   \n",
       "3                     0.688367          0.969929          0.982214   \n",
       "4                     0.633457          0.966576          0.966648   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.779129                  0.068657               0.052935   \n",
       "1             0.873889                  0.910178               0.112686   \n",
       "2             0.856315                  0.086372               0.060808   \n",
       "3             0.894272                  0.821637               0.183958   \n",
       "4             0.819498                  0.133774               0.103345   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.852981             0.908816  \n",
       "1                        0.078600             0.879056  \n",
       "2                        0.879798             0.915902  \n",
       "3                        0.571124             0.908133  \n",
       "4                        0.655478             0.906419  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5029.186975</td>\n",
       "      <td>0.896127</td>\n",
       "      <td>0.582485</td>\n",
       "      <td>0.038108</td>\n",
       "      <td>0.711496</td>\n",
       "      <td>0.796867</td>\n",
       "      <td>0.832430</td>\n",
       "      <td>0.575496</td>\n",
       "      <td>0.486626</td>\n",
       "      <td>0.238401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795056</td>\n",
       "      <td>0.933664</td>\n",
       "      <td>0.667313</td>\n",
       "      <td>0.963671</td>\n",
       "      <td>0.972931</td>\n",
       "      <td>0.863182</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>0.136925</td>\n",
       "      <td>0.554122</td>\n",
       "      <td>0.909531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2812.670060</td>\n",
       "      <td>0.039982</td>\n",
       "      <td>0.124397</td>\n",
       "      <td>0.062485</td>\n",
       "      <td>0.098423</td>\n",
       "      <td>0.099223</td>\n",
       "      <td>0.132235</td>\n",
       "      <td>0.050571</td>\n",
       "      <td>0.084852</td>\n",
       "      <td>0.200253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075954</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>0.042605</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>0.010440</td>\n",
       "      <td>0.036491</td>\n",
       "      <td>0.310672</td>\n",
       "      <td>0.062876</td>\n",
       "      <td>0.267938</td>\n",
       "      <td>0.018798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.770787</td>\n",
       "      <td>0.355648</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.274419</td>\n",
       "      <td>0.334729</td>\n",
       "      <td>0.267721</td>\n",
       "      <td>0.470656</td>\n",
       "      <td>0.329610</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614739</td>\n",
       "      <td>0.808747</td>\n",
       "      <td>0.552613</td>\n",
       "      <td>0.907370</td>\n",
       "      <td>0.908348</td>\n",
       "      <td>0.724476</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.011110</td>\n",
       "      <td>0.036660</td>\n",
       "      <td>0.834766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2572.000000</td>\n",
       "      <td>0.870181</td>\n",
       "      <td>0.469157</td>\n",
       "      <td>0.009116</td>\n",
       "      <td>0.654106</td>\n",
       "      <td>0.750665</td>\n",
       "      <td>0.804502</td>\n",
       "      <td>0.537416</td>\n",
       "      <td>0.421905</td>\n",
       "      <td>0.081936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731617</td>\n",
       "      <td>0.921810</td>\n",
       "      <td>0.638876</td>\n",
       "      <td>0.957690</td>\n",
       "      <td>0.967831</td>\n",
       "      <td>0.841039</td>\n",
       "      <td>0.146352</td>\n",
       "      <td>0.091058</td>\n",
       "      <td>0.331873</td>\n",
       "      <td>0.897491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5093.000000</td>\n",
       "      <td>0.896991</td>\n",
       "      <td>0.570223</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.715862</td>\n",
       "      <td>0.806113</td>\n",
       "      <td>0.882478</td>\n",
       "      <td>0.569053</td>\n",
       "      <td>0.463868</td>\n",
       "      <td>0.165313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798477</td>\n",
       "      <td>0.937759</td>\n",
       "      <td>0.665187</td>\n",
       "      <td>0.965044</td>\n",
       "      <td>0.975256</td>\n",
       "      <td>0.867605</td>\n",
       "      <td>0.543794</td>\n",
       "      <td>0.137334</td>\n",
       "      <td>0.570612</td>\n",
       "      <td>0.911549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7482.000000</td>\n",
       "      <td>0.926084</td>\n",
       "      <td>0.681391</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>0.774992</td>\n",
       "      <td>0.862398</td>\n",
       "      <td>0.913105</td>\n",
       "      <td>0.610146</td>\n",
       "      <td>0.525559</td>\n",
       "      <td>0.369711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858909</td>\n",
       "      <td>0.949790</td>\n",
       "      <td>0.694106</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.980689</td>\n",
       "      <td>0.889567</td>\n",
       "      <td>0.769779</td>\n",
       "      <td>0.182052</td>\n",
       "      <td>0.779542</td>\n",
       "      <td>0.922620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9640.000000</td>\n",
       "      <td>0.972022</td>\n",
       "      <td>0.892755</td>\n",
       "      <td>0.549330</td>\n",
       "      <td>0.952685</td>\n",
       "      <td>0.972115</td>\n",
       "      <td>0.972205</td>\n",
       "      <td>0.701667</td>\n",
       "      <td>0.743521</td>\n",
       "      <td>0.847218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951136</td>\n",
       "      <td>0.976533</td>\n",
       "      <td>0.805517</td>\n",
       "      <td>0.984114</td>\n",
       "      <td>0.990430</td>\n",
       "      <td>0.951369</td>\n",
       "      <td>0.940973</td>\n",
       "      <td>0.308652</td>\n",
       "      <td>0.987875</td>\n",
       "      <td>0.948462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qa_id  question_asker_intent_understanding  \\\n",
       "count   476.000000                           476.000000   \n",
       "mean   5029.186975                             0.896127   \n",
       "std    2812.670060                             0.039982   \n",
       "min      39.000000                             0.770787   \n",
       "25%    2572.000000                             0.870181   \n",
       "50%    5093.000000                             0.896991   \n",
       "75%    7482.000000                             0.926084   \n",
       "max    9640.000000                             0.972022   \n",
       "\n",
       "       question_body_critical  question_conversational  \\\n",
       "count              476.000000               476.000000   \n",
       "mean                 0.582485                 0.038108   \n",
       "std                  0.124397                 0.062485   \n",
       "min                  0.355648                 0.004169   \n",
       "25%                  0.469157                 0.009116   \n",
       "50%                  0.570223                 0.014289   \n",
       "75%                  0.681391                 0.033184   \n",
       "max                  0.892755                 0.549330   \n",
       "\n",
       "       question_expect_short_answer  question_fact_seeking  \\\n",
       "count                    476.000000             476.000000   \n",
       "mean                       0.711496               0.796867   \n",
       "std                        0.098423               0.099223   \n",
       "min                        0.274419               0.334729   \n",
       "25%                        0.654106               0.750665   \n",
       "50%                        0.715862               0.806113   \n",
       "75%                        0.774992               0.862398   \n",
       "max                        0.952685               0.972115   \n",
       "\n",
       "       question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "count                             476.000000                       476.000000   \n",
       "mean                                0.832430                         0.575496   \n",
       "std                                 0.132235                         0.050571   \n",
       "min                                 0.267721                         0.470656   \n",
       "25%                                 0.804502                         0.537416   \n",
       "50%                                 0.882478                         0.569053   \n",
       "75%                                 0.913105                         0.610146   \n",
       "max                                 0.972205                         0.701667   \n",
       "\n",
       "       question_interestingness_self  question_multi_intent  ...  \\\n",
       "count                     476.000000             476.000000  ...   \n",
       "mean                        0.486626               0.238401  ...   \n",
       "std                         0.084852               0.200253  ...   \n",
       "min                         0.329610               0.010352  ...   \n",
       "25%                         0.421905               0.081936  ...   \n",
       "50%                         0.463868               0.165313  ...   \n",
       "75%                         0.525559               0.369711  ...   \n",
       "max                         0.743521               0.847218  ...   \n",
       "\n",
       "       question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "count             476.000000      476.000000                   476.000000   \n",
       "mean                0.795056        0.933664                     0.667313   \n",
       "std                 0.075954        0.021842                     0.042605   \n",
       "min                 0.614739        0.808747                     0.552613   \n",
       "25%                 0.731617        0.921810                     0.638876   \n",
       "50%                 0.798477        0.937759                     0.665187   \n",
       "75%                 0.858909        0.949790                     0.694106   \n",
       "max                 0.951136        0.976533                     0.805517   \n",
       "\n",
       "       answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "count        476.000000        476.000000           476.000000   \n",
       "mean           0.963671          0.972931             0.863182   \n",
       "std            0.010306          0.010440             0.036491   \n",
       "min            0.907370          0.908348             0.724476   \n",
       "25%            0.957690          0.967831             0.841039   \n",
       "50%            0.965044          0.975256             0.867605   \n",
       "75%            0.971014          0.980689             0.889567   \n",
       "max            0.984114          0.990430             0.951369   \n",
       "\n",
       "       answer_type_instructions  answer_type_procedure  \\\n",
       "count                476.000000             476.000000   \n",
       "mean                   0.484177               0.136925   \n",
       "std                    0.310672               0.062876   \n",
       "min                    0.008313               0.011110   \n",
       "25%                    0.146352               0.091058   \n",
       "50%                    0.543794               0.137334   \n",
       "75%                    0.769779               0.182052   \n",
       "max                    0.940973               0.308652   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                      476.000000           476.000000  \n",
       "mean                         0.554122             0.909531  \n",
       "std                          0.267938             0.018798  \n",
       "min                          0.036660             0.834766  \n",
       "25%                          0.331873             0.897491  \n",
       "50%                          0.570612             0.911549  \n",
       "75%                          0.779542             0.922620  \n",
       "max                          0.987875             0.948462  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "submission[target_cols] = Y_test\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "display(submission.head())\n",
    "display(submission.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
