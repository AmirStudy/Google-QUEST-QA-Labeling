{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import warnings\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D, SpatialDropout1D, Concatenate\n",
    "from googleqa_utilityscript import *\n",
    "import bert_tokenization as tokenization\n",
    "from transformers import BertConfig, BertTokenizer, TFBertModel\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to predict (tf):\n",
      "/kaggle/input/130-googleq-a-train-3fold-bert-base-unc-quest-ans3/model_fold_1.h5\n",
      "/kaggle/input/130-googleq-a-train-3fold-bert-base-unc-quest-ans3/model_fold_2.h5\n",
      "/kaggle/input/130-googleq-a-train-3fold-bert-base-unc-quest-ans3/model_fold_3.h5\n",
      "/kaggle/input/bert-131-best/131-Bert_base_unc Quest_Ans3_model_fold_1.h5\n",
      "/kaggle/input/bert-131-best/131-Bert_base_unc Quest_Ans3_model_fold_2.h5\n",
      "/kaggle/input/bert-131-best/131-Bert_base_unc Quest_Ans3_model_fold_3.h5\n",
      "/kaggle/input/bert-131-best/131-Bert_base_unc Quest_Ans3_model_fold_4.h5\n",
      "/kaggle/input/bert-131-best/131-Bert_base_unc Quest_Ans3_model_fold_5.h5\n",
      "/kaggle/input/bert-131-last/bert-131-last/131-Bert_base_unc Quest_Ans3_model_fold_1_last_epoch.h5\n",
      "/kaggle/input/bert-131-last/bert-131-last/131-Bert_base_unc Quest_Ans3_model_fold_2_last_epoch.h5\n",
      "/kaggle/input/bert-131-last/bert-131-last/131-Bert_base_unc Quest_Ans3_model_fold_4_last_epoch.h5\n",
      "/kaggle/input/bert-131-last/bert-131-last/131-Bert_base_unc Quest_Ans3_model_fold_5_last_epoch.h5\n",
      "Models to predict (tf2):\n",
      "/kaggle/input/bert-138-last/138-BERT_base_uncased_model_fold_1_last_epoch.h5\n",
      "/kaggle/input/bert-138-last/138-BERT_base_uncased_model_fold_2_last_epoch.h5\n",
      "/kaggle/input/bert-138-last/138-BERT_base_uncased_model_fold_3_last_epoch.h5\n",
      "/kaggle/input/bert-138-last/138-BERT_base_uncased_model_fold_4_last_epoch.h5\n",
      "/kaggle/input/bert-138-last/138-BERT_base_uncased_model_fold_5_last_epoch.h5\n",
      "Models to predict:\n",
      "/kaggle/input/148-googleq-a-train-3fold-bert-base-unc-qa3/model_fold_1.h5\n",
      "/kaggle/input/148-googleq-a-train-3fold-bert-base-unc-qa3/model_fold_2.h5\n",
      "/kaggle/input/148-googleq-a-train-3fold-bert-base-unc-qa3/model_fold_3.h5\n",
      "Test samples: 476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BERT_PATH_TF = '/kaggle/input/tf-hub-bert-base/bert_base_uncased'\n",
    "VOCAB_PATH_TF = BERT_PATH_TF + '/assets/vocab.txt'\n",
    "BERT_PATH = '/kaggle/input/bert-base-uncased-huggingface/bert-base-uncased/bert-base-uncased-tf_model.h5'\n",
    "VOCAB_PATH = '/kaggle/input/bert-base-uncased-huggingface/bert-base-uncased/bert-base-uncased-vocab.txt'\n",
    "\n",
    "model_path_list_tf = glob.glob('/kaggle/input/130-googleq-a-train-3fold-bert-base-unc-quest-ans3/' + '*.h5')\n",
    "model_path_list_tf += glob.glob('/kaggle/input/bert-131-last/bert-131-last/' + '*.h5')\n",
    "model_path_list_tf += glob.glob('/kaggle/input/bert-131-best/' + '*.h5')\n",
    "model_path_list_tf.sort()\n",
    "\n",
    "model_path_list_tf2 = glob.glob('/kaggle/input/bert-138-last/' + '*.h5')\n",
    "model_path_list_tf2.sort()\n",
    "\n",
    "model_path_list = glob.glob('/kaggle/input/148-googleq-a-train-3fold-bert-base-unc-qa3/' + '*1.h5')\n",
    "model_path_list += glob.glob('/kaggle/input/148-googleq-a-train-3fold-bert-base-unc-qa3/' + '*2.h5')\n",
    "model_path_list += glob.glob('/kaggle/input/148-googleq-a-train-3fold-bert-base-unc-qa3/' + '*3.h5')\n",
    "model_path_list.sort()\n",
    "n_models  = len(model_path_list_tf) + len(model_path_list_tf2) + len(model_path_list)\n",
    "\n",
    "print('Models to predict (tf):')\n",
    "print(*model_path_list_tf, sep = \"\\n\")\n",
    "print('Models to predict (tf2):')\n",
    "print(*model_path_list_tf2, sep = \"\\n\")\n",
    "print('Models to predict:')\n",
    "print(*model_path_list, sep = \"\\n\")\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "question_target_cols = ['question_asker_intent_understanding','question_body_critical', 'question_conversational', \n",
    "                        'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                        'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', \n",
    "                        'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                        'question_type_compare', 'question_type_consequence', 'question_type_definition', \n",
    "                        'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                        'question_type_reason_explanation', 'question_type_spelling', 'question_well_written']\n",
    "answer_target_cols = ['answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                      'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', \n",
    "                      'answer_type_reason_explanation', 'answer_well_written']\n",
    "target_cols = question_target_cols + answer_target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BERT auxiliar function\n",
    "def _get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_segments(tokens, max_seq_length, ignore_first_sep=True):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if ignore_first_sep:\n",
    "                ignore_first_sep = False \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input_2_tail(ft_input1, ft_input2, tokenizer, max_sequence_length, \n",
    "                  max_len_ft1=254, max_len_ft2=255):\n",
    "\n",
    "    ft1 = tokenizer.tokenize(ft_input1)\n",
    "    ft2 = tokenizer.tokenize(ft_input2)\n",
    "    \n",
    "    ft1_len = len(ft1)\n",
    "    ft2_len = len(ft2)\n",
    "\n",
    "    if (ft1_len + ft2_len + 3) > max_sequence_length:\n",
    "      \n",
    "        if max_len_ft2 > ft2_len:\n",
    "            ft2_new_len = ft2_len \n",
    "            ft1_new_len = max_len_ft1 + (max_len_ft2 - ft2_len)\n",
    "        elif max_len_ft1 > ft1_len:\n",
    "            ft2_new_len = max_len_ft2 + (max_len_ft1 - ft1_len)\n",
    "            ft1_new_len = ft1_len\n",
    "        else:\n",
    "            ft2_new_len = max_len_ft2\n",
    "            ft1_new_len = max_len_ft1\n",
    "                        \n",
    "        if ft1_new_len + ft2_new_len + 3 > max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (ft1_new_len + ft2_new_len + 3)))\n",
    "        \n",
    "        ft1 = ft1[-ft1_new_len:]\n",
    "        ft2 = ft2[-ft2_new_len:]\n",
    "        \n",
    "    return ft1, ft2\n",
    "\n",
    "def _convert_to_bert_inputs_2(feature1, feature2, tokenizer, max_sequence_length, ignore_first_sep=True):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    \n",
    "    stoken = [\"[CLS]\"] + feature1 + [\"[SEP]\"] + feature2 + [\"[SEP]\"]\n",
    "\n",
    "    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n",
    "    input_masks = _get_masks(stoken, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken, max_sequence_length, ignore_first_sep)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "def compute_input_arays_2_tail(df, columns, tokenizer, max_sequence_length, \n",
    "                          max_len_ft1, max_len_ft2, ignore_first_sep=True):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for _, instance in df[columns].iterrows():\n",
    "        ft1, ft2 = instance[columns[0]], instance[columns[1]]\n",
    "\n",
    "        ft1, ft2 = _trim_input_2_tail(ft1, ft2, tokenizer, max_sequence_length, \n",
    "                                      max_len_ft1, max_len_ft2)\n",
    "\n",
    "        ids, masks, segments = _convert_to_bert_inputs_2(ft1, ft2, tokenizer, max_sequence_length, \n",
    "                                                         ignore_first_sep)\n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_segments.append(segments)\n",
    "        \n",
    "    return [np.asarray(input_ids, dtype=np.int32), \n",
    "            np.asarray(input_masks, dtype=np.int32), \n",
    "            np.asarray(input_segments, dtype=np.int32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['question_title', 'question_body', 'answer']\n",
    "text_features_question = ['question_title', 'question_body']\n",
    "text_features_answer = ['question_title', 'answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "N_CLASS = len(target_cols)\n",
    "N_CLASS_QUESTION = len(question_target_cols)\n",
    "N_CLASS_ANSWER = len(answer_target_cols)\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "MAX_LENGTH_TITLE = 30\n",
    "MAX_LENGTH_QUESTION = 479\n",
    "MAX_LENGTH_ANSWER = 479"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(VOCAB_PATH_TF, do_lower_case=True)\n",
    "\n",
    "# Test features HEAD\n",
    "X_test = compute_input_arays_2(test, text_features_question, tokenizer, MAX_SEQUENCE_LENGTH, \n",
    "                               MAX_LENGTH_TITLE, MAX_LENGTH_QUESTION, ignore_first_sep=False)\\\n",
    "        + compute_input_arays_2(test, text_features_answer, tokenizer, MAX_SEQUENCE_LENGTH, \n",
    "                                MAX_LENGTH_TITLE, MAX_LENGTH_ANSWER, ignore_first_sep=False)\n",
    "\n",
    "# Test features TAIL\n",
    "X_test_tail = compute_input_arays_2_tail(test, text_features_question, tokenizer, MAX_SEQUENCE_LENGTH, \n",
    "                                         MAX_LENGTH_TITLE, MAX_LENGTH_QUESTION, ignore_first_sep=False)\\\n",
    "              + compute_input_arays_2_tail(test, text_features_answer, tokenizer, MAX_SEQUENCE_LENGTH, \n",
    "                                           MAX_LENGTH_TITLE, MAX_LENGTH_ANSWER, ignore_first_sep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "bert_config = BertConfig()\n",
    "bert_config.output_hidden_states=False\n",
    "\n",
    "def model_fn():\n",
    "    input_word_ids_question = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids_question')\n",
    "    input_masks_question = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks_question')\n",
    "    segment_ids_question = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids_question')\n",
    "\n",
    "    input_word_ids_answer = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids_answer')\n",
    "    input_masks_answer = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks_answer')\n",
    "    segment_ids_answer = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids_answer')\n",
    "\n",
    "    bert_model = TFBertModel.from_pretrained(BERT_PATH, config=bert_config)\n",
    "    sequence_output_question, pooled_output_question = bert_model([input_word_ids_question, input_masks_question, segment_ids_question])\n",
    "    sequence_output_answer, pooled_output_answer = bert_model([input_word_ids_answer, input_masks_answer, segment_ids_answer])\n",
    "    \n",
    "    x_question = GlobalAveragePooling1D()(sequence_output_question)\n",
    "    x_question = Dropout(0.2)(x_question)\n",
    "    output_question = Dense(N_CLASS_QUESTION, kernel_initializer='glorot_uniform', activation=\"sigmoid\", name=\"outputquestion\")(x_question)\n",
    "    \n",
    "    x_answer = GlobalAveragePooling1D()(sequence_output_answer)\n",
    "    x_answer = Dropout(0.2)(x_answer)\n",
    "    output_answer = Dense(N_CLASS_ANSWER, kernel_initializer='glorot_uniform', activation=\"sigmoid\", name=\"output_answer\")(x_answer)\n",
    "    \n",
    "    output = Concatenate()([output_question, output_answer])\n",
    "\n",
    "    model = Model(inputs=[input_word_ids_question, input_masks_question, segment_ids_question, \n",
    "                          input_word_ids_answer, input_masks_answer, segment_ids_answer], outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "def model_fn_tf():\n",
    "    input_word_ids_question = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids_question')\n",
    "    input_masks_question = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks_question')\n",
    "    segment_ids_question = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids_question')\n",
    "\n",
    "    input_word_ids_answer = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids_answer')\n",
    "    input_masks_answer = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks_answer')\n",
    "    segment_ids_answer = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids_answer')\n",
    "\n",
    "    bert_layer = KerasLayer(BERT_PATH_TF, trainable=True)\n",
    "    pooled_output_question, sequence_output_question = bert_layer([input_word_ids_question, input_masks_question, segment_ids_question])\n",
    "    pooled_output_answer, sequence_output_answer = bert_layer([input_word_ids_answer, input_masks_answer, segment_ids_answer])\n",
    "\n",
    "    x_question = GlobalAveragePooling1D()(sequence_output_question)\n",
    "    x_question = Dropout(0.2)(x_question)\n",
    "    output_question = Dense(N_CLASS_QUESTION, kernel_initializer='glorot_uniform', activation=\"sigmoid\", name=\"outputquestion\")(x_question)\n",
    "    \n",
    "    x_answer = GlobalAveragePooling1D()(sequence_output_answer)\n",
    "    x_answer = Dropout(0.2)(x_answer)\n",
    "    output_answer = Dense(N_CLASS_ANSWER, kernel_initializer='glorot_uniform', activation=\"sigmoid\", name=\"output_answer\")(x_answer)\n",
    "    \n",
    "    output = Concatenate()([output_question, output_answer])\n",
    "\n",
    "    model = Model(inputs=[input_word_ids_question, input_masks_question, segment_ids_question, \n",
    "                          input_word_ids_answer, input_masks_answer, segment_ids_answer], outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_fn_tf2():\n",
    "    input_word_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    segment_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids')\n",
    "\n",
    "    bert_layer = KerasLayer(BERT_PATH_TF, trainable=False)\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_masks, segment_ids])\n",
    "\n",
    "    x = GlobalAveragePooling1D()(sequence_output)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(N_CLASS, activation=\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "    model = Model(inputs=[input_word_ids, input_masks, segment_ids], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.zeros((len(test), N_CLASS))\n",
    "\n",
    "for model_path in model_path_list:\n",
    "    model = model_fn()\n",
    "    model.load_weights(model_path)\n",
    "    Y_test += ((model.predict(X_test) + model.predict(X_test_tail)) / 2) / n_models\n",
    "    \n",
    "for model_path in model_path_list_tf:\n",
    "    model = model_fn_tf()\n",
    "    model.load_weights(model_path)\n",
    "    Y_test += ((model.predict(X_test) + model.predict(X_test_tail)) / 2) / n_models\n",
    "    \n",
    "for model_path in model_path_list_tf2:\n",
    "    model = model_fn_tf2()\n",
    "    model.load_weights(model_path)\n",
    "    Y_test += ((model.predict(X_test) + model.predict(X_test_tail)) / 2) / n_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.953507</td>\n",
       "      <td>0.695183</td>\n",
       "      <td>0.162824</td>\n",
       "      <td>0.616901</td>\n",
       "      <td>0.641201</td>\n",
       "      <td>0.603509</td>\n",
       "      <td>0.686106</td>\n",
       "      <td>0.638112</td>\n",
       "      <td>0.516880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911559</td>\n",
       "      <td>0.934077</td>\n",
       "      <td>0.626078</td>\n",
       "      <td>0.973088</td>\n",
       "      <td>0.976435</td>\n",
       "      <td>0.846252</td>\n",
       "      <td>0.043377</td>\n",
       "      <td>0.038125</td>\n",
       "      <td>0.822683</td>\n",
       "      <td>0.916932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.861798</td>\n",
       "      <td>0.500108</td>\n",
       "      <td>0.008709</td>\n",
       "      <td>0.779624</td>\n",
       "      <td>0.774629</td>\n",
       "      <td>0.934871</td>\n",
       "      <td>0.536041</td>\n",
       "      <td>0.457276</td>\n",
       "      <td>0.087832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641709</td>\n",
       "      <td>0.940234</td>\n",
       "      <td>0.663171</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.979680</td>\n",
       "      <td>0.871423</td>\n",
       "      <td>0.879715</td>\n",
       "      <td>0.128230</td>\n",
       "      <td>0.145817</td>\n",
       "      <td>0.877207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.895262</td>\n",
       "      <td>0.690728</td>\n",
       "      <td>0.028490</td>\n",
       "      <td>0.789512</td>\n",
       "      <td>0.878969</td>\n",
       "      <td>0.920898</td>\n",
       "      <td>0.586120</td>\n",
       "      <td>0.490428</td>\n",
       "      <td>0.131377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859073</td>\n",
       "      <td>0.948565</td>\n",
       "      <td>0.632484</td>\n",
       "      <td>0.969904</td>\n",
       "      <td>0.970908</td>\n",
       "      <td>0.870428</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>0.043115</td>\n",
       "      <td>0.864238</td>\n",
       "      <td>0.907203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.839173</td>\n",
       "      <td>0.419477</td>\n",
       "      <td>0.009314</td>\n",
       "      <td>0.708116</td>\n",
       "      <td>0.760134</td>\n",
       "      <td>0.911453</td>\n",
       "      <td>0.508830</td>\n",
       "      <td>0.399409</td>\n",
       "      <td>0.100994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669735</td>\n",
       "      <td>0.953588</td>\n",
       "      <td>0.703736</td>\n",
       "      <td>0.971149</td>\n",
       "      <td>0.980632</td>\n",
       "      <td>0.906637</td>\n",
       "      <td>0.772888</td>\n",
       "      <td>0.159859</td>\n",
       "      <td>0.601196</td>\n",
       "      <td>0.887457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.932315</td>\n",
       "      <td>0.478202</td>\n",
       "      <td>0.037392</td>\n",
       "      <td>0.876551</td>\n",
       "      <td>0.791687</td>\n",
       "      <td>0.909015</td>\n",
       "      <td>0.637064</td>\n",
       "      <td>0.591562</td>\n",
       "      <td>0.085856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659374</td>\n",
       "      <td>0.922701</td>\n",
       "      <td>0.664268</td>\n",
       "      <td>0.960629</td>\n",
       "      <td>0.965830</td>\n",
       "      <td>0.840505</td>\n",
       "      <td>0.205367</td>\n",
       "      <td>0.129715</td>\n",
       "      <td>0.631912</td>\n",
       "      <td>0.886449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.953507                0.695183   \n",
       "1     46                             0.861798                0.500108   \n",
       "2     70                             0.895262                0.690728   \n",
       "3    132                             0.839173                0.419477   \n",
       "4    200                             0.932315                0.478202   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.162824                      0.616901   \n",
       "1                 0.008709                      0.779624   \n",
       "2                 0.028490                      0.789512   \n",
       "3                 0.009314                      0.708116   \n",
       "4                 0.037392                      0.876551   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.641201                               0.603509   \n",
       "1               0.774629                               0.934871   \n",
       "2               0.878969                               0.920898   \n",
       "3               0.760134                               0.911453   \n",
       "4               0.791687                               0.909015   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.686106                       0.638112   \n",
       "1                         0.536041                       0.457276   \n",
       "2                         0.586120                       0.490428   \n",
       "3                         0.508830                       0.399409   \n",
       "4                         0.637064                       0.591562   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.516880  ...               0.911559        0.934077   \n",
       "1               0.087832  ...               0.641709        0.940234   \n",
       "2               0.131377  ...               0.859073        0.948565   \n",
       "3               0.100994  ...               0.669735        0.953588   \n",
       "4               0.085856  ...               0.659374        0.922701   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.626078          0.973088          0.976435   \n",
       "1                     0.663171          0.970750          0.979680   \n",
       "2                     0.632484          0.969904          0.970908   \n",
       "3                     0.703736          0.971149          0.980632   \n",
       "4                     0.664268          0.960629          0.965830   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.846252                  0.043377               0.038125   \n",
       "1             0.871423                  0.879715               0.128230   \n",
       "2             0.870428                  0.050321               0.043115   \n",
       "3             0.906637                  0.772888               0.159859   \n",
       "4             0.840505                  0.205367               0.129715   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.822683             0.916932  \n",
       "1                        0.145817             0.877207  \n",
       "2                        0.864238             0.907203  \n",
       "3                        0.601196             0.887457  \n",
       "4                        0.631912             0.886449  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5029.186975</td>\n",
       "      <td>0.891478</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.032761</td>\n",
       "      <td>0.751046</td>\n",
       "      <td>0.811013</td>\n",
       "      <td>0.861495</td>\n",
       "      <td>0.576797</td>\n",
       "      <td>0.487319</td>\n",
       "      <td>0.197883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785990</td>\n",
       "      <td>0.934192</td>\n",
       "      <td>0.665800</td>\n",
       "      <td>0.964078</td>\n",
       "      <td>0.972931</td>\n",
       "      <td>0.869153</td>\n",
       "      <td>0.497816</td>\n",
       "      <td>0.134083</td>\n",
       "      <td>0.510610</td>\n",
       "      <td>0.903609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2812.670060</td>\n",
       "      <td>0.047502</td>\n",
       "      <td>0.145066</td>\n",
       "      <td>0.050820</td>\n",
       "      <td>0.087136</td>\n",
       "      <td>0.089694</td>\n",
       "      <td>0.112949</td>\n",
       "      <td>0.052694</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.168569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096134</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>0.037592</td>\n",
       "      <td>0.011884</td>\n",
       "      <td>0.010704</td>\n",
       "      <td>0.033756</td>\n",
       "      <td>0.301487</td>\n",
       "      <td>0.057888</td>\n",
       "      <td>0.252673</td>\n",
       "      <td>0.022140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.742782</td>\n",
       "      <td>0.346997</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.382506</td>\n",
       "      <td>0.459894</td>\n",
       "      <td>0.231130</td>\n",
       "      <td>0.485198</td>\n",
       "      <td>0.358900</td>\n",
       "      <td>0.014039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574367</td>\n",
       "      <td>0.810831</td>\n",
       "      <td>0.547739</td>\n",
       "      <td>0.908454</td>\n",
       "      <td>0.901203</td>\n",
       "      <td>0.737421</td>\n",
       "      <td>0.008252</td>\n",
       "      <td>0.012815</td>\n",
       "      <td>0.061005</td>\n",
       "      <td>0.832567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2572.000000</td>\n",
       "      <td>0.855306</td>\n",
       "      <td>0.470893</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>0.704890</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.846749</td>\n",
       "      <td>0.533908</td>\n",
       "      <td>0.420819</td>\n",
       "      <td>0.070075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700773</td>\n",
       "      <td>0.921485</td>\n",
       "      <td>0.640350</td>\n",
       "      <td>0.958518</td>\n",
       "      <td>0.968029</td>\n",
       "      <td>0.851144</td>\n",
       "      <td>0.191527</td>\n",
       "      <td>0.095463</td>\n",
       "      <td>0.290739</td>\n",
       "      <td>0.889493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5093.000000</td>\n",
       "      <td>0.895825</td>\n",
       "      <td>0.588653</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>0.752669</td>\n",
       "      <td>0.820246</td>\n",
       "      <td>0.904952</td>\n",
       "      <td>0.566549</td>\n",
       "      <td>0.457755</td>\n",
       "      <td>0.135823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781937</td>\n",
       "      <td>0.939276</td>\n",
       "      <td>0.664306</td>\n",
       "      <td>0.966194</td>\n",
       "      <td>0.975025</td>\n",
       "      <td>0.872678</td>\n",
       "      <td>0.581506</td>\n",
       "      <td>0.137654</td>\n",
       "      <td>0.504803</td>\n",
       "      <td>0.905576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7482.000000</td>\n",
       "      <td>0.929726</td>\n",
       "      <td>0.732399</td>\n",
       "      <td>0.028791</td>\n",
       "      <td>0.800828</td>\n",
       "      <td>0.871122</td>\n",
       "      <td>0.927567</td>\n",
       "      <td>0.614897</td>\n",
       "      <td>0.542505</td>\n",
       "      <td>0.289610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878785</td>\n",
       "      <td>0.950283</td>\n",
       "      <td>0.689043</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.980509</td>\n",
       "      <td>0.892696</td>\n",
       "      <td>0.771623</td>\n",
       "      <td>0.174161</td>\n",
       "      <td>0.725493</td>\n",
       "      <td>0.919333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9640.000000</td>\n",
       "      <td>0.976061</td>\n",
       "      <td>0.899250</td>\n",
       "      <td>0.386679</td>\n",
       "      <td>0.963952</td>\n",
       "      <td>0.974981</td>\n",
       "      <td>0.970100</td>\n",
       "      <td>0.716034</td>\n",
       "      <td>0.734911</td>\n",
       "      <td>0.796849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959722</td>\n",
       "      <td>0.977856</td>\n",
       "      <td>0.786994</td>\n",
       "      <td>0.983402</td>\n",
       "      <td>0.990115</td>\n",
       "      <td>0.939564</td>\n",
       "      <td>0.933787</td>\n",
       "      <td>0.305896</td>\n",
       "      <td>0.976253</td>\n",
       "      <td>0.953157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qa_id  question_asker_intent_understanding  \\\n",
       "count   476.000000                           476.000000   \n",
       "mean   5029.186975                             0.891478   \n",
       "std    2812.670060                             0.047502   \n",
       "min      39.000000                             0.742782   \n",
       "25%    2572.000000                             0.855306   \n",
       "50%    5093.000000                             0.895825   \n",
       "75%    7482.000000                             0.929726   \n",
       "max    9640.000000                             0.976061   \n",
       "\n",
       "       question_body_critical  question_conversational  \\\n",
       "count              476.000000               476.000000   \n",
       "mean                 0.602740                 0.032761   \n",
       "std                  0.145066                 0.050820   \n",
       "min                  0.346997                 0.004337   \n",
       "25%                  0.470893                 0.008803   \n",
       "50%                  0.588653                 0.012706   \n",
       "75%                  0.732399                 0.028791   \n",
       "max                  0.899250                 0.386679   \n",
       "\n",
       "       question_expect_short_answer  question_fact_seeking  \\\n",
       "count                    476.000000             476.000000   \n",
       "mean                       0.751046               0.811013   \n",
       "std                        0.087136               0.089694   \n",
       "min                        0.382506               0.459894   \n",
       "25%                        0.704890               0.770341   \n",
       "50%                        0.752669               0.820246   \n",
       "75%                        0.800828               0.871122   \n",
       "max                        0.963952               0.974981   \n",
       "\n",
       "       question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "count                             476.000000                       476.000000   \n",
       "mean                                0.861495                         0.576797   \n",
       "std                                 0.112949                         0.052694   \n",
       "min                                 0.231130                         0.485198   \n",
       "25%                                 0.846749                         0.533908   \n",
       "50%                                 0.904952                         0.566549   \n",
       "75%                                 0.927567                         0.614897   \n",
       "max                                 0.970100                         0.716034   \n",
       "\n",
       "       question_interestingness_self  question_multi_intent  ...  \\\n",
       "count                     476.000000             476.000000  ...   \n",
       "mean                        0.487319               0.197883  ...   \n",
       "std                         0.087300               0.168569  ...   \n",
       "min                         0.358900               0.014039  ...   \n",
       "25%                         0.420819               0.070075  ...   \n",
       "50%                         0.457755               0.135823  ...   \n",
       "75%                         0.542505               0.289610  ...   \n",
       "max                         0.734911               0.796849  ...   \n",
       "\n",
       "       question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "count             476.000000      476.000000                   476.000000   \n",
       "mean                0.785990        0.934192                     0.665800   \n",
       "std                 0.096134        0.023018                     0.037592   \n",
       "min                 0.574367        0.810831                     0.547739   \n",
       "25%                 0.700773        0.921485                     0.640350   \n",
       "50%                 0.781937        0.939276                     0.664306   \n",
       "75%                 0.878785        0.950283                     0.689043   \n",
       "max                 0.959722        0.977856                     0.786994   \n",
       "\n",
       "       answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "count        476.000000        476.000000           476.000000   \n",
       "mean           0.964078          0.972931             0.869153   \n",
       "std            0.011884          0.010704             0.033756   \n",
       "min            0.908454          0.901203             0.737421   \n",
       "25%            0.958518          0.968029             0.851144   \n",
       "50%            0.966194          0.975025             0.872678   \n",
       "75%            0.972222          0.980509             0.892696   \n",
       "max            0.983402          0.990115             0.939564   \n",
       "\n",
       "       answer_type_instructions  answer_type_procedure  \\\n",
       "count                476.000000             476.000000   \n",
       "mean                   0.497816               0.134083   \n",
       "std                    0.301487               0.057888   \n",
       "min                    0.008252               0.012815   \n",
       "25%                    0.191527               0.095463   \n",
       "50%                    0.581506               0.137654   \n",
       "75%                    0.771623               0.174161   \n",
       "max                    0.933787               0.305896   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                      476.000000           476.000000  \n",
       "mean                         0.510610             0.903609  \n",
       "std                          0.252673             0.022140  \n",
       "min                          0.061005             0.832567  \n",
       "25%                          0.290739             0.889493  \n",
       "50%                          0.504803             0.905576  \n",
       "75%                          0.725493             0.919333  \n",
       "max                          0.976253             0.953157  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "submission[target_cols] = Y_test\n",
    "\n",
    "\n",
    "# n=test['url'].apply(lambda x:(('ell.stackexchange.com' in x) or ('english.stackexchange.com' in x))).tolist()\n",
    "# spelling=[]\n",
    "# for x in n:\n",
    "#     if x:\n",
    "#         spelling.append(0.5)\n",
    "#     else:\n",
    "#         spelling.append(0.)\n",
    "        \n",
    "# submission['question_type_spelling']=spelling\n",
    "\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "display(submission.head())\n",
    "display(submission.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
