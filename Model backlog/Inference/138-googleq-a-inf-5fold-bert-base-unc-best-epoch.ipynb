{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import warnings\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D, SpatialDropout1D, Concatenate\n",
    "from googleqa_utilityscript import *\n",
    "from googleqa_map_utilityscript import *\n",
    "import bert_tokenization as tokenization\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to predict:\n",
      "/kaggle/input/138bert-base-best/138-BERT_base_uncased_model_fold_1.h5\n",
      "/kaggle/input/138bert-base-best/138-BERT_base_uncased_model_fold_2.h5\n",
      "/kaggle/input/138bert-base-best/138-BERT_base_uncased_model_fold_3.h5\n",
      "/kaggle/input/138bert-base-best/138-BERT_base_uncased_model_fold_4.h5\n",
      "/kaggle/input/138bert-base-best/138-BERT_base_uncased_model_fold_5.h5\n",
      "Test samples: 476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BERT_PATH = '/kaggle/input/tf-hub-bert-base/bert_base_uncased'\n",
    "VOCAB_PATH = BERT_PATH + '/assets/vocab.txt'\n",
    "model_path_list = glob.glob('/kaggle/input/138bert-base-best/' + '*.h5')\n",
    "model_path_list.sort()\n",
    "print('Models to predict:')\n",
    "print(*model_path_list, sep = \"\\n\")\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "question_target_cols = ['question_asker_intent_understanding','question_body_critical', 'question_conversational', \n",
    "                        'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                        'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', \n",
    "                        'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                        'question_type_compare', 'question_type_consequence', 'question_type_definition', \n",
    "                        'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                        'question_type_reason_explanation', 'question_type_spelling', 'question_well_written']\n",
    "answer_target_cols = ['answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                      'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', \n",
    "                      'answer_type_reason_explanation', 'answer_well_written']\n",
    "target_cols = question_target_cols + answer_target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "### BERT auxiliar function\n",
    "def _get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_segments(tokens, max_seq_length, ignore_first_sep=True):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if ignore_first_sep:\n",
    "                ignore_first_sep = False \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, tokenizer, max_sequence_length, \n",
    "                t_max_len=30, q_max_len=239, a_max_len=239):\n",
    "    \n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "            \n",
    "\n",
    "        t = t[:t_new_len//2] + t[-t_new_len//2:]\n",
    "        q = q[:q_new_len//2] + q[-q_new_len//2:]\n",
    "        a = a[:a_new_len//2] + a[-a_new_len//2:]\n",
    "\n",
    "    return t, q, a\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, tokenizer, max_sequence_length, ignore_first_sep=True):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    \n",
    "    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "\n",
    "    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n",
    "    input_masks = _get_masks(stoken, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken, max_sequence_length, ignore_first_sep)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "def compute_input_arays(df, columns, tokenizer, max_sequence_length, ignore_first_sep=True):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for _, instance in df[columns].iterrows():\n",
    "        t, q, a = instance.question_title, instance.question_body, instance.answer\n",
    "\n",
    "        t, q, a = _trim_input(t, q, a, tokenizer, max_sequence_length)\n",
    "\n",
    "        ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length, ignore_first_sep)\n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_segments.append(segments)\n",
    "        \n",
    "    return [np.asarray(input_ids, dtype=np.int32), \n",
    "            np.asarray(input_masks, dtype=np.int32), \n",
    "            np.asarray(input_segments, dtype=np.int32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['question_title', 'question_body', 'answer']\n",
    "\n",
    "# for feature in text_features:\n",
    "#     # Lower\n",
    "#     test[feature] = test[feature].apply(lambda x: x.lower())\n",
    "#     # Map misspellings\n",
    "#     test[feature] = test[feature].apply(lambda x: map_misspellings(x))\n",
    "#     # Map contractions\n",
    "#     test[feature] = test[feature].apply(lambda x: map_contraction(x))\n",
    "#     # Trim text\n",
    "#     test[feature] = test[feature].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "N_CLASS = len(target_cols)\n",
    "MAX_SEQUENCE_LENGTH = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(VOCAB_PATH, do_lower_case=True)\n",
    "\n",
    "# Test features\n",
    "X_test = compute_input_arays(test, text_features, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    input_word_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    segment_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids')\n",
    "\n",
    "    bert_layer = KerasLayer(BERT_PATH, trainable=False)\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_masks, segment_ids])\n",
    "\n",
    "    x = GlobalAveragePooling1D()(sequence_output)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(N_CLASS, activation=\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "    model = Model(inputs=[input_word_ids, input_masks, segment_ids], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.zeros((len(test), N_CLASS))\n",
    "\n",
    "for model_path in model_path_list:\n",
    "    model = model_fn()\n",
    "    model.load_weights(model_path)\n",
    "    Y_test += model.predict(X_test) / len(model_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.936441</td>\n",
       "      <td>0.619144</td>\n",
       "      <td>0.296912</td>\n",
       "      <td>0.476972</td>\n",
       "      <td>0.519930</td>\n",
       "      <td>0.461609</td>\n",
       "      <td>0.658736</td>\n",
       "      <td>0.654583</td>\n",
       "      <td>0.577389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872172</td>\n",
       "      <td>0.892197</td>\n",
       "      <td>0.581031</td>\n",
       "      <td>0.952966</td>\n",
       "      <td>0.956080</td>\n",
       "      <td>0.789677</td>\n",
       "      <td>0.067903</td>\n",
       "      <td>0.065870</td>\n",
       "      <td>0.816865</td>\n",
       "      <td>0.913863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.885324</td>\n",
       "      <td>0.529124</td>\n",
       "      <td>0.007807</td>\n",
       "      <td>0.732602</td>\n",
       "      <td>0.770993</td>\n",
       "      <td>0.904441</td>\n",
       "      <td>0.542038</td>\n",
       "      <td>0.480350</td>\n",
       "      <td>0.076268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737575</td>\n",
       "      <td>0.950339</td>\n",
       "      <td>0.678365</td>\n",
       "      <td>0.968575</td>\n",
       "      <td>0.981087</td>\n",
       "      <td>0.877730</td>\n",
       "      <td>0.879669</td>\n",
       "      <td>0.122407</td>\n",
       "      <td>0.105658</td>\n",
       "      <td>0.883651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.924776</td>\n",
       "      <td>0.678599</td>\n",
       "      <td>0.046863</td>\n",
       "      <td>0.753826</td>\n",
       "      <td>0.808090</td>\n",
       "      <td>0.893982</td>\n",
       "      <td>0.589081</td>\n",
       "      <td>0.501755</td>\n",
       "      <td>0.148041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855471</td>\n",
       "      <td>0.939754</td>\n",
       "      <td>0.660558</td>\n",
       "      <td>0.969681</td>\n",
       "      <td>0.974934</td>\n",
       "      <td>0.868690</td>\n",
       "      <td>0.081116</td>\n",
       "      <td>0.062574</td>\n",
       "      <td>0.866793</td>\n",
       "      <td>0.927113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.869061</td>\n",
       "      <td>0.435703</td>\n",
       "      <td>0.008510</td>\n",
       "      <td>0.707919</td>\n",
       "      <td>0.774891</td>\n",
       "      <td>0.921134</td>\n",
       "      <td>0.544381</td>\n",
       "      <td>0.396891</td>\n",
       "      <td>0.163151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689278</td>\n",
       "      <td>0.956683</td>\n",
       "      <td>0.685693</td>\n",
       "      <td>0.970425</td>\n",
       "      <td>0.982646</td>\n",
       "      <td>0.896638</td>\n",
       "      <td>0.801130</td>\n",
       "      <td>0.170841</td>\n",
       "      <td>0.572138</td>\n",
       "      <td>0.910236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.928903</td>\n",
       "      <td>0.448742</td>\n",
       "      <td>0.063769</td>\n",
       "      <td>0.779217</td>\n",
       "      <td>0.678145</td>\n",
       "      <td>0.756431</td>\n",
       "      <td>0.627143</td>\n",
       "      <td>0.583408</td>\n",
       "      <td>0.096555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718931</td>\n",
       "      <td>0.912714</td>\n",
       "      <td>0.647974</td>\n",
       "      <td>0.965031</td>\n",
       "      <td>0.967789</td>\n",
       "      <td>0.839897</td>\n",
       "      <td>0.125299</td>\n",
       "      <td>0.101368</td>\n",
       "      <td>0.698383</td>\n",
       "      <td>0.914914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.936441                0.619144   \n",
       "1     46                             0.885324                0.529124   \n",
       "2     70                             0.924776                0.678599   \n",
       "3    132                             0.869061                0.435703   \n",
       "4    200                             0.928903                0.448742   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.296912                      0.476972   \n",
       "1                 0.007807                      0.732602   \n",
       "2                 0.046863                      0.753826   \n",
       "3                 0.008510                      0.707919   \n",
       "4                 0.063769                      0.779217   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.519930                               0.461609   \n",
       "1               0.770993                               0.904441   \n",
       "2               0.808090                               0.893982   \n",
       "3               0.774891                               0.921134   \n",
       "4               0.678145                               0.756431   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.658736                       0.654583   \n",
       "1                         0.542038                       0.480350   \n",
       "2                         0.589081                       0.501755   \n",
       "3                         0.544381                       0.396891   \n",
       "4                         0.627143                       0.583408   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.577389  ...               0.872172        0.892197   \n",
       "1               0.076268  ...               0.737575        0.950339   \n",
       "2               0.148041  ...               0.855471        0.939754   \n",
       "3               0.163151  ...               0.689278        0.956683   \n",
       "4               0.096555  ...               0.718931        0.912714   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.581031          0.952966          0.956080   \n",
       "1                     0.678365          0.968575          0.981087   \n",
       "2                     0.660558          0.969681          0.974934   \n",
       "3                     0.685693          0.970425          0.982646   \n",
       "4                     0.647974          0.965031          0.967789   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.789677                  0.067903               0.065870   \n",
       "1             0.877730                  0.879669               0.122407   \n",
       "2             0.868690                  0.081116               0.062574   \n",
       "3             0.896638                  0.801130               0.170841   \n",
       "4             0.839897                  0.125299               0.101368   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.816865             0.913863  \n",
       "1                        0.105658             0.883651  \n",
       "2                        0.866793             0.927113  \n",
       "3                        0.572138             0.910236  \n",
       "4                        0.698383             0.914914  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5029.186975</td>\n",
       "      <td>0.897482</td>\n",
       "      <td>0.591049</td>\n",
       "      <td>0.043985</td>\n",
       "      <td>0.701021</td>\n",
       "      <td>0.783380</td>\n",
       "      <td>0.827281</td>\n",
       "      <td>0.573644</td>\n",
       "      <td>0.485740</td>\n",
       "      <td>0.247758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797069</td>\n",
       "      <td>0.936028</td>\n",
       "      <td>0.666715</td>\n",
       "      <td>0.964068</td>\n",
       "      <td>0.974629</td>\n",
       "      <td>0.869868</td>\n",
       "      <td>0.461689</td>\n",
       "      <td>0.136979</td>\n",
       "      <td>0.567737</td>\n",
       "      <td>0.913387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2812.670060</td>\n",
       "      <td>0.038237</td>\n",
       "      <td>0.123355</td>\n",
       "      <td>0.069599</td>\n",
       "      <td>0.096868</td>\n",
       "      <td>0.103170</td>\n",
       "      <td>0.136868</td>\n",
       "      <td>0.046396</td>\n",
       "      <td>0.084156</td>\n",
       "      <td>0.195096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074043</td>\n",
       "      <td>0.019189</td>\n",
       "      <td>0.041462</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.008686</td>\n",
       "      <td>0.031354</td>\n",
       "      <td>0.300523</td>\n",
       "      <td>0.060833</td>\n",
       "      <td>0.253978</td>\n",
       "      <td>0.017145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.775933</td>\n",
       "      <td>0.364444</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>0.279680</td>\n",
       "      <td>0.344754</td>\n",
       "      <td>0.288027</td>\n",
       "      <td>0.466577</td>\n",
       "      <td>0.327801</td>\n",
       "      <td>0.012897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606198</td>\n",
       "      <td>0.829442</td>\n",
       "      <td>0.543782</td>\n",
       "      <td>0.917967</td>\n",
       "      <td>0.924838</td>\n",
       "      <td>0.744326</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>0.014270</td>\n",
       "      <td>0.047957</td>\n",
       "      <td>0.855241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2572.000000</td>\n",
       "      <td>0.872381</td>\n",
       "      <td>0.480560</td>\n",
       "      <td>0.009882</td>\n",
       "      <td>0.646482</td>\n",
       "      <td>0.738697</td>\n",
       "      <td>0.799923</td>\n",
       "      <td>0.538583</td>\n",
       "      <td>0.419624</td>\n",
       "      <td>0.093382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736508</td>\n",
       "      <td>0.925322</td>\n",
       "      <td>0.639376</td>\n",
       "      <td>0.959163</td>\n",
       "      <td>0.970283</td>\n",
       "      <td>0.851014</td>\n",
       "      <td>0.126771</td>\n",
       "      <td>0.094624</td>\n",
       "      <td>0.367172</td>\n",
       "      <td>0.903112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5093.000000</td>\n",
       "      <td>0.900096</td>\n",
       "      <td>0.581762</td>\n",
       "      <td>0.016647</td>\n",
       "      <td>0.706105</td>\n",
       "      <td>0.798101</td>\n",
       "      <td>0.881363</td>\n",
       "      <td>0.568557</td>\n",
       "      <td>0.465748</td>\n",
       "      <td>0.177560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801623</td>\n",
       "      <td>0.939183</td>\n",
       "      <td>0.664047</td>\n",
       "      <td>0.965722</td>\n",
       "      <td>0.976093</td>\n",
       "      <td>0.872914</td>\n",
       "      <td>0.509176</td>\n",
       "      <td>0.135416</td>\n",
       "      <td>0.586236</td>\n",
       "      <td>0.915717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7482.000000</td>\n",
       "      <td>0.926793</td>\n",
       "      <td>0.685385</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.763604</td>\n",
       "      <td>0.852064</td>\n",
       "      <td>0.913242</td>\n",
       "      <td>0.604528</td>\n",
       "      <td>0.531227</td>\n",
       "      <td>0.370891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862231</td>\n",
       "      <td>0.950204</td>\n",
       "      <td>0.693677</td>\n",
       "      <td>0.970323</td>\n",
       "      <td>0.981235</td>\n",
       "      <td>0.892897</td>\n",
       "      <td>0.734055</td>\n",
       "      <td>0.180348</td>\n",
       "      <td>0.779360</td>\n",
       "      <td>0.926156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9640.000000</td>\n",
       "      <td>0.970873</td>\n",
       "      <td>0.891955</td>\n",
       "      <td>0.574965</td>\n",
       "      <td>0.940241</td>\n",
       "      <td>0.963632</td>\n",
       "      <td>0.962407</td>\n",
       "      <td>0.686557</td>\n",
       "      <td>0.717792</td>\n",
       "      <td>0.797359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947426</td>\n",
       "      <td>0.974030</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.982538</td>\n",
       "      <td>0.989151</td>\n",
       "      <td>0.946551</td>\n",
       "      <td>0.923018</td>\n",
       "      <td>0.302771</td>\n",
       "      <td>0.984955</td>\n",
       "      <td>0.951871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qa_id  question_asker_intent_understanding  \\\n",
       "count   476.000000                           476.000000   \n",
       "mean   5029.186975                             0.897482   \n",
       "std    2812.670060                             0.038237   \n",
       "min      39.000000                             0.775933   \n",
       "25%    2572.000000                             0.872381   \n",
       "50%    5093.000000                             0.900096   \n",
       "75%    7482.000000                             0.926793   \n",
       "max    9640.000000                             0.970873   \n",
       "\n",
       "       question_body_critical  question_conversational  \\\n",
       "count              476.000000               476.000000   \n",
       "mean                 0.591049                 0.043985   \n",
       "std                  0.123355                 0.069599   \n",
       "min                  0.364444                 0.004288   \n",
       "25%                  0.480560                 0.009882   \n",
       "50%                  0.581762                 0.016647   \n",
       "75%                  0.685385                 0.041016   \n",
       "max                  0.891955                 0.574965   \n",
       "\n",
       "       question_expect_short_answer  question_fact_seeking  \\\n",
       "count                    476.000000             476.000000   \n",
       "mean                       0.701021               0.783380   \n",
       "std                        0.096868               0.103170   \n",
       "min                        0.279680               0.344754   \n",
       "25%                        0.646482               0.738697   \n",
       "50%                        0.706105               0.798101   \n",
       "75%                        0.763604               0.852064   \n",
       "max                        0.940241               0.963632   \n",
       "\n",
       "       question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "count                             476.000000                       476.000000   \n",
       "mean                                0.827281                         0.573644   \n",
       "std                                 0.136868                         0.046396   \n",
       "min                                 0.288027                         0.466577   \n",
       "25%                                 0.799923                         0.538583   \n",
       "50%                                 0.881363                         0.568557   \n",
       "75%                                 0.913242                         0.604528   \n",
       "max                                 0.962407                         0.686557   \n",
       "\n",
       "       question_interestingness_self  question_multi_intent  ...  \\\n",
       "count                     476.000000             476.000000  ...   \n",
       "mean                        0.485740               0.247758  ...   \n",
       "std                         0.084156               0.195096  ...   \n",
       "min                         0.327801               0.012897  ...   \n",
       "25%                         0.419624               0.093382  ...   \n",
       "50%                         0.465748               0.177560  ...   \n",
       "75%                         0.531227               0.370891  ...   \n",
       "max                         0.717792               0.797359  ...   \n",
       "\n",
       "       question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "count             476.000000      476.000000                   476.000000   \n",
       "mean                0.797069        0.936028                     0.666715   \n",
       "std                 0.074043        0.019189                     0.041462   \n",
       "min                 0.606198        0.829442                     0.543782   \n",
       "25%                 0.736508        0.925322                     0.639376   \n",
       "50%                 0.801623        0.939183                     0.664047   \n",
       "75%                 0.862231        0.950204                     0.693677   \n",
       "max                 0.947426        0.974030                     0.796296   \n",
       "\n",
       "       answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "count        476.000000        476.000000           476.000000   \n",
       "mean           0.964068          0.974629             0.869868   \n",
       "std            0.009367          0.008686             0.031354   \n",
       "min            0.917967          0.924838             0.744326   \n",
       "25%            0.959163          0.970283             0.851014   \n",
       "50%            0.965722          0.976093             0.872914   \n",
       "75%            0.970323          0.981235             0.892897   \n",
       "max            0.982538          0.989151             0.946551   \n",
       "\n",
       "       answer_type_instructions  answer_type_procedure  \\\n",
       "count                476.000000             476.000000   \n",
       "mean                   0.461689               0.136979   \n",
       "std                    0.300523               0.060833   \n",
       "min                    0.010196               0.014270   \n",
       "25%                    0.126771               0.094624   \n",
       "50%                    0.509176               0.135416   \n",
       "75%                    0.734055               0.180348   \n",
       "max                    0.923018               0.302771   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                      476.000000           476.000000  \n",
       "mean                         0.567737             0.913387  \n",
       "std                          0.253978             0.017145  \n",
       "min                          0.047957             0.855241  \n",
       "25%                          0.367172             0.903112  \n",
       "50%                          0.586236             0.915717  \n",
       "75%                          0.779360             0.926156  \n",
       "max                          0.984955             0.951871  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "submission[target_cols] = Y_test\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "display(submission.head())\n",
    "display(submission.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
