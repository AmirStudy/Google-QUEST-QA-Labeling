{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import warnings\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D, SpatialDropout1D, Concatenate\n",
    "from googleqa_utilityscript import *\n",
    "from googleqa_map_utilityscript import *\n",
    "import bert_tokenization as tokenization\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to predict: ['/kaggle/input/121-googleq-a-train-3fold-bert-base-unc-categoryv2/model_fold_1.h5', '/kaggle/input/121-googleq-a-train-3fold-bert-base-unc-categoryv2/model_fold_2.h5', '/kaggle/input/121-googleq-a-train-3fold-bert-base-unc-categoryv2/model_fold_3.h5']\n",
      "Test samples: 476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BERT_PATH = '/kaggle/input/tf-hub-bert-base/bert_base_uncased'\n",
    "VOCAB_PATH = BERT_PATH + '/assets/vocab.txt'\n",
    "model_path_list = glob.glob('/kaggle/input/121-googleq-a-train-3fold-bert-base-unc-categoryv2/' + '*.h5')\n",
    "model_path_list.sort()\n",
    "print('Models to predict:', model_path_list)\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "question_target_cols = ['question_asker_intent_understanding','question_body_critical', 'question_conversational', \n",
    "                        'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                        'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', \n",
    "                        'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                        'question_type_compare', 'question_type_consequence', 'question_type_definition', \n",
    "                        'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                        'question_type_reason_explanation', 'question_type_spelling', 'question_well_written']\n",
    "answer_target_cols = ['answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                      'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', \n",
    "                      'answer_type_reason_explanation', 'answer_well_written']\n",
    "target_cols = question_target_cols + answer_target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['question_title', 'question_body', 'answer']\n",
    "    \n",
    "for feature in text_features:\n",
    "    # Lower\n",
    "    test[feature] = test[feature].apply(lambda x: x.lower())\n",
    "    # Map misspellings\n",
    "    test[feature] = test[feature].apply(lambda x: map_misspellings(x))\n",
    "    # Map contractions\n",
    "    test[feature] = test[feature].apply(lambda x: map_contraction(x))\n",
    "    # Trim text\n",
    "    test[feature] = test[feature].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "N_CLASS = len(target_cols)\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "N_CLASS_CAT = test['category'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(VOCAB_PATH, do_lower_case=True)\n",
    "\n",
    "# Test features\n",
    "X_test = compute_input_arays(test, text_features, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    input_word_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    segment_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids')\n",
    "\n",
    "    bert_layer = KerasLayer(BERT_PATH, trainable=True)\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_masks, segment_ids])\n",
    "\n",
    "    x = GlobalAveragePooling1D()(sequence_output)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output_seq = Dense(N_CLASS, activation=\"sigmoid\", name=\"output_seq\")(x)\n",
    "    output_class = Dense(N_CLASS_CAT, activation=\"softmax\", name=\"output_class\")(pooled_output)\n",
    "\n",
    "    model = Model(inputs=[input_word_ids, input_masks, segment_ids], outputs=[output_seq, output_class])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.zeros((len(test), N_CLASS))\n",
    "\n",
    "for model_path in model_path_list:\n",
    "    model = model_fn()\n",
    "    model.load_weights(model_path)\n",
    "    Y_test += model.predict(X_test)[0][: ,:N_CLASS] / len(model_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.927318</td>\n",
       "      <td>0.648074</td>\n",
       "      <td>0.188183</td>\n",
       "      <td>0.549473</td>\n",
       "      <td>0.647343</td>\n",
       "      <td>0.552432</td>\n",
       "      <td>0.679916</td>\n",
       "      <td>0.609298</td>\n",
       "      <td>0.528219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900496</td>\n",
       "      <td>0.917316</td>\n",
       "      <td>0.571571</td>\n",
       "      <td>0.963811</td>\n",
       "      <td>0.968182</td>\n",
       "      <td>0.839239</td>\n",
       "      <td>0.098133</td>\n",
       "      <td>0.079360</td>\n",
       "      <td>0.804632</td>\n",
       "      <td>0.928977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.890666</td>\n",
       "      <td>0.510079</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.774297</td>\n",
       "      <td>0.794132</td>\n",
       "      <td>0.898136</td>\n",
       "      <td>0.522293</td>\n",
       "      <td>0.446752</td>\n",
       "      <td>0.065875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680737</td>\n",
       "      <td>0.940899</td>\n",
       "      <td>0.689133</td>\n",
       "      <td>0.962950</td>\n",
       "      <td>0.973353</td>\n",
       "      <td>0.855647</td>\n",
       "      <td>0.843525</td>\n",
       "      <td>0.128690</td>\n",
       "      <td>0.160521</td>\n",
       "      <td>0.862972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.903183</td>\n",
       "      <td>0.688351</td>\n",
       "      <td>0.044261</td>\n",
       "      <td>0.815174</td>\n",
       "      <td>0.864589</td>\n",
       "      <td>0.870652</td>\n",
       "      <td>0.588024</td>\n",
       "      <td>0.515661</td>\n",
       "      <td>0.157142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857526</td>\n",
       "      <td>0.939980</td>\n",
       "      <td>0.626533</td>\n",
       "      <td>0.975558</td>\n",
       "      <td>0.971689</td>\n",
       "      <td>0.900728</td>\n",
       "      <td>0.149604</td>\n",
       "      <td>0.062612</td>\n",
       "      <td>0.811012</td>\n",
       "      <td>0.924597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.852068</td>\n",
       "      <td>0.447859</td>\n",
       "      <td>0.008957</td>\n",
       "      <td>0.675882</td>\n",
       "      <td>0.793259</td>\n",
       "      <td>0.916768</td>\n",
       "      <td>0.532428</td>\n",
       "      <td>0.412811</td>\n",
       "      <td>0.171386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695490</td>\n",
       "      <td>0.936860</td>\n",
       "      <td>0.642420</td>\n",
       "      <td>0.967879</td>\n",
       "      <td>0.980709</td>\n",
       "      <td>0.873658</td>\n",
       "      <td>0.844188</td>\n",
       "      <td>0.191634</td>\n",
       "      <td>0.304431</td>\n",
       "      <td>0.882380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.923497</td>\n",
       "      <td>0.557812</td>\n",
       "      <td>0.081830</td>\n",
       "      <td>0.788583</td>\n",
       "      <td>0.765091</td>\n",
       "      <td>0.706744</td>\n",
       "      <td>0.672137</td>\n",
       "      <td>0.608310</td>\n",
       "      <td>0.117711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770093</td>\n",
       "      <td>0.931089</td>\n",
       "      <td>0.633912</td>\n",
       "      <td>0.967759</td>\n",
       "      <td>0.960853</td>\n",
       "      <td>0.854578</td>\n",
       "      <td>0.134477</td>\n",
       "      <td>0.072941</td>\n",
       "      <td>0.598993</td>\n",
       "      <td>0.920742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.927318                0.648074   \n",
       "1     46                             0.890666                0.510079   \n",
       "2     70                             0.903183                0.688351   \n",
       "3    132                             0.852068                0.447859   \n",
       "4    200                             0.923497                0.557812   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.188183                      0.549473   \n",
       "1                 0.009587                      0.774297   \n",
       "2                 0.044261                      0.815174   \n",
       "3                 0.008957                      0.675882   \n",
       "4                 0.081830                      0.788583   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.647343                               0.552432   \n",
       "1               0.794132                               0.898136   \n",
       "2               0.864589                               0.870652   \n",
       "3               0.793259                               0.916768   \n",
       "4               0.765091                               0.706744   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.679916                       0.609298   \n",
       "1                         0.522293                       0.446752   \n",
       "2                         0.588024                       0.515661   \n",
       "3                         0.532428                       0.412811   \n",
       "4                         0.672137                       0.608310   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.528219  ...               0.900496        0.917316   \n",
       "1               0.065875  ...               0.680737        0.940899   \n",
       "2               0.157142  ...               0.857526        0.939980   \n",
       "3               0.171386  ...               0.695490        0.936860   \n",
       "4               0.117711  ...               0.770093        0.931089   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.571571          0.963811          0.968182   \n",
       "1                     0.689133          0.962950          0.973353   \n",
       "2                     0.626533          0.975558          0.971689   \n",
       "3                     0.642420          0.967879          0.980709   \n",
       "4                     0.633912          0.967759          0.960853   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.839239                  0.098133               0.079360   \n",
       "1             0.855647                  0.843525               0.128690   \n",
       "2             0.900728                  0.149604               0.062612   \n",
       "3             0.873658                  0.844188               0.191634   \n",
       "4             0.854578                  0.134477               0.072941   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.804632             0.928977  \n",
       "1                        0.160521             0.862972  \n",
       "2                        0.811012             0.924597  \n",
       "3                        0.304431             0.882380  \n",
       "4                        0.598993             0.920742  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5029.186975</td>\n",
       "      <td>0.884160</td>\n",
       "      <td>0.585380</td>\n",
       "      <td>0.039579</td>\n",
       "      <td>0.703697</td>\n",
       "      <td>0.797637</td>\n",
       "      <td>0.832838</td>\n",
       "      <td>0.579008</td>\n",
       "      <td>0.483830</td>\n",
       "      <td>0.224793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786594</td>\n",
       "      <td>0.929275</td>\n",
       "      <td>0.653971</td>\n",
       "      <td>0.963337</td>\n",
       "      <td>0.971376</td>\n",
       "      <td>0.860341</td>\n",
       "      <td>0.523948</td>\n",
       "      <td>0.133918</td>\n",
       "      <td>0.474017</td>\n",
       "      <td>0.898865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2812.670060</td>\n",
       "      <td>0.034457</td>\n",
       "      <td>0.100851</td>\n",
       "      <td>0.052361</td>\n",
       "      <td>0.090610</td>\n",
       "      <td>0.077999</td>\n",
       "      <td>0.114371</td>\n",
       "      <td>0.051252</td>\n",
       "      <td>0.077467</td>\n",
       "      <td>0.151413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075457</td>\n",
       "      <td>0.014524</td>\n",
       "      <td>0.036551</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>0.008327</td>\n",
       "      <td>0.025474</td>\n",
       "      <td>0.296727</td>\n",
       "      <td>0.055416</td>\n",
       "      <td>0.240766</td>\n",
       "      <td>0.020689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.795538</td>\n",
       "      <td>0.412963</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.324407</td>\n",
       "      <td>0.457242</td>\n",
       "      <td>0.301544</td>\n",
       "      <td>0.483895</td>\n",
       "      <td>0.377441</td>\n",
       "      <td>0.017160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595750</td>\n",
       "      <td>0.869625</td>\n",
       "      <td>0.532805</td>\n",
       "      <td>0.935359</td>\n",
       "      <td>0.936471</td>\n",
       "      <td>0.774565</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.017963</td>\n",
       "      <td>0.062735</td>\n",
       "      <td>0.836225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2572.000000</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.496742</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>0.652429</td>\n",
       "      <td>0.756927</td>\n",
       "      <td>0.796876</td>\n",
       "      <td>0.535858</td>\n",
       "      <td>0.426275</td>\n",
       "      <td>0.103137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723651</td>\n",
       "      <td>0.921119</td>\n",
       "      <td>0.631361</td>\n",
       "      <td>0.959306</td>\n",
       "      <td>0.965943</td>\n",
       "      <td>0.843265</td>\n",
       "      <td>0.225150</td>\n",
       "      <td>0.088565</td>\n",
       "      <td>0.269487</td>\n",
       "      <td>0.884710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5093.000000</td>\n",
       "      <td>0.882224</td>\n",
       "      <td>0.575527</td>\n",
       "      <td>0.017827</td>\n",
       "      <td>0.702738</td>\n",
       "      <td>0.800528</td>\n",
       "      <td>0.875669</td>\n",
       "      <td>0.570938</td>\n",
       "      <td>0.454850</td>\n",
       "      <td>0.183913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793377</td>\n",
       "      <td>0.931320</td>\n",
       "      <td>0.655637</td>\n",
       "      <td>0.963836</td>\n",
       "      <td>0.972358</td>\n",
       "      <td>0.863159</td>\n",
       "      <td>0.612566</td>\n",
       "      <td>0.137658</td>\n",
       "      <td>0.432381</td>\n",
       "      <td>0.898905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7482.000000</td>\n",
       "      <td>0.910232</td>\n",
       "      <td>0.660316</td>\n",
       "      <td>0.047617</td>\n",
       "      <td>0.759714</td>\n",
       "      <td>0.853434</td>\n",
       "      <td>0.909505</td>\n",
       "      <td>0.614616</td>\n",
       "      <td>0.517751</td>\n",
       "      <td>0.313128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853824</td>\n",
       "      <td>0.939697</td>\n",
       "      <td>0.677024</td>\n",
       "      <td>0.967997</td>\n",
       "      <td>0.977760</td>\n",
       "      <td>0.877824</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.173856</td>\n",
       "      <td>0.663485</td>\n",
       "      <td>0.915644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9640.000000</td>\n",
       "      <td>0.966939</td>\n",
       "      <td>0.850033</td>\n",
       "      <td>0.338420</td>\n",
       "      <td>0.947374</td>\n",
       "      <td>0.948769</td>\n",
       "      <td>0.962665</td>\n",
       "      <td>0.723029</td>\n",
       "      <td>0.722829</td>\n",
       "      <td>0.723845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933316</td>\n",
       "      <td>0.964702</td>\n",
       "      <td>0.764418</td>\n",
       "      <td>0.979458</td>\n",
       "      <td>0.986838</td>\n",
       "      <td>0.923974</td>\n",
       "      <td>0.894892</td>\n",
       "      <td>0.291299</td>\n",
       "      <td>0.955046</td>\n",
       "      <td>0.947321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qa_id  question_asker_intent_understanding  \\\n",
       "count   476.000000                           476.000000   \n",
       "mean   5029.186975                             0.884160   \n",
       "std    2812.670060                             0.034457   \n",
       "min      39.000000                             0.795538   \n",
       "25%    2572.000000                             0.856061   \n",
       "50%    5093.000000                             0.882224   \n",
       "75%    7482.000000                             0.910232   \n",
       "max    9640.000000                             0.966939   \n",
       "\n",
       "       question_body_critical  question_conversational  \\\n",
       "count              476.000000               476.000000   \n",
       "mean                 0.585380                 0.039579   \n",
       "std                  0.100851                 0.052361   \n",
       "min                  0.412963                 0.004766   \n",
       "25%                  0.496742                 0.010337   \n",
       "50%                  0.575527                 0.017827   \n",
       "75%                  0.660316                 0.047617   \n",
       "max                  0.850033                 0.338420   \n",
       "\n",
       "       question_expect_short_answer  question_fact_seeking  \\\n",
       "count                    476.000000             476.000000   \n",
       "mean                       0.703697               0.797637   \n",
       "std                        0.090610               0.077999   \n",
       "min                        0.324407               0.457242   \n",
       "25%                        0.652429               0.756927   \n",
       "50%                        0.702738               0.800528   \n",
       "75%                        0.759714               0.853434   \n",
       "max                        0.947374               0.948769   \n",
       "\n",
       "       question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "count                             476.000000                       476.000000   \n",
       "mean                                0.832838                         0.579008   \n",
       "std                                 0.114371                         0.051252   \n",
       "min                                 0.301544                         0.483895   \n",
       "25%                                 0.796876                         0.535858   \n",
       "50%                                 0.875669                         0.570938   \n",
       "75%                                 0.909505                         0.614616   \n",
       "max                                 0.962665                         0.723029   \n",
       "\n",
       "       question_interestingness_self  question_multi_intent  ...  \\\n",
       "count                     476.000000             476.000000  ...   \n",
       "mean                        0.483830               0.224793  ...   \n",
       "std                         0.077467               0.151413  ...   \n",
       "min                         0.377441               0.017160  ...   \n",
       "25%                         0.426275               0.103137  ...   \n",
       "50%                         0.454850               0.183913  ...   \n",
       "75%                         0.517751               0.313128  ...   \n",
       "max                         0.722829               0.723845  ...   \n",
       "\n",
       "       question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "count             476.000000      476.000000                   476.000000   \n",
       "mean                0.786594        0.929275                     0.653971   \n",
       "std                 0.075457        0.014524                     0.036551   \n",
       "min                 0.595750        0.869625                     0.532805   \n",
       "25%                 0.723651        0.921119                     0.631361   \n",
       "50%                 0.793377        0.931320                     0.655637   \n",
       "75%                 0.853824        0.939697                     0.677024   \n",
       "max                 0.933316        0.964702                     0.764418   \n",
       "\n",
       "       answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "count        476.000000        476.000000           476.000000   \n",
       "mean           0.963337          0.971376             0.860341   \n",
       "std            0.007225          0.008327             0.025474   \n",
       "min            0.935359          0.936471             0.774565   \n",
       "25%            0.959306          0.965943             0.843265   \n",
       "50%            0.963836          0.972358             0.863159   \n",
       "75%            0.967997          0.977760             0.877824   \n",
       "max            0.979458          0.986838             0.923974   \n",
       "\n",
       "       answer_type_instructions  answer_type_procedure  \\\n",
       "count                476.000000             476.000000   \n",
       "mean                   0.523948               0.133918   \n",
       "std                    0.296727               0.055416   \n",
       "min                    0.011220               0.017963   \n",
       "25%                    0.225150               0.088565   \n",
       "50%                    0.612566               0.137658   \n",
       "75%                    0.800394               0.173856   \n",
       "max                    0.894892               0.291299   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                      476.000000           476.000000  \n",
       "mean                         0.474017             0.898865  \n",
       "std                          0.240766             0.020689  \n",
       "min                          0.062735             0.836225  \n",
       "25%                          0.269487             0.884710  \n",
       "50%                          0.432381             0.898905  \n",
       "75%                          0.663485             0.915644  \n",
       "max                          0.955046             0.947321  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "submission[target_cols] = Y_test\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "display(submission.head())\n",
    "display(submission.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
