{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import warnings\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D, SpatialDropout1D, Concatenate\n",
    "from googleqa_utilityscript import *\n",
    "from googleqa_map_utilityscript import *\n",
    "import bert_tokenization as tokenization\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to predict: ['/kaggle/input/122-googleq-a-train-3fold-bert-base-unc-categoryv3/model_fold_1.h5', '/kaggle/input/122-googleq-a-train-3fold-bert-base-unc-categoryv3/model_fold_2.h5', '/kaggle/input/122-googleq-a-train-3fold-bert-base-unc-categoryv3/model_fold_3.h5']\n",
      "Test samples: 476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BERT_PATH = '/kaggle/input/tf-hub-bert-base/bert_base_uncased'\n",
    "VOCAB_PATH = BERT_PATH + '/assets/vocab.txt'\n",
    "model_path_list = glob.glob('/kaggle/input/122-googleq-a-train-3fold-bert-base-unc-categoryv3/' + '*.h5')\n",
    "model_path_list.sort()\n",
    "print('Models to predict:', model_path_list)\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "question_target_cols = ['question_asker_intent_understanding','question_body_critical', 'question_conversational', \n",
    "                        'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                        'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', \n",
    "                        'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                        'question_type_compare', 'question_type_consequence', 'question_type_definition', \n",
    "                        'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                        'question_type_reason_explanation', 'question_type_spelling', 'question_well_written']\n",
    "answer_target_cols = ['answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                      'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', \n",
    "                      'answer_type_reason_explanation', 'answer_well_written']\n",
    "target_cols = question_target_cols + answer_target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['question_title', 'question_body', 'answer']\n",
    "    \n",
    "for feature in text_features:\n",
    "    # Lower\n",
    "    test[feature] = test[feature].apply(lambda x: x.lower())\n",
    "    # Map misspellings\n",
    "    test[feature] = test[feature].apply(lambda x: map_misspellings(x))\n",
    "    # Map contractions\n",
    "    test[feature] = test[feature].apply(lambda x: map_contraction(x))\n",
    "    # Trim text\n",
    "    test[feature] = test[feature].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "N_CLASS = len(target_cols)\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "N_CLASS_CAT = test['category'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(VOCAB_PATH, do_lower_case=True)\n",
    "\n",
    "# Test features\n",
    "X_test = compute_input_arays(test, text_features, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    input_word_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    segment_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids')\n",
    "\n",
    "    bert_layer = KerasLayer(BERT_PATH, trainable=True)\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_masks, segment_ids])\n",
    "\n",
    "    x = GlobalAveragePooling1D()(sequence_output)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output_seq = Dense(N_CLASS, activation=\"sigmoid\", name=\"output_seq\")(x)\n",
    "    output_class = Dense(N_CLASS_CAT, activation=\"softmax\", name=\"output_class\")(pooled_output)\n",
    "\n",
    "    model = Model(inputs=[input_word_ids, input_masks, segment_ids], outputs=[output_seq, output_class])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.zeros((len(test), N_CLASS))\n",
    "\n",
    "for model_path in model_path_list:\n",
    "    model = model_fn()\n",
    "    model.load_weights(model_path)\n",
    "    Y_test += model.predict(X_test)[0][: ,:N_CLASS] / len(model_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.932751</td>\n",
       "      <td>0.674821</td>\n",
       "      <td>0.119975</td>\n",
       "      <td>0.555536</td>\n",
       "      <td>0.662290</td>\n",
       "      <td>0.606968</td>\n",
       "      <td>0.674387</td>\n",
       "      <td>0.579693</td>\n",
       "      <td>0.507852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912704</td>\n",
       "      <td>0.923667</td>\n",
       "      <td>0.579044</td>\n",
       "      <td>0.967566</td>\n",
       "      <td>0.962791</td>\n",
       "      <td>0.826529</td>\n",
       "      <td>0.166110</td>\n",
       "      <td>0.054223</td>\n",
       "      <td>0.783755</td>\n",
       "      <td>0.928684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.886285</td>\n",
       "      <td>0.523687</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.757152</td>\n",
       "      <td>0.773529</td>\n",
       "      <td>0.900763</td>\n",
       "      <td>0.542357</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>0.064785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684753</td>\n",
       "      <td>0.947448</td>\n",
       "      <td>0.664143</td>\n",
       "      <td>0.958139</td>\n",
       "      <td>0.975366</td>\n",
       "      <td>0.880654</td>\n",
       "      <td>0.899054</td>\n",
       "      <td>0.099850</td>\n",
       "      <td>0.129082</td>\n",
       "      <td>0.883860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.914322</td>\n",
       "      <td>0.718819</td>\n",
       "      <td>0.035117</td>\n",
       "      <td>0.806469</td>\n",
       "      <td>0.831509</td>\n",
       "      <td>0.897910</td>\n",
       "      <td>0.576657</td>\n",
       "      <td>0.520867</td>\n",
       "      <td>0.088972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.927763</td>\n",
       "      <td>0.632750</td>\n",
       "      <td>0.967762</td>\n",
       "      <td>0.970426</td>\n",
       "      <td>0.895992</td>\n",
       "      <td>0.155749</td>\n",
       "      <td>0.057174</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.911733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.858207</td>\n",
       "      <td>0.454314</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.662201</td>\n",
       "      <td>0.766754</td>\n",
       "      <td>0.897975</td>\n",
       "      <td>0.546007</td>\n",
       "      <td>0.423810</td>\n",
       "      <td>0.138740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697699</td>\n",
       "      <td>0.942286</td>\n",
       "      <td>0.644609</td>\n",
       "      <td>0.968314</td>\n",
       "      <td>0.978677</td>\n",
       "      <td>0.887371</td>\n",
       "      <td>0.895447</td>\n",
       "      <td>0.158571</td>\n",
       "      <td>0.242336</td>\n",
       "      <td>0.901522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.921184</td>\n",
       "      <td>0.546202</td>\n",
       "      <td>0.038587</td>\n",
       "      <td>0.886216</td>\n",
       "      <td>0.824055</td>\n",
       "      <td>0.853785</td>\n",
       "      <td>0.678429</td>\n",
       "      <td>0.601608</td>\n",
       "      <td>0.070214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719099</td>\n",
       "      <td>0.918167</td>\n",
       "      <td>0.660503</td>\n",
       "      <td>0.961656</td>\n",
       "      <td>0.960461</td>\n",
       "      <td>0.872111</td>\n",
       "      <td>0.166740</td>\n",
       "      <td>0.081903</td>\n",
       "      <td>0.580041</td>\n",
       "      <td>0.914271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.932751                0.674821   \n",
       "1     46                             0.886285                0.523687   \n",
       "2     70                             0.914322                0.718819   \n",
       "3    132                             0.858207                0.454314   \n",
       "4    200                             0.921184                0.546202   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.119975                      0.555536   \n",
       "1                 0.008217                      0.757152   \n",
       "2                 0.035117                      0.806469   \n",
       "3                 0.007929                      0.662201   \n",
       "4                 0.038587                      0.886216   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.662290                               0.606968   \n",
       "1               0.773529                               0.900763   \n",
       "2               0.831509                               0.897910   \n",
       "3               0.766754                               0.897975   \n",
       "4               0.824055                               0.853785   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.674387                       0.579693   \n",
       "1                         0.542357                       0.430740   \n",
       "2                         0.576657                       0.520867   \n",
       "3                         0.546007                       0.423810   \n",
       "4                         0.678429                       0.601608   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.507852  ...               0.912704        0.923667   \n",
       "1               0.064785  ...               0.684753        0.947448   \n",
       "2               0.088972  ...               0.868687        0.927763   \n",
       "3               0.138740  ...               0.697699        0.942286   \n",
       "4               0.070214  ...               0.719099        0.918167   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.579044          0.967566          0.962791   \n",
       "1                     0.664143          0.958139          0.975366   \n",
       "2                     0.632750          0.967762          0.970426   \n",
       "3                     0.644609          0.968314          0.978677   \n",
       "4                     0.660503          0.961656          0.960461   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.826529                  0.166110               0.054223   \n",
       "1             0.880654                  0.899054               0.099850   \n",
       "2             0.895992                  0.155749               0.057174   \n",
       "3             0.887371                  0.895447               0.158571   \n",
       "4             0.872111                  0.166740               0.081903   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.783755             0.928684  \n",
       "1                        0.129082             0.883860  \n",
       "2                        0.814480             0.911733  \n",
       "3                        0.242336             0.901522  \n",
       "4                        0.580041             0.914271  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5029.186975</td>\n",
       "      <td>0.894014</td>\n",
       "      <td>0.594932</td>\n",
       "      <td>0.033497</td>\n",
       "      <td>0.708212</td>\n",
       "      <td>0.790365</td>\n",
       "      <td>0.834522</td>\n",
       "      <td>0.581020</td>\n",
       "      <td>0.486002</td>\n",
       "      <td>0.217696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789103</td>\n",
       "      <td>0.934695</td>\n",
       "      <td>0.667292</td>\n",
       "      <td>0.961293</td>\n",
       "      <td>0.970152</td>\n",
       "      <td>0.870487</td>\n",
       "      <td>0.561167</td>\n",
       "      <td>0.116595</td>\n",
       "      <td>0.466043</td>\n",
       "      <td>0.912124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2812.670060</td>\n",
       "      <td>0.038953</td>\n",
       "      <td>0.122779</td>\n",
       "      <td>0.055064</td>\n",
       "      <td>0.096320</td>\n",
       "      <td>0.102855</td>\n",
       "      <td>0.131635</td>\n",
       "      <td>0.049883</td>\n",
       "      <td>0.077603</td>\n",
       "      <td>0.180433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076835</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.042790</td>\n",
       "      <td>0.009997</td>\n",
       "      <td>0.010247</td>\n",
       "      <td>0.031186</td>\n",
       "      <td>0.315308</td>\n",
       "      <td>0.053046</td>\n",
       "      <td>0.259671</td>\n",
       "      <td>0.015773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.788602</td>\n",
       "      <td>0.369203</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.310239</td>\n",
       "      <td>0.326927</td>\n",
       "      <td>0.178819</td>\n",
       "      <td>0.470438</td>\n",
       "      <td>0.348992</td>\n",
       "      <td>0.006315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600528</td>\n",
       "      <td>0.864135</td>\n",
       "      <td>0.518186</td>\n",
       "      <td>0.924831</td>\n",
       "      <td>0.923390</td>\n",
       "      <td>0.758268</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>0.009112</td>\n",
       "      <td>0.043601</td>\n",
       "      <td>0.853898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2572.000000</td>\n",
       "      <td>0.863942</td>\n",
       "      <td>0.487109</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>0.653809</td>\n",
       "      <td>0.742213</td>\n",
       "      <td>0.807153</td>\n",
       "      <td>0.541287</td>\n",
       "      <td>0.429049</td>\n",
       "      <td>0.082563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727574</td>\n",
       "      <td>0.924147</td>\n",
       "      <td>0.639121</td>\n",
       "      <td>0.955074</td>\n",
       "      <td>0.964235</td>\n",
       "      <td>0.852317</td>\n",
       "      <td>0.238877</td>\n",
       "      <td>0.070021</td>\n",
       "      <td>0.234605</td>\n",
       "      <td>0.902705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5093.000000</td>\n",
       "      <td>0.895274</td>\n",
       "      <td>0.584812</td>\n",
       "      <td>0.013179</td>\n",
       "      <td>0.699936</td>\n",
       "      <td>0.796542</td>\n",
       "      <td>0.881889</td>\n",
       "      <td>0.572622</td>\n",
       "      <td>0.465195</td>\n",
       "      <td>0.151225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792021</td>\n",
       "      <td>0.936972</td>\n",
       "      <td>0.665348</td>\n",
       "      <td>0.962585</td>\n",
       "      <td>0.971824</td>\n",
       "      <td>0.873528</td>\n",
       "      <td>0.666822</td>\n",
       "      <td>0.119354</td>\n",
       "      <td>0.420834</td>\n",
       "      <td>0.912986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7482.000000</td>\n",
       "      <td>0.924655</td>\n",
       "      <td>0.695911</td>\n",
       "      <td>0.029515</td>\n",
       "      <td>0.765949</td>\n",
       "      <td>0.860567</td>\n",
       "      <td>0.913090</td>\n",
       "      <td>0.616657</td>\n",
       "      <td>0.521201</td>\n",
       "      <td>0.303242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855222</td>\n",
       "      <td>0.948142</td>\n",
       "      <td>0.694017</td>\n",
       "      <td>0.968386</td>\n",
       "      <td>0.978211</td>\n",
       "      <td>0.892670</td>\n",
       "      <td>0.846794</td>\n",
       "      <td>0.154087</td>\n",
       "      <td>0.670410</td>\n",
       "      <td>0.923420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9640.000000</td>\n",
       "      <td>0.973835</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.441970</td>\n",
       "      <td>0.957097</td>\n",
       "      <td>0.971520</td>\n",
       "      <td>0.982222</td>\n",
       "      <td>0.706289</td>\n",
       "      <td>0.749186</td>\n",
       "      <td>0.829211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938067</td>\n",
       "      <td>0.972939</td>\n",
       "      <td>0.800639</td>\n",
       "      <td>0.980715</td>\n",
       "      <td>0.988292</td>\n",
       "      <td>0.949450</td>\n",
       "      <td>0.951799</td>\n",
       "      <td>0.274680</td>\n",
       "      <td>0.981783</td>\n",
       "      <td>0.952058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qa_id  question_asker_intent_understanding  \\\n",
       "count   476.000000                           476.000000   \n",
       "mean   5029.186975                             0.894014   \n",
       "std    2812.670060                             0.038953   \n",
       "min      39.000000                             0.788602   \n",
       "25%    2572.000000                             0.863942   \n",
       "50%    5093.000000                             0.895274   \n",
       "75%    7482.000000                             0.924655   \n",
       "max    9640.000000                             0.973835   \n",
       "\n",
       "       question_body_critical  question_conversational  \\\n",
       "count              476.000000               476.000000   \n",
       "mean                 0.594932                 0.033497   \n",
       "std                  0.122779                 0.055064   \n",
       "min                  0.369203                 0.003178   \n",
       "25%                  0.487109                 0.008428   \n",
       "50%                  0.584812                 0.013179   \n",
       "75%                  0.695911                 0.029515   \n",
       "max                  0.860832                 0.441970   \n",
       "\n",
       "       question_expect_short_answer  question_fact_seeking  \\\n",
       "count                    476.000000             476.000000   \n",
       "mean                       0.708212               0.790365   \n",
       "std                        0.096320               0.102855   \n",
       "min                        0.310239               0.326927   \n",
       "25%                        0.653809               0.742213   \n",
       "50%                        0.699936               0.796542   \n",
       "75%                        0.765949               0.860567   \n",
       "max                        0.957097               0.971520   \n",
       "\n",
       "       question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "count                             476.000000                       476.000000   \n",
       "mean                                0.834522                         0.581020   \n",
       "std                                 0.131635                         0.049883   \n",
       "min                                 0.178819                         0.470438   \n",
       "25%                                 0.807153                         0.541287   \n",
       "50%                                 0.881889                         0.572622   \n",
       "75%                                 0.913090                         0.616657   \n",
       "max                                 0.982222                         0.706289   \n",
       "\n",
       "       question_interestingness_self  question_multi_intent  ...  \\\n",
       "count                     476.000000             476.000000  ...   \n",
       "mean                        0.486002               0.217696  ...   \n",
       "std                         0.077603               0.180433  ...   \n",
       "min                         0.348992               0.006315  ...   \n",
       "25%                         0.429049               0.082563  ...   \n",
       "50%                         0.465195               0.151225  ...   \n",
       "75%                         0.521201               0.303242  ...   \n",
       "max                         0.749186               0.829211  ...   \n",
       "\n",
       "       question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "count             476.000000      476.000000                   476.000000   \n",
       "mean                0.789103        0.934695                     0.667292   \n",
       "std                 0.076835        0.018443                     0.042790   \n",
       "min                 0.600528        0.864135                     0.518186   \n",
       "25%                 0.727574        0.924147                     0.639121   \n",
       "50%                 0.792021        0.936972                     0.665348   \n",
       "75%                 0.855222        0.948142                     0.694017   \n",
       "max                 0.938067        0.972939                     0.800639   \n",
       "\n",
       "       answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "count        476.000000        476.000000           476.000000   \n",
       "mean           0.961293          0.970152             0.870487   \n",
       "std            0.009997          0.010247             0.031186   \n",
       "min            0.924831          0.923390             0.758268   \n",
       "25%            0.955074          0.964235             0.852317   \n",
       "50%            0.962585          0.971824             0.873528   \n",
       "75%            0.968386          0.978211             0.892670   \n",
       "max            0.980715          0.988292             0.949450   \n",
       "\n",
       "       answer_type_instructions  answer_type_procedure  \\\n",
       "count                476.000000             476.000000   \n",
       "mean                   0.561167               0.116595   \n",
       "std                    0.315308               0.053046   \n",
       "min                    0.008122               0.009112   \n",
       "25%                    0.238877               0.070021   \n",
       "50%                    0.666822               0.119354   \n",
       "75%                    0.846794               0.154087   \n",
       "max                    0.951799               0.274680   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                      476.000000           476.000000  \n",
       "mean                         0.466043             0.912124  \n",
       "std                          0.259671             0.015773  \n",
       "min                          0.043601             0.853898  \n",
       "25%                          0.234605             0.902705  \n",
       "50%                          0.420834             0.912986  \n",
       "75%                          0.670410             0.923420  \n",
       "max                          0.981783             0.952058  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "submission[target_cols] = Y_test\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "display(submission.head())\n",
    "display(submission.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
