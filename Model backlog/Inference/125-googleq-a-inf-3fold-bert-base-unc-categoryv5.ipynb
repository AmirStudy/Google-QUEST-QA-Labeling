{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import warnings\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D, SpatialDropout1D, Concatenate\n",
    "from googleqa_utilityscript import *\n",
    "from googleqa_map_utilityscript import *\n",
    "import bert_tokenization as tokenization\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to predict: ['/kaggle/input/125-googleq-a-train-2fold-bert-base-unc-categoryv5/model_fold_1.h5', '/kaggle/input/125-googleq-a-train-2fold-bert-base-unc-categoryv5/model_fold_2.h5']\n",
      "Test samples: 476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BERT_PATH = '/kaggle/input/tf-hub-bert-base/bert_base_uncased'\n",
    "VOCAB_PATH = BERT_PATH + '/assets/vocab.txt'\n",
    "model_path_list = glob.glob('/kaggle/input/125-googleq-a-train-2fold-bert-base-unc-categoryv5/' + '*.h5')\n",
    "model_path_list.sort()\n",
    "print('Models to predict:', model_path_list)\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "question_target_cols = ['question_asker_intent_understanding','question_body_critical', 'question_conversational', \n",
    "                        'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                        'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', \n",
    "                        'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                        'question_type_compare', 'question_type_consequence', 'question_type_definition', \n",
    "                        'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                        'question_type_reason_explanation', 'question_type_spelling', 'question_well_written']\n",
    "answer_target_cols = ['answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                      'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', \n",
    "                      'answer_type_reason_explanation', 'answer_well_written']\n",
    "target_cols = question_target_cols + answer_target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['question_title', 'question_body', 'answer']\n",
    "    \n",
    "# for feature in text_features:\n",
    "#     # Lower\n",
    "#     test[feature] = test[feature].apply(lambda x: x.lower())\n",
    "#     # Map misspellings\n",
    "#     test[feature] = test[feature].apply(lambda x: map_misspellings(x))\n",
    "#     # Map contractions\n",
    "#     test[feature] = test[feature].apply(lambda x: map_contraction(x))\n",
    "#     # Trim text\n",
    "#     test[feature] = test[feature].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "N_CLASS = len(target_cols)\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "N_CLASS_CAT = test['category'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(VOCAB_PATH, do_lower_case=True)\n",
    "\n",
    "# Test features\n",
    "X_test = compute_input_arays(test, text_features, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    input_word_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    segment_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids')\n",
    "\n",
    "    bert_layer = KerasLayer(BERT_PATH, trainable=True)\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_masks, segment_ids])\n",
    "\n",
    "    # Sequence output\n",
    "    seq_branch = SpatialDropout1D(0.3)(sequence_output)\n",
    "    seq_branch = GlobalAveragePooling1D()(seq_branch)\n",
    "    output_seq = Dense(N_CLASS, activation=\"sigmoid\", name=\"output_seq\")(seq_branch)\n",
    "    \n",
    "    # Class output\n",
    "    class_branch = Dropout(0.3)(pooled_output)\n",
    "    output_class = Dense(N_CLASS_CAT, activation=\"softmax\", name=\"output_class\")(class_branch)\n",
    "\n",
    "    model = Model(inputs=[input_word_ids, input_masks, segment_ids], outputs=[output_seq, output_class])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.zeros((len(test), N_CLASS))\n",
    "\n",
    "for model_path in model_path_list:\n",
    "    model = model_fn()\n",
    "    model.load_weights(model_path)\n",
    "    Y_test += model.predict(X_test)[0] / len(model_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.940991</td>\n",
       "      <td>0.650606</td>\n",
       "      <td>0.196062</td>\n",
       "      <td>0.499480</td>\n",
       "      <td>0.586706</td>\n",
       "      <td>0.480348</td>\n",
       "      <td>0.693087</td>\n",
       "      <td>0.618637</td>\n",
       "      <td>0.438965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921307</td>\n",
       "      <td>0.930857</td>\n",
       "      <td>0.593457</td>\n",
       "      <td>0.962335</td>\n",
       "      <td>0.957972</td>\n",
       "      <td>0.837815</td>\n",
       "      <td>0.081368</td>\n",
       "      <td>0.049898</td>\n",
       "      <td>0.769465</td>\n",
       "      <td>0.918450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.888936</td>\n",
       "      <td>0.515788</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.785756</td>\n",
       "      <td>0.830355</td>\n",
       "      <td>0.914835</td>\n",
       "      <td>0.564990</td>\n",
       "      <td>0.453957</td>\n",
       "      <td>0.055756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746931</td>\n",
       "      <td>0.949585</td>\n",
       "      <td>0.698319</td>\n",
       "      <td>0.965590</td>\n",
       "      <td>0.975874</td>\n",
       "      <td>0.875894</td>\n",
       "      <td>0.910859</td>\n",
       "      <td>0.118255</td>\n",
       "      <td>0.074409</td>\n",
       "      <td>0.866380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.906965</td>\n",
       "      <td>0.703399</td>\n",
       "      <td>0.025490</td>\n",
       "      <td>0.822056</td>\n",
       "      <td>0.868600</td>\n",
       "      <td>0.919062</td>\n",
       "      <td>0.587727</td>\n",
       "      <td>0.511749</td>\n",
       "      <td>0.048106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872015</td>\n",
       "      <td>0.947577</td>\n",
       "      <td>0.653075</td>\n",
       "      <td>0.965819</td>\n",
       "      <td>0.970831</td>\n",
       "      <td>0.881634</td>\n",
       "      <td>0.215414</td>\n",
       "      <td>0.079586</td>\n",
       "      <td>0.784638</td>\n",
       "      <td>0.918626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.874633</td>\n",
       "      <td>0.422964</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.646797</td>\n",
       "      <td>0.771172</td>\n",
       "      <td>0.906940</td>\n",
       "      <td>0.502879</td>\n",
       "      <td>0.436196</td>\n",
       "      <td>0.143360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710097</td>\n",
       "      <td>0.944513</td>\n",
       "      <td>0.643613</td>\n",
       "      <td>0.968891</td>\n",
       "      <td>0.976530</td>\n",
       "      <td>0.885792</td>\n",
       "      <td>0.863449</td>\n",
       "      <td>0.190791</td>\n",
       "      <td>0.265618</td>\n",
       "      <td>0.901787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.908559</td>\n",
       "      <td>0.364501</td>\n",
       "      <td>0.030876</td>\n",
       "      <td>0.827418</td>\n",
       "      <td>0.802791</td>\n",
       "      <td>0.857078</td>\n",
       "      <td>0.625598</td>\n",
       "      <td>0.568623</td>\n",
       "      <td>0.046743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669165</td>\n",
       "      <td>0.896762</td>\n",
       "      <td>0.607168</td>\n",
       "      <td>0.954185</td>\n",
       "      <td>0.934135</td>\n",
       "      <td>0.826430</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.106723</td>\n",
       "      <td>0.681053</td>\n",
       "      <td>0.912820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.940991                0.650606   \n",
       "1     46                             0.888936                0.515788   \n",
       "2     70                             0.906965                0.703399   \n",
       "3    132                             0.874633                0.422964   \n",
       "4    200                             0.908559                0.364501   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.196062                      0.499480   \n",
       "1                 0.005378                      0.785756   \n",
       "2                 0.025490                      0.822056   \n",
       "3                 0.008524                      0.646797   \n",
       "4                 0.030876                      0.827418   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.586706                               0.480348   \n",
       "1               0.830355                               0.914835   \n",
       "2               0.868600                               0.919062   \n",
       "3               0.771172                               0.906940   \n",
       "4               0.802791                               0.857078   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.693087                       0.618637   \n",
       "1                         0.564990                       0.453957   \n",
       "2                         0.587727                       0.511749   \n",
       "3                         0.502879                       0.436196   \n",
       "4                         0.625598                       0.568623   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.438965  ...               0.921307        0.930857   \n",
       "1               0.055756  ...               0.746931        0.949585   \n",
       "2               0.048106  ...               0.872015        0.947577   \n",
       "3               0.143360  ...               0.710097        0.944513   \n",
       "4               0.046743  ...               0.669165        0.896762   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.593457          0.962335          0.957972   \n",
       "1                     0.698319          0.965590          0.975874   \n",
       "2                     0.653075          0.965819          0.970831   \n",
       "3                     0.643613          0.968891          0.976530   \n",
       "4                     0.607168          0.954185          0.934135   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.837815                  0.081368               0.049898   \n",
       "1             0.875894                  0.910859               0.118255   \n",
       "2             0.881634                  0.215414               0.079586   \n",
       "3             0.885792                  0.863449               0.190791   \n",
       "4             0.826430                  0.153061               0.106723   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.769465             0.918450  \n",
       "1                        0.074409             0.866380  \n",
       "2                        0.784638             0.918626  \n",
       "3                        0.265618             0.901787  \n",
       "4                        0.681053             0.912820  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5029.186975</td>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.580770</td>\n",
       "      <td>0.034292</td>\n",
       "      <td>0.709581</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>0.848066</td>\n",
       "      <td>0.579516</td>\n",
       "      <td>0.475682</td>\n",
       "      <td>0.216375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794639</td>\n",
       "      <td>0.929468</td>\n",
       "      <td>0.660605</td>\n",
       "      <td>0.961451</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.862055</td>\n",
       "      <td>0.547313</td>\n",
       "      <td>0.129516</td>\n",
       "      <td>0.478519</td>\n",
       "      <td>0.905943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2812.670060</td>\n",
       "      <td>0.044802</td>\n",
       "      <td>0.139714</td>\n",
       "      <td>0.063375</td>\n",
       "      <td>0.113790</td>\n",
       "      <td>0.112103</td>\n",
       "      <td>0.134133</td>\n",
       "      <td>0.053492</td>\n",
       "      <td>0.086279</td>\n",
       "      <td>0.203015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087977</td>\n",
       "      <td>0.020580</td>\n",
       "      <td>0.047879</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.033847</td>\n",
       "      <td>0.324394</td>\n",
       "      <td>0.062590</td>\n",
       "      <td>0.274453</td>\n",
       "      <td>0.021181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.759376</td>\n",
       "      <td>0.325794</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.268697</td>\n",
       "      <td>0.332183</td>\n",
       "      <td>0.180326</td>\n",
       "      <td>0.463988</td>\n",
       "      <td>0.339261</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572485</td>\n",
       "      <td>0.857759</td>\n",
       "      <td>0.506974</td>\n",
       "      <td>0.920169</td>\n",
       "      <td>0.912674</td>\n",
       "      <td>0.742523</td>\n",
       "      <td>0.006929</td>\n",
       "      <td>0.008117</td>\n",
       "      <td>0.054992</td>\n",
       "      <td>0.828353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2572.000000</td>\n",
       "      <td>0.859436</td>\n",
       "      <td>0.455530</td>\n",
       "      <td>0.006535</td>\n",
       "      <td>0.646952</td>\n",
       "      <td>0.757532</td>\n",
       "      <td>0.828774</td>\n",
       "      <td>0.538701</td>\n",
       "      <td>0.412764</td>\n",
       "      <td>0.066709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721414</td>\n",
       "      <td>0.918475</td>\n",
       "      <td>0.629626</td>\n",
       "      <td>0.955195</td>\n",
       "      <td>0.965786</td>\n",
       "      <td>0.843400</td>\n",
       "      <td>0.202021</td>\n",
       "      <td>0.077331</td>\n",
       "      <td>0.231352</td>\n",
       "      <td>0.891553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5093.000000</td>\n",
       "      <td>0.890781</td>\n",
       "      <td>0.573722</td>\n",
       "      <td>0.011167</td>\n",
       "      <td>0.705195</td>\n",
       "      <td>0.815470</td>\n",
       "      <td>0.894027</td>\n",
       "      <td>0.571269</td>\n",
       "      <td>0.450785</td>\n",
       "      <td>0.133282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795242</td>\n",
       "      <td>0.932142</td>\n",
       "      <td>0.659746</td>\n",
       "      <td>0.963137</td>\n",
       "      <td>0.973948</td>\n",
       "      <td>0.866157</td>\n",
       "      <td>0.648369</td>\n",
       "      <td>0.133005</td>\n",
       "      <td>0.428269</td>\n",
       "      <td>0.906209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7482.000000</td>\n",
       "      <td>0.925890</td>\n",
       "      <td>0.690934</td>\n",
       "      <td>0.027698</td>\n",
       "      <td>0.780856</td>\n",
       "      <td>0.880194</td>\n",
       "      <td>0.929361</td>\n",
       "      <td>0.615949</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.307807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874031</td>\n",
       "      <td>0.944779</td>\n",
       "      <td>0.690695</td>\n",
       "      <td>0.968914</td>\n",
       "      <td>0.979325</td>\n",
       "      <td>0.885766</td>\n",
       "      <td>0.845618</td>\n",
       "      <td>0.173852</td>\n",
       "      <td>0.721527</td>\n",
       "      <td>0.920811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9640.000000</td>\n",
       "      <td>0.974978</td>\n",
       "      <td>0.896942</td>\n",
       "      <td>0.464771</td>\n",
       "      <td>0.973659</td>\n",
       "      <td>0.982035</td>\n",
       "      <td>0.986197</td>\n",
       "      <td>0.729986</td>\n",
       "      <td>0.771042</td>\n",
       "      <td>0.854584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964542</td>\n",
       "      <td>0.973138</td>\n",
       "      <td>0.810142</td>\n",
       "      <td>0.985487</td>\n",
       "      <td>0.989047</td>\n",
       "      <td>0.945926</td>\n",
       "      <td>0.937761</td>\n",
       "      <td>0.280196</td>\n",
       "      <td>0.986245</td>\n",
       "      <td>0.955265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qa_id  question_asker_intent_understanding  \\\n",
       "count   476.000000                           476.000000   \n",
       "mean   5029.186975                             0.889900   \n",
       "std    2812.670060                             0.044802   \n",
       "min      39.000000                             0.759376   \n",
       "25%    2572.000000                             0.859436   \n",
       "50%    5093.000000                             0.890781   \n",
       "75%    7482.000000                             0.925890   \n",
       "max    9640.000000                             0.974978   \n",
       "\n",
       "       question_body_critical  question_conversational  \\\n",
       "count              476.000000               476.000000   \n",
       "mean                 0.580770                 0.034292   \n",
       "std                  0.139714                 0.063375   \n",
       "min                  0.325794                 0.002532   \n",
       "25%                  0.455530                 0.006535   \n",
       "50%                  0.573722                 0.011167   \n",
       "75%                  0.690934                 0.027698   \n",
       "max                  0.896942                 0.464771   \n",
       "\n",
       "       question_expect_short_answer  question_fact_seeking  \\\n",
       "count                    476.000000             476.000000   \n",
       "mean                       0.709581               0.802982   \n",
       "std                        0.113790               0.112103   \n",
       "min                        0.268697               0.332183   \n",
       "25%                        0.646952               0.757532   \n",
       "50%                        0.705195               0.815470   \n",
       "75%                        0.780856               0.880194   \n",
       "max                        0.973659               0.982035   \n",
       "\n",
       "       question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "count                             476.000000                       476.000000   \n",
       "mean                                0.848066                         0.579516   \n",
       "std                                 0.134133                         0.053492   \n",
       "min                                 0.180326                         0.463988   \n",
       "25%                                 0.828774                         0.538701   \n",
       "50%                                 0.894027                         0.571269   \n",
       "75%                                 0.929361                         0.615949   \n",
       "max                                 0.986197                         0.729986   \n",
       "\n",
       "       question_interestingness_self  question_multi_intent  ...  \\\n",
       "count                     476.000000             476.000000  ...   \n",
       "mean                        0.475682               0.216375  ...   \n",
       "std                         0.086279               0.203015  ...   \n",
       "min                         0.339261               0.003576  ...   \n",
       "25%                         0.412764               0.066709  ...   \n",
       "50%                         0.450785               0.133282  ...   \n",
       "75%                         0.523179               0.307807  ...   \n",
       "max                         0.771042               0.854584  ...   \n",
       "\n",
       "       question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "count             476.000000      476.000000                   476.000000   \n",
       "mean                0.794639        0.929468                     0.660605   \n",
       "std                 0.087977        0.020580                     0.047879   \n",
       "min                 0.572485        0.857759                     0.506974   \n",
       "25%                 0.721414        0.918475                     0.629626   \n",
       "50%                 0.795242        0.932142                     0.659746   \n",
       "75%                 0.874031        0.944779                     0.690695   \n",
       "max                 0.964542        0.973138                     0.810142   \n",
       "\n",
       "       answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "count        476.000000        476.000000           476.000000   \n",
       "mean           0.961451          0.971223             0.862055   \n",
       "std            0.011247          0.011333             0.033847   \n",
       "min            0.920169          0.912674             0.742523   \n",
       "25%            0.955195          0.965786             0.843400   \n",
       "50%            0.963137          0.973948             0.866157   \n",
       "75%            0.968914          0.979325             0.885766   \n",
       "max            0.985487          0.989047             0.945926   \n",
       "\n",
       "       answer_type_instructions  answer_type_procedure  \\\n",
       "count                476.000000             476.000000   \n",
       "mean                   0.547313               0.129516   \n",
       "std                    0.324394               0.062590   \n",
       "min                    0.006929               0.008117   \n",
       "25%                    0.202021               0.077331   \n",
       "50%                    0.648369               0.133005   \n",
       "75%                    0.845618               0.173852   \n",
       "max                    0.937761               0.280196   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                      476.000000           476.000000  \n",
       "mean                         0.478519             0.905943  \n",
       "std                          0.274453             0.021181  \n",
       "min                          0.054992             0.828353  \n",
       "25%                          0.231352             0.891553  \n",
       "50%                          0.428269             0.906209  \n",
       "75%                          0.721527             0.920811  \n",
       "max                          0.986245             0.955265  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "submission[target_cols] = Y_test\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "display(submission.head())\n",
    "display(submission.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
