{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import warnings\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D, SpatialDropout1D, Concatenate\n",
    "from googleqa_utilityscript import *\n",
    "from googleqa_map_utilityscript import *\n",
    "import bert_tokenization as tokenization\n",
    "from transformers import BertConfig, BertTokenizer, TFBertModel\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to predict:\n",
      "/kaggle/input/140-googleq-a-train-3fold-bert-base-unc-raw-huface/model_fold_1.h5\n",
      "/kaggle/input/140-googleq-a-train-3fold-bert-base-unc-raw-huface/model_fold_2.h5\n",
      "/kaggle/input/140-googleq-a-train-3fold-bert-base-unc-raw-huface/model_fold_3.h5\n",
      "Test samples: 476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BERT_PATH = '/kaggle/input/bert-base-uncased-huggingface-transformer/bert-base-uncased-tf_model.h5'\n",
    "VOCAB_PATH = '/kaggle/input/bert-base-uncased-huggingface-transformer/bert-base-uncased-vocab.txt'\n",
    "model_path_list = glob.glob('/kaggle/input/140-googleq-a-train-3fold-bert-base-unc-raw-huface/' + '*1.h5')\n",
    "model_path_list += glob.glob('/kaggle/input/140-googleq-a-train-3fold-bert-base-unc-raw-huface/' + '*2.h5')\n",
    "model_path_list += glob.glob('/kaggle/input/140-googleq-a-train-3fold-bert-base-unc-raw-huface/' + '*3.h5')\n",
    "model_path_list.sort()\n",
    "print('Models to predict:')\n",
    "print(*model_path_list, sep = \"\\n\")\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "question_target_cols = ['question_asker_intent_understanding','question_body_critical', 'question_conversational', \n",
    "                        'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                        'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', \n",
    "                        'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                        'question_type_compare', 'question_type_consequence', 'question_type_definition', \n",
    "                        'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                        'question_type_reason_explanation', 'question_type_spelling', 'question_well_written']\n",
    "answer_target_cols = ['answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                      'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', \n",
    "                      'answer_type_reason_explanation', 'answer_well_written']\n",
    "target_cols = question_target_cols + answer_target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['question_title', 'question_body', 'answer']\n",
    "\n",
    "# for feature in text_features:\n",
    "#     # Lower\n",
    "#     test[feature] = test[feature].apply(lambda x: x.lower())\n",
    "#     # Map misspellings\n",
    "#     test[feature] = test[feature].apply(lambda x: map_misspellings(x))\n",
    "#     # Map contractions\n",
    "#     test[feature] = test[feature].apply(lambda x: map_contraction(x))\n",
    "#     # Trim text\n",
    "#     test[feature] = test[feature].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "N_CLASS = len(target_cols)\n",
    "MAX_SEQUENCE_LENGTH = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(VOCAB_PATH, do_lower_case=True)\n",
    "\n",
    "# Test features\n",
    "X_test = compute_input_arays(test, text_features, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "bert_config = BertConfig()\n",
    "bert_config.output_hidden_states=False\n",
    "\n",
    "def model_fn():\n",
    "    input_word_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    segment_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids')\n",
    "\n",
    "    bert_model = TFBertModel.from_pretrained(BERT_PATH, config=bert_config)\n",
    "    sequence_output, pooled_output = bert_model([input_word_ids, input_masks, segment_ids])\n",
    "\n",
    "    x = GlobalAveragePooling1D()(sequence_output)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(N_CLASS, activation=\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "    model = Model(inputs=[input_word_ids, input_masks, segment_ids], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.zeros((len(test), N_CLASS))\n",
    "\n",
    "for model_path in model_path_list:\n",
    "    model = model_fn()\n",
    "    model.load_weights(model_path)\n",
    "    Y_test += model.predict(X_test) / len(model_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.939659</td>\n",
       "      <td>0.636260</td>\n",
       "      <td>0.209095</td>\n",
       "      <td>0.517714</td>\n",
       "      <td>0.591920</td>\n",
       "      <td>0.547158</td>\n",
       "      <td>0.671477</td>\n",
       "      <td>0.671813</td>\n",
       "      <td>0.671853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905061</td>\n",
       "      <td>0.897970</td>\n",
       "      <td>0.573826</td>\n",
       "      <td>0.963302</td>\n",
       "      <td>0.965611</td>\n",
       "      <td>0.799106</td>\n",
       "      <td>0.052498</td>\n",
       "      <td>0.067196</td>\n",
       "      <td>0.866889</td>\n",
       "      <td>0.904376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.879376</td>\n",
       "      <td>0.556844</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>0.758570</td>\n",
       "      <td>0.805026</td>\n",
       "      <td>0.944186</td>\n",
       "      <td>0.543537</td>\n",
       "      <td>0.456715</td>\n",
       "      <td>0.061984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738701</td>\n",
       "      <td>0.948977</td>\n",
       "      <td>0.628432</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>0.979108</td>\n",
       "      <td>0.870339</td>\n",
       "      <td>0.892675</td>\n",
       "      <td>0.122915</td>\n",
       "      <td>0.136263</td>\n",
       "      <td>0.900138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.926201</td>\n",
       "      <td>0.690540</td>\n",
       "      <td>0.029586</td>\n",
       "      <td>0.759330</td>\n",
       "      <td>0.872744</td>\n",
       "      <td>0.915747</td>\n",
       "      <td>0.599228</td>\n",
       "      <td>0.514503</td>\n",
       "      <td>0.191895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881730</td>\n",
       "      <td>0.930254</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.965038</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.866008</td>\n",
       "      <td>0.074548</td>\n",
       "      <td>0.059125</td>\n",
       "      <td>0.857847</td>\n",
       "      <td>0.916206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.898507</td>\n",
       "      <td>0.467175</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>0.748808</td>\n",
       "      <td>0.740768</td>\n",
       "      <td>0.936044</td>\n",
       "      <td>0.519524</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.094934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698404</td>\n",
       "      <td>0.961085</td>\n",
       "      <td>0.684382</td>\n",
       "      <td>0.970666</td>\n",
       "      <td>0.985671</td>\n",
       "      <td>0.915629</td>\n",
       "      <td>0.853219</td>\n",
       "      <td>0.135318</td>\n",
       "      <td>0.413749</td>\n",
       "      <td>0.909327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.922178</td>\n",
       "      <td>0.461648</td>\n",
       "      <td>0.032658</td>\n",
       "      <td>0.851897</td>\n",
       "      <td>0.763758</td>\n",
       "      <td>0.875704</td>\n",
       "      <td>0.620653</td>\n",
       "      <td>0.546095</td>\n",
       "      <td>0.121948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676788</td>\n",
       "      <td>0.913535</td>\n",
       "      <td>0.635394</td>\n",
       "      <td>0.969855</td>\n",
       "      <td>0.968604</td>\n",
       "      <td>0.857898</td>\n",
       "      <td>0.182692</td>\n",
       "      <td>0.082484</td>\n",
       "      <td>0.849316</td>\n",
       "      <td>0.910053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.939659                0.636260   \n",
       "1     46                             0.879376                0.556844   \n",
       "2     70                             0.926201                0.690540   \n",
       "3    132                             0.898507                0.467175   \n",
       "4    200                             0.922178                0.461648   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.209095                      0.517714   \n",
       "1                 0.005063                      0.758570   \n",
       "2                 0.029586                      0.759330   \n",
       "3                 0.006385                      0.748808   \n",
       "4                 0.032658                      0.851897   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.591920                               0.547158   \n",
       "1               0.805026                               0.944186   \n",
       "2               0.872744                               0.915747   \n",
       "3               0.740768                               0.936044   \n",
       "4               0.763758                               0.875704   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.671477                       0.671813   \n",
       "1                         0.543537                       0.456715   \n",
       "2                         0.599228                       0.514503   \n",
       "3                         0.519524                       0.411754   \n",
       "4                         0.620653                       0.546095   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.671853  ...               0.905061        0.897970   \n",
       "1               0.061984  ...               0.738701        0.948977   \n",
       "2               0.191895  ...               0.881730        0.930254   \n",
       "3               0.094934  ...               0.698404        0.961085   \n",
       "4               0.121948  ...               0.676788        0.913535   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.573826          0.963302          0.965611   \n",
       "1                     0.628432          0.971489          0.979108   \n",
       "2                     0.602000          0.965038          0.970684   \n",
       "3                     0.684382          0.970666          0.985671   \n",
       "4                     0.635394          0.969855          0.968604   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.799106                  0.052498               0.067196   \n",
       "1             0.870339                  0.892675               0.122915   \n",
       "2             0.866008                  0.074548               0.059125   \n",
       "3             0.915629                  0.853219               0.135318   \n",
       "4             0.857898                  0.182692               0.082484   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.866889             0.904376  \n",
       "1                        0.136263             0.900138  \n",
       "2                        0.857847             0.916206  \n",
       "3                        0.413749             0.909327  \n",
       "4                        0.849316             0.910053  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5029.186975</td>\n",
       "      <td>0.903008</td>\n",
       "      <td>0.611739</td>\n",
       "      <td>0.035204</td>\n",
       "      <td>0.726244</td>\n",
       "      <td>0.796666</td>\n",
       "      <td>0.866781</td>\n",
       "      <td>0.569608</td>\n",
       "      <td>0.490571</td>\n",
       "      <td>0.236056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788594</td>\n",
       "      <td>0.938301</td>\n",
       "      <td>0.658700</td>\n",
       "      <td>0.966365</td>\n",
       "      <td>0.974100</td>\n",
       "      <td>0.875843</td>\n",
       "      <td>0.499792</td>\n",
       "      <td>0.127062</td>\n",
       "      <td>0.555944</td>\n",
       "      <td>0.910064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2812.670060</td>\n",
       "      <td>0.032711</td>\n",
       "      <td>0.112292</td>\n",
       "      <td>0.059862</td>\n",
       "      <td>0.091441</td>\n",
       "      <td>0.090662</td>\n",
       "      <td>0.110978</td>\n",
       "      <td>0.050949</td>\n",
       "      <td>0.086811</td>\n",
       "      <td>0.191776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075223</td>\n",
       "      <td>0.020318</td>\n",
       "      <td>0.045626</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.009715</td>\n",
       "      <td>0.033115</td>\n",
       "      <td>0.317790</td>\n",
       "      <td>0.054860</td>\n",
       "      <td>0.274882</td>\n",
       "      <td>0.016719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.807172</td>\n",
       "      <td>0.385040</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.318803</td>\n",
       "      <td>0.283226</td>\n",
       "      <td>0.290298</td>\n",
       "      <td>0.465791</td>\n",
       "      <td>0.342701</td>\n",
       "      <td>0.013776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599920</td>\n",
       "      <td>0.858751</td>\n",
       "      <td>0.522770</td>\n",
       "      <td>0.925688</td>\n",
       "      <td>0.925712</td>\n",
       "      <td>0.774757</td>\n",
       "      <td>0.006615</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0.037468</td>\n",
       "      <td>0.852630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2572.000000</td>\n",
       "      <td>0.883091</td>\n",
       "      <td>0.513983</td>\n",
       "      <td>0.007904</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.750101</td>\n",
       "      <td>0.855799</td>\n",
       "      <td>0.529842</td>\n",
       "      <td>0.429129</td>\n",
       "      <td>0.085801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730267</td>\n",
       "      <td>0.926997</td>\n",
       "      <td>0.626064</td>\n",
       "      <td>0.961322</td>\n",
       "      <td>0.968186</td>\n",
       "      <td>0.855824</td>\n",
       "      <td>0.163935</td>\n",
       "      <td>0.091113</td>\n",
       "      <td>0.323738</td>\n",
       "      <td>0.898956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5093.000000</td>\n",
       "      <td>0.901960</td>\n",
       "      <td>0.607658</td>\n",
       "      <td>0.012758</td>\n",
       "      <td>0.731566</td>\n",
       "      <td>0.803742</td>\n",
       "      <td>0.911243</td>\n",
       "      <td>0.564760</td>\n",
       "      <td>0.469834</td>\n",
       "      <td>0.162207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792468</td>\n",
       "      <td>0.941811</td>\n",
       "      <td>0.656443</td>\n",
       "      <td>0.967644</td>\n",
       "      <td>0.976014</td>\n",
       "      <td>0.879935</td>\n",
       "      <td>0.573398</td>\n",
       "      <td>0.126785</td>\n",
       "      <td>0.556520</td>\n",
       "      <td>0.910767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7482.000000</td>\n",
       "      <td>0.925914</td>\n",
       "      <td>0.699753</td>\n",
       "      <td>0.029963</td>\n",
       "      <td>0.783113</td>\n",
       "      <td>0.855117</td>\n",
       "      <td>0.930489</td>\n",
       "      <td>0.602018</td>\n",
       "      <td>0.532528</td>\n",
       "      <td>0.349282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851245</td>\n",
       "      <td>0.953179</td>\n",
       "      <td>0.691118</td>\n",
       "      <td>0.971975</td>\n",
       "      <td>0.981885</td>\n",
       "      <td>0.901350</td>\n",
       "      <td>0.788282</td>\n",
       "      <td>0.161849</td>\n",
       "      <td>0.797590</td>\n",
       "      <td>0.922114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9640.000000</td>\n",
       "      <td>0.975986</td>\n",
       "      <td>0.875277</td>\n",
       "      <td>0.531363</td>\n",
       "      <td>0.956027</td>\n",
       "      <td>0.970830</td>\n",
       "      <td>0.966792</td>\n",
       "      <td>0.735049</td>\n",
       "      <td>0.756011</td>\n",
       "      <td>0.851834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936907</td>\n",
       "      <td>0.976400</td>\n",
       "      <td>0.789906</td>\n",
       "      <td>0.984518</td>\n",
       "      <td>0.989328</td>\n",
       "      <td>0.951394</td>\n",
       "      <td>0.947927</td>\n",
       "      <td>0.277912</td>\n",
       "      <td>0.991073</td>\n",
       "      <td>0.955519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qa_id  question_asker_intent_understanding  \\\n",
       "count   476.000000                           476.000000   \n",
       "mean   5029.186975                             0.903008   \n",
       "std    2812.670060                             0.032711   \n",
       "min      39.000000                             0.807172   \n",
       "25%    2572.000000                             0.883091   \n",
       "50%    5093.000000                             0.901960   \n",
       "75%    7482.000000                             0.925914   \n",
       "max    9640.000000                             0.975986   \n",
       "\n",
       "       question_body_critical  question_conversational  \\\n",
       "count              476.000000               476.000000   \n",
       "mean                 0.611739                 0.035204   \n",
       "std                  0.112292                 0.059862   \n",
       "min                  0.385040                 0.003750   \n",
       "25%                  0.513983                 0.007904   \n",
       "50%                  0.607658                 0.012758   \n",
       "75%                  0.699753                 0.029963   \n",
       "max                  0.875277                 0.531363   \n",
       "\n",
       "       question_expect_short_answer  question_fact_seeking  \\\n",
       "count                    476.000000             476.000000   \n",
       "mean                       0.726244               0.796666   \n",
       "std                        0.091441               0.090662   \n",
       "min                        0.318803               0.283226   \n",
       "25%                        0.682000               0.750101   \n",
       "50%                        0.731566               0.803742   \n",
       "75%                        0.783113               0.855117   \n",
       "max                        0.956027               0.970830   \n",
       "\n",
       "       question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "count                             476.000000                       476.000000   \n",
       "mean                                0.866781                         0.569608   \n",
       "std                                 0.110978                         0.050949   \n",
       "min                                 0.290298                         0.465791   \n",
       "25%                                 0.855799                         0.529842   \n",
       "50%                                 0.911243                         0.564760   \n",
       "75%                                 0.930489                         0.602018   \n",
       "max                                 0.966792                         0.735049   \n",
       "\n",
       "       question_interestingness_self  question_multi_intent  ...  \\\n",
       "count                     476.000000             476.000000  ...   \n",
       "mean                        0.490571               0.236056  ...   \n",
       "std                         0.086811               0.191776  ...   \n",
       "min                         0.342701               0.013776  ...   \n",
       "25%                         0.429129               0.085801  ...   \n",
       "50%                         0.469834               0.162207  ...   \n",
       "75%                         0.532528               0.349282  ...   \n",
       "max                         0.756011               0.851834  ...   \n",
       "\n",
       "       question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "count             476.000000      476.000000                   476.000000   \n",
       "mean                0.788594        0.938301                     0.658700   \n",
       "std                 0.075223        0.020318                     0.045626   \n",
       "min                 0.599920        0.858751                     0.522770   \n",
       "25%                 0.730267        0.926997                     0.626064   \n",
       "50%                 0.792468        0.941811                     0.656443   \n",
       "75%                 0.851245        0.953179                     0.691118   \n",
       "max                 0.936907        0.976400                     0.789906   \n",
       "\n",
       "       answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "count        476.000000        476.000000           476.000000   \n",
       "mean           0.966365          0.974100             0.875843   \n",
       "std            0.008480          0.009715             0.033115   \n",
       "min            0.925688          0.925712             0.774757   \n",
       "25%            0.961322          0.968186             0.855824   \n",
       "50%            0.967644          0.976014             0.879935   \n",
       "75%            0.971975          0.981885             0.901350   \n",
       "max            0.984518          0.989328             0.951394   \n",
       "\n",
       "       answer_type_instructions  answer_type_procedure  \\\n",
       "count                476.000000             476.000000   \n",
       "mean                   0.499792               0.127062   \n",
       "std                    0.317790               0.054860   \n",
       "min                    0.006615               0.011426   \n",
       "25%                    0.163935               0.091113   \n",
       "50%                    0.573398               0.126785   \n",
       "75%                    0.788282               0.161849   \n",
       "max                    0.947927               0.277912   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                      476.000000           476.000000  \n",
       "mean                         0.555944             0.910064  \n",
       "std                          0.274882             0.016719  \n",
       "min                          0.037468             0.852630  \n",
       "25%                          0.323738             0.898956  \n",
       "50%                          0.556520             0.910767  \n",
       "75%                          0.797590             0.922114  \n",
       "max                          0.991073             0.955519  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "submission[target_cols] = Y_test\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "display(submission.head())\n",
    "display(submission.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
