{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D, SpatialDropout1D, Concatenate\n",
    "from googleqa_utilityscript import *\n",
    "from googleqa_map_utilityscript import *\n",
    "import bert_tokenization as tokenization\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = '/kaggle/input/114-googleq-a-train-bert-base-uncased-seq-slicesv2/model.h5'\n",
    "BERT_PATH = '/kaggle/input/tf-hub-bert-base/bert_base_uncased'\n",
    "VOCAB_PATH = BERT_PATH + '/assets/vocab.txt'\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "question_target_cols = ['question_asker_intent_understanding','question_body_critical', 'question_conversational', \n",
    "                        'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                        'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', \n",
    "                        'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                        'question_type_compare', 'question_type_consequence', 'question_type_definition', \n",
    "                        'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                        'question_type_reason_explanation', 'question_type_spelling', 'question_well_written']\n",
    "answer_target_cols = ['answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                      'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', \n",
    "                      'answer_type_reason_explanation', 'answer_well_written']\n",
    "target_cols = question_target_cols + answer_target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['question_title', 'question_body', 'answer']\n",
    "    \n",
    "for feature in text_features:\n",
    "    # Lower\n",
    "    test[feature] = test[feature].apply(lambda x: x.lower())\n",
    "    # Map misspellings\n",
    "    test[feature] = test[feature].apply(lambda x: map_misspellings(x))\n",
    "    # Map contractions\n",
    "    test[feature] = test[feature].apply(lambda x: map_contraction(x))\n",
    "    # Trim text\n",
    "    test[feature] = test[feature].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "N_CLASS = len(target_cols)\n",
    "MAX_SEQUENCE_LENGTH = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(VOCAB_PATH, do_lower_case=True)\n",
    "\n",
    "# Test features\n",
    "X_test = compute_input_arays(test, text_features, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, None, 768)]  0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, None, 768)]  0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 768)          0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 768)          0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, None, 768)]  0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 768)          0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 768)          0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1536)         0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 768)          0           global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 21)           32277       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 9)            6921        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output (Concatenate)            (None, 30)           0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 109,521,439\n",
      "Trainable params: 109,521,438\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_word_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "input_masks = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "segment_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='segment_ids')\n",
    "\n",
    "bert_layer = KerasLayer(BERT_PATH, trainable=True)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_masks, segment_ids])\n",
    "\n",
    "t = GlobalAveragePooling1D()(sequence_output[:,:32])\n",
    "t = Dropout(0.2)(t)\n",
    "\n",
    "q = GlobalAveragePooling1D()(sequence_output[:,32:272])\n",
    "q = Dropout(0.2)(q)\n",
    "\n",
    "question = Concatenate()([t, q])\n",
    "question = Dense(21 , kernel_initializer='glorot_uniform', activation=\"sigmoid\")(question)\n",
    "\n",
    "a = GlobalAveragePooling1D()(sequence_output[:,272:])\n",
    "a = Dropout(0.2)(a)\n",
    "a = Dense(9, kernel_initializer='glorot_uniform', activation=\"sigmoid\")(a)\n",
    "\n",
    "output = Concatenate(name=\"output\")([question, a])\n",
    "\n",
    "model = Model(inputs=[input_word_ids, input_masks, segment_ids], outputs=output)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.950032</td>\n",
       "      <td>0.699860</td>\n",
       "      <td>0.413357</td>\n",
       "      <td>0.373360</td>\n",
       "      <td>0.506507</td>\n",
       "      <td>0.386052</td>\n",
       "      <td>0.656133</td>\n",
       "      <td>0.624760</td>\n",
       "      <td>0.621221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949498</td>\n",
       "      <td>0.956421</td>\n",
       "      <td>0.576656</td>\n",
       "      <td>0.978202</td>\n",
       "      <td>0.973051</td>\n",
       "      <td>0.846995</td>\n",
       "      <td>0.022211</td>\n",
       "      <td>0.050035</td>\n",
       "      <td>0.901865</td>\n",
       "      <td>0.924380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.873603</td>\n",
       "      <td>0.435373</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.713400</td>\n",
       "      <td>0.787217</td>\n",
       "      <td>0.888723</td>\n",
       "      <td>0.546658</td>\n",
       "      <td>0.529200</td>\n",
       "      <td>0.092340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664863</td>\n",
       "      <td>0.972197</td>\n",
       "      <td>0.643773</td>\n",
       "      <td>0.977454</td>\n",
       "      <td>0.980125</td>\n",
       "      <td>0.897128</td>\n",
       "      <td>0.947560</td>\n",
       "      <td>0.151027</td>\n",
       "      <td>0.057080</td>\n",
       "      <td>0.898421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.895755</td>\n",
       "      <td>0.523496</td>\n",
       "      <td>0.059155</td>\n",
       "      <td>0.633642</td>\n",
       "      <td>0.755933</td>\n",
       "      <td>0.848452</td>\n",
       "      <td>0.605806</td>\n",
       "      <td>0.549028</td>\n",
       "      <td>0.192711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857639</td>\n",
       "      <td>0.954895</td>\n",
       "      <td>0.578760</td>\n",
       "      <td>0.970593</td>\n",
       "      <td>0.969508</td>\n",
       "      <td>0.857757</td>\n",
       "      <td>0.082417</td>\n",
       "      <td>0.067726</td>\n",
       "      <td>0.886554</td>\n",
       "      <td>0.925947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.889313</td>\n",
       "      <td>0.380248</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.659805</td>\n",
       "      <td>0.674026</td>\n",
       "      <td>0.877537</td>\n",
       "      <td>0.507265</td>\n",
       "      <td>0.500591</td>\n",
       "      <td>0.062903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745855</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.646577</td>\n",
       "      <td>0.964245</td>\n",
       "      <td>0.980531</td>\n",
       "      <td>0.886036</td>\n",
       "      <td>0.844855</td>\n",
       "      <td>0.186565</td>\n",
       "      <td>0.230002</td>\n",
       "      <td>0.881543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.926595</td>\n",
       "      <td>0.554131</td>\n",
       "      <td>0.046043</td>\n",
       "      <td>0.757462</td>\n",
       "      <td>0.693863</td>\n",
       "      <td>0.830533</td>\n",
       "      <td>0.610183</td>\n",
       "      <td>0.608693</td>\n",
       "      <td>0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710687</td>\n",
       "      <td>0.940687</td>\n",
       "      <td>0.685800</td>\n",
       "      <td>0.964386</td>\n",
       "      <td>0.967561</td>\n",
       "      <td>0.866790</td>\n",
       "      <td>0.194188</td>\n",
       "      <td>0.135696</td>\n",
       "      <td>0.751425</td>\n",
       "      <td>0.900629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.950032                0.699860   \n",
       "1     46                             0.873603                0.435373   \n",
       "2     70                             0.895755                0.523496   \n",
       "3    132                             0.889313                0.380248   \n",
       "4    200                             0.926595                0.554131   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.413357                      0.373360   \n",
       "1                 0.008016                      0.713400   \n",
       "2                 0.059155                      0.633642   \n",
       "3                 0.009511                      0.659805   \n",
       "4                 0.046043                      0.757462   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.506507                               0.386052   \n",
       "1               0.787217                               0.888723   \n",
       "2               0.755933                               0.848452   \n",
       "3               0.674026                               0.877537   \n",
       "4               0.693863                               0.830533   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.656133                       0.624760   \n",
       "1                         0.546658                       0.529200   \n",
       "2                         0.605806                       0.549028   \n",
       "3                         0.507265                       0.500591   \n",
       "4                         0.610183                       0.608693   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.621221  ...               0.949498        0.956421   \n",
       "1               0.092340  ...               0.664863        0.972197   \n",
       "2               0.192711  ...               0.857639        0.954895   \n",
       "3               0.062903  ...               0.745855        0.963504   \n",
       "4               0.147053  ...               0.710687        0.940687   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.576656          0.978202          0.973051   \n",
       "1                     0.643773          0.977454          0.980125   \n",
       "2                     0.578760          0.970593          0.969508   \n",
       "3                     0.646577          0.964245          0.980531   \n",
       "4                     0.685800          0.964386          0.967561   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.846995                  0.022211               0.050035   \n",
       "1             0.897128                  0.947560               0.151027   \n",
       "2             0.857757                  0.082417               0.067726   \n",
       "3             0.886036                  0.844855               0.186565   \n",
       "4             0.866790                  0.194188               0.135696   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.901865             0.924380  \n",
       "1                        0.057080             0.898421  \n",
       "2                        0.886554             0.925947  \n",
       "3                        0.230002             0.881543  \n",
       "4                        0.751425             0.900629  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5029.186975</td>\n",
       "      <td>0.897208</td>\n",
       "      <td>0.552736</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.671470</td>\n",
       "      <td>0.756151</td>\n",
       "      <td>0.795116</td>\n",
       "      <td>0.570353</td>\n",
       "      <td>0.511523</td>\n",
       "      <td>0.167812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810051</td>\n",
       "      <td>0.947660</td>\n",
       "      <td>0.643729</td>\n",
       "      <td>0.966196</td>\n",
       "      <td>0.970076</td>\n",
       "      <td>0.874824</td>\n",
       "      <td>0.561731</td>\n",
       "      <td>0.164965</td>\n",
       "      <td>0.460703</td>\n",
       "      <td>0.899347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2812.670060</td>\n",
       "      <td>0.041026</td>\n",
       "      <td>0.119739</td>\n",
       "      <td>0.093324</td>\n",
       "      <td>0.112663</td>\n",
       "      <td>0.096616</td>\n",
       "      <td>0.143994</td>\n",
       "      <td>0.056827</td>\n",
       "      <td>0.078943</td>\n",
       "      <td>0.142811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084684</td>\n",
       "      <td>0.023580</td>\n",
       "      <td>0.045735</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>0.012632</td>\n",
       "      <td>0.038863</td>\n",
       "      <td>0.329668</td>\n",
       "      <td>0.058074</td>\n",
       "      <td>0.288558</td>\n",
       "      <td>0.023555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.767653</td>\n",
       "      <td>0.320180</td>\n",
       "      <td>0.003890</td>\n",
       "      <td>0.245915</td>\n",
       "      <td>0.250918</td>\n",
       "      <td>0.194213</td>\n",
       "      <td>0.456371</td>\n",
       "      <td>0.384093</td>\n",
       "      <td>0.011043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599401</td>\n",
       "      <td>0.830932</td>\n",
       "      <td>0.494386</td>\n",
       "      <td>0.916165</td>\n",
       "      <td>0.918233</td>\n",
       "      <td>0.696177</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.027334</td>\n",
       "      <td>0.019526</td>\n",
       "      <td>0.815880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2572.000000</td>\n",
       "      <td>0.869128</td>\n",
       "      <td>0.453014</td>\n",
       "      <td>0.011992</td>\n",
       "      <td>0.607107</td>\n",
       "      <td>0.719671</td>\n",
       "      <td>0.755833</td>\n",
       "      <td>0.527280</td>\n",
       "      <td>0.455180</td>\n",
       "      <td>0.062854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741969</td>\n",
       "      <td>0.939283</td>\n",
       "      <td>0.614227</td>\n",
       "      <td>0.961629</td>\n",
       "      <td>0.964425</td>\n",
       "      <td>0.859956</td>\n",
       "      <td>0.241180</td>\n",
       "      <td>0.126111</td>\n",
       "      <td>0.203530</td>\n",
       "      <td>0.883312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5093.000000</td>\n",
       "      <td>0.897839</td>\n",
       "      <td>0.549650</td>\n",
       "      <td>0.019367</td>\n",
       "      <td>0.670056</td>\n",
       "      <td>0.765281</td>\n",
       "      <td>0.845647</td>\n",
       "      <td>0.560170</td>\n",
       "      <td>0.488335</td>\n",
       "      <td>0.113110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814160</td>\n",
       "      <td>0.954062</td>\n",
       "      <td>0.647203</td>\n",
       "      <td>0.967812</td>\n",
       "      <td>0.973612</td>\n",
       "      <td>0.882408</td>\n",
       "      <td>0.669858</td>\n",
       "      <td>0.171628</td>\n",
       "      <td>0.434778</td>\n",
       "      <td>0.900259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7482.000000</td>\n",
       "      <td>0.930247</td>\n",
       "      <td>0.645294</td>\n",
       "      <td>0.052095</td>\n",
       "      <td>0.735328</td>\n",
       "      <td>0.813324</td>\n",
       "      <td>0.887400</td>\n",
       "      <td>0.605863</td>\n",
       "      <td>0.548473</td>\n",
       "      <td>0.235073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886323</td>\n",
       "      <td>0.963086</td>\n",
       "      <td>0.674389</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.979344</td>\n",
       "      <td>0.901987</td>\n",
       "      <td>0.860114</td>\n",
       "      <td>0.206862</td>\n",
       "      <td>0.703854</td>\n",
       "      <td>0.917239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9640.000000</td>\n",
       "      <td>0.973624</td>\n",
       "      <td>0.828714</td>\n",
       "      <td>0.743814</td>\n",
       "      <td>0.958111</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.962701</td>\n",
       "      <td>0.734610</td>\n",
       "      <td>0.749239</td>\n",
       "      <td>0.746979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949498</td>\n",
       "      <td>0.986175</td>\n",
       "      <td>0.778078</td>\n",
       "      <td>0.989226</td>\n",
       "      <td>0.990456</td>\n",
       "      <td>0.955655</td>\n",
       "      <td>0.963488</td>\n",
       "      <td>0.300946</td>\n",
       "      <td>0.981473</td>\n",
       "      <td>0.948430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qa_id  question_asker_intent_understanding  \\\n",
       "count   476.000000                           476.000000   \n",
       "mean   5029.186975                             0.897208   \n",
       "std    2812.670060                             0.041026   \n",
       "min      39.000000                             0.767653   \n",
       "25%    2572.000000                             0.869128   \n",
       "50%    5093.000000                             0.897839   \n",
       "75%    7482.000000                             0.930247   \n",
       "max    9640.000000                             0.973624   \n",
       "\n",
       "       question_body_critical  question_conversational  \\\n",
       "count              476.000000               476.000000   \n",
       "mean                 0.552736                 0.055683   \n",
       "std                  0.119739                 0.093324   \n",
       "min                  0.320180                 0.003890   \n",
       "25%                  0.453014                 0.011992   \n",
       "50%                  0.549650                 0.019367   \n",
       "75%                  0.645294                 0.052095   \n",
       "max                  0.828714                 0.743814   \n",
       "\n",
       "       question_expect_short_answer  question_fact_seeking  \\\n",
       "count                    476.000000             476.000000   \n",
       "mean                       0.671470               0.756151   \n",
       "std                        0.112663               0.096616   \n",
       "min                        0.245915               0.250918   \n",
       "25%                        0.607107               0.719671   \n",
       "50%                        0.670056               0.765281   \n",
       "75%                        0.735328               0.813324   \n",
       "max                        0.958111               0.977558   \n",
       "\n",
       "       question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "count                             476.000000                       476.000000   \n",
       "mean                                0.795116                         0.570353   \n",
       "std                                 0.143994                         0.056827   \n",
       "min                                 0.194213                         0.456371   \n",
       "25%                                 0.755833                         0.527280   \n",
       "50%                                 0.845647                         0.560170   \n",
       "75%                                 0.887400                         0.605863   \n",
       "max                                 0.962701                         0.734610   \n",
       "\n",
       "       question_interestingness_self  question_multi_intent  ...  \\\n",
       "count                     476.000000             476.000000  ...   \n",
       "mean                        0.511523               0.167812  ...   \n",
       "std                         0.078943               0.142811  ...   \n",
       "min                         0.384093               0.011043  ...   \n",
       "25%                         0.455180               0.062854  ...   \n",
       "50%                         0.488335               0.113110  ...   \n",
       "75%                         0.548473               0.235073  ...   \n",
       "max                         0.749239               0.746979  ...   \n",
       "\n",
       "       question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "count             476.000000      476.000000                   476.000000   \n",
       "mean                0.810051        0.947660                     0.643729   \n",
       "std                 0.084684        0.023580                     0.045735   \n",
       "min                 0.599401        0.830932                     0.494386   \n",
       "25%                 0.741969        0.939283                     0.614227   \n",
       "50%                 0.814160        0.954062                     0.647203   \n",
       "75%                 0.886323        0.963086                     0.674389   \n",
       "max                 0.949498        0.986175                     0.778078   \n",
       "\n",
       "       answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "count        476.000000        476.000000           476.000000   \n",
       "mean           0.966196          0.970076             0.874824   \n",
       "std            0.010496          0.012632             0.038863   \n",
       "min            0.916165          0.918233             0.696177   \n",
       "25%            0.961629          0.964425             0.859956   \n",
       "50%            0.967812          0.973612             0.882408   \n",
       "75%            0.973046          0.979344             0.901987   \n",
       "max            0.989226          0.990456             0.955655   \n",
       "\n",
       "       answer_type_instructions  answer_type_procedure  \\\n",
       "count                476.000000             476.000000   \n",
       "mean                   0.561731               0.164965   \n",
       "std                    0.329668               0.058074   \n",
       "min                    0.007466               0.027334   \n",
       "25%                    0.241180               0.126111   \n",
       "50%                    0.669858               0.171628   \n",
       "75%                    0.860114               0.206862   \n",
       "max                    0.963488               0.300946   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                      476.000000           476.000000  \n",
       "mean                         0.460703             0.899347  \n",
       "std                          0.288558             0.023555  \n",
       "min                          0.019526             0.815880  \n",
       "25%                          0.203530             0.883312  \n",
       "50%                          0.434778             0.900259  \n",
       "75%                          0.703854             0.917239  \n",
       "max                          0.981473             0.948430  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "submission[target_cols] = Y_test\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "display(submission.head())\n",
    "display(submission.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
