{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import warnings\n",
    "from joblib import load\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import Model, optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Dropout, Concatenate, BatchNormalization, Activation, Average, Add, Reshape\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Embedding, LSTM, Conv1D, SpatialDropout1D, Bidirectional, Flatten\n",
    "from googleqa_utilityscript import *\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "module_url = '/kaggle/input/universalsentenceencodermodels/universal-sentence-encoder-models/use'\n",
    "encoder_path = '/kaggle/input/pickled-glove840b300d-for-10sec-loading/glove.840B.300d.pkl'\n",
    "model_path = '/kaggle/input/78-googleq-a-train-glove-2lstm-avgv2/model.h5'\n",
    "tokenizer_path = '/kaggle/input/78-googleq-a-train-glove-2lstm-avgv2/tokenizer.joblib'\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n",
    "\n",
    "print('Test samples: %s' % len(test))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "question_target_cols = ['question_asker_intent_understanding','question_body_critical', 'question_conversational', \n",
    "                        'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                        'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', \n",
    "                        'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                        'question_type_compare', 'question_type_consequence', 'question_type_definition', \n",
    "                        'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                        'question_type_reason_explanation', 'question_type_spelling', 'question_well_written']\n",
    "answer_target_cols = ['answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                      'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', \n",
    "                      'answer_type_reason_explanation', 'answer_well_written']\n",
    "target_cols = question_target_cols + answer_target_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['question_title', 'question_body', 'answer']\n",
    "    \n",
    "for feature in text_features:\n",
    "    # Map contractions\n",
    "    test[feature] = test[feature].apply(lambda x: map_contraction(x))\n",
    "    # Trim text\n",
    "    test[feature] = test[feature].apply(lambda x: x.strip())\n",
    "\n",
    "for feature in text_features:\n",
    "    test[feature + '_uncased'] = test[feature]\n",
    "\n",
    "for feature in text_features:\n",
    "    # Lower\n",
    "    test[feature] = test[feature].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "EMBEDDDING_SIZE = 512\n",
    "N_CLASS = len(target_cols)\n",
    "MAX_FEATURES = 20000\n",
    "TITLE_MAX_LEN = 30\n",
    "BODY_MAX_LEN = 200\n",
    "ANSWER_MAX_LEN = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load(tokenizer_path)\n",
    "\n",
    "# Test features\n",
    "# X_test_title = test['question_title']\n",
    "# X_test_body = test['question_body']\n",
    "# X_test_answer = test['answer']\n",
    "X_test_title_seq = test['question_title_uncased']\n",
    "X_test_body_seq = test['question_body_uncased']\n",
    "X_test_answer_seq = test['answer_uncased']\n",
    "\n",
    "# Tokenize the sentences\n",
    "X_test_title_seq = tokenizer.texts_to_sequences(X_test_title_seq)\n",
    "X_test_body_seq = tokenizer.texts_to_sequences(X_test_body_seq)\n",
    "X_test_answer_seq = tokenizer.texts_to_sequences(X_test_answer_seq)\n",
    "\n",
    "# Pad the sentences\n",
    "X_test_title_seq = pad_sequences(X_test_title_seq, maxlen=TITLE_MAX_LEN)\n",
    "X_test_body_seq = pad_sequences(X_test_body_seq, maxlen=BODY_MAX_LEN)\n",
    "X_test_answer_seq = pad_sequences(X_test_answer_seq, maxlen=ANSWER_MAX_LEN)\n",
    "\n",
    "X_test = [X_test_title_seq, X_test_body_seq, X_test_answer_seq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "use_embed = hub.load(module_url)\n",
    "\n",
    "def USEEmbedding(x):\n",
    "    return use_embed(tf.squeeze(tf.cast(x, tf.string)))\n",
    "\n",
    "def encoder_block(input_layer):\n",
    "    encoder = Lambda(USEEmbedding, output_shape=(EMBEDDDING_SIZE,))(input_layer)\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n unknown words (GloVe):  3306\n"
     ]
    }
   ],
   "source": [
    "glove_embedding_matrix, glove_unknown_words = build_matrix(tokenizer.word_index, encoder_path, MAX_FEATURES)\n",
    "print('n unknown words (GloVe): ', len(glove_unknown_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_title_seq (InputLayer)    [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_body_seq (InputLayer)     [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_answer_seq (InputLayer)   [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 300)      17424600    input_title_seq[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 300)     17424600    input_body_seq[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 200, 300)     17424600    input_answer_seq[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 30, 512)      1665024     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 200, 512)     1665024     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 200, 512)     1665024     embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 30, 256)      787456      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 200, 256)     787456      lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 200, 256)     787456      lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 256)          0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 256)          0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 256)          0           lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 768)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 768)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          393728      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 30)           15390       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 60,040,358\n",
      "Trainable params: 7,766,558\n",
      "Non-trainable params: 52,273,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Title sequence\n",
    "input_title_seq = Input(shape=(TITLE_MAX_LEN,), dtype=tf.float32, name='input_title_seq')\n",
    "title = Embedding(*glove_embedding_matrix.shape, weights=[glove_embedding_matrix], trainable=False)(input_title_seq)\n",
    "title = LSTM(512, kernel_initializer='lecun_normal', recurrent_dropout=0.5, return_sequences=True)(title)\n",
    "title = LSTM(256, kernel_initializer='lecun_normal', recurrent_dropout=0.5, return_sequences=True)(title)\n",
    "title_out = GlobalAveragePooling1D()(title)\n",
    "\n",
    "# Body sequence\n",
    "input_body_seq = Input(shape=(BODY_MAX_LEN,), dtype=tf.float32, name='input_body_seq')\n",
    "body = Embedding(*glove_embedding_matrix.shape, weights=[glove_embedding_matrix], trainable=False)(input_body_seq)\n",
    "body = LSTM(512, kernel_initializer='lecun_normal', recurrent_dropout=0.5, return_sequences=True)(body)\n",
    "body = LSTM(256, kernel_initializer='lecun_normal', recurrent_dropout=0.5, return_sequences=True)(body)\n",
    "body_out = GlobalAveragePooling1D()(body)\n",
    "\n",
    "# Answer sequence\n",
    "input_answer_seq = Input(shape=(ANSWER_MAX_LEN,), dtype=tf.float32, name='input_answer_seq')\n",
    "answer = Embedding(*glove_embedding_matrix.shape, weights=[glove_embedding_matrix], trainable=False)(input_answer_seq)\n",
    "answer = LSTM(512, kernel_initializer='lecun_normal', recurrent_dropout=0.5, return_sequences=True)(answer)\n",
    "answer = LSTM(256, kernel_initializer='lecun_normal', recurrent_dropout=0.5, return_sequences=True)(answer)\n",
    "answer_out = GlobalAveragePooling1D()(answer)\n",
    "\n",
    "\n",
    "# Output\n",
    "x = Concatenate()([title_out, body_out, answer_out])\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu', kernel_initializer='lecun_normal')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(N_CLASS, activation='sigmoid', kernel_initializer='lecun_normal', name='output')(x)\n",
    "model = Model(inputs=[input_title_seq, input_body_seq, input_answer_seq], outputs=[output])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.915013</td>\n",
       "      <td>0.593609</td>\n",
       "      <td>0.086590</td>\n",
       "      <td>0.665256</td>\n",
       "      <td>0.761295</td>\n",
       "      <td>0.751605</td>\n",
       "      <td>0.633944</td>\n",
       "      <td>0.573284</td>\n",
       "      <td>0.371557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880683</td>\n",
       "      <td>0.896223</td>\n",
       "      <td>0.594546</td>\n",
       "      <td>0.960029</td>\n",
       "      <td>0.960838</td>\n",
       "      <td>0.796325</td>\n",
       "      <td>0.182454</td>\n",
       "      <td>0.072155</td>\n",
       "      <td>0.572666</td>\n",
       "      <td>0.910298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.886998</td>\n",
       "      <td>0.554867</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.719055</td>\n",
       "      <td>0.764358</td>\n",
       "      <td>0.880835</td>\n",
       "      <td>0.550018</td>\n",
       "      <td>0.462107</td>\n",
       "      <td>0.123737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749212</td>\n",
       "      <td>0.925031</td>\n",
       "      <td>0.628337</td>\n",
       "      <td>0.962960</td>\n",
       "      <td>0.968159</td>\n",
       "      <td>0.840522</td>\n",
       "      <td>0.863268</td>\n",
       "      <td>0.154771</td>\n",
       "      <td>0.126434</td>\n",
       "      <td>0.880270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.907012</td>\n",
       "      <td>0.677478</td>\n",
       "      <td>0.024590</td>\n",
       "      <td>0.745364</td>\n",
       "      <td>0.944681</td>\n",
       "      <td>0.914696</td>\n",
       "      <td>0.602402</td>\n",
       "      <td>0.537459</td>\n",
       "      <td>0.418991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885018</td>\n",
       "      <td>0.899448</td>\n",
       "      <td>0.617597</td>\n",
       "      <td>0.950076</td>\n",
       "      <td>0.957223</td>\n",
       "      <td>0.817313</td>\n",
       "      <td>0.074183</td>\n",
       "      <td>0.061950</td>\n",
       "      <td>0.685571</td>\n",
       "      <td>0.900184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.873127</td>\n",
       "      <td>0.491936</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.804151</td>\n",
       "      <td>0.814499</td>\n",
       "      <td>0.946146</td>\n",
       "      <td>0.541817</td>\n",
       "      <td>0.425467</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741977</td>\n",
       "      <td>0.963939</td>\n",
       "      <td>0.691483</td>\n",
       "      <td>0.980617</td>\n",
       "      <td>0.990351</td>\n",
       "      <td>0.913528</td>\n",
       "      <td>0.754348</td>\n",
       "      <td>0.134878</td>\n",
       "      <td>0.721599</td>\n",
       "      <td>0.920241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.899649</td>\n",
       "      <td>0.503609</td>\n",
       "      <td>0.027867</td>\n",
       "      <td>0.805547</td>\n",
       "      <td>0.805958</td>\n",
       "      <td>0.862124</td>\n",
       "      <td>0.585111</td>\n",
       "      <td>0.513471</td>\n",
       "      <td>0.242008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752472</td>\n",
       "      <td>0.922174</td>\n",
       "      <td>0.656462</td>\n",
       "      <td>0.963941</td>\n",
       "      <td>0.966445</td>\n",
       "      <td>0.846378</td>\n",
       "      <td>0.245598</td>\n",
       "      <td>0.088157</td>\n",
       "      <td>0.584843</td>\n",
       "      <td>0.911222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.915013                0.593609   \n",
       "1     46                             0.886998                0.554867   \n",
       "2     70                             0.907012                0.677478   \n",
       "3    132                             0.873127                0.491936   \n",
       "4    200                             0.899649                0.503609   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.086590                      0.665256   \n",
       "1                 0.006843                      0.719055   \n",
       "2                 0.024590                      0.745364   \n",
       "3                 0.002857                      0.804151   \n",
       "4                 0.027867                      0.805547   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.761295                               0.751605   \n",
       "1               0.764358                               0.880835   \n",
       "2               0.944681                               0.914696   \n",
       "3               0.814499                               0.946146   \n",
       "4               0.805958                               0.862124   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.633944                       0.573284   \n",
       "1                         0.550018                       0.462107   \n",
       "2                         0.602402                       0.537459   \n",
       "3                         0.541817                       0.425467   \n",
       "4                         0.585111                       0.513471   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.371557  ...               0.880683        0.896223   \n",
       "1               0.123737  ...               0.749212        0.925031   \n",
       "2               0.418991  ...               0.885018        0.899448   \n",
       "3               0.140534  ...               0.741977        0.963939   \n",
       "4               0.242008  ...               0.752472        0.922174   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.594546          0.960029          0.960838   \n",
       "1                     0.628337          0.962960          0.968159   \n",
       "2                     0.617597          0.950076          0.957223   \n",
       "3                     0.691483          0.980617          0.990351   \n",
       "4                     0.656462          0.963941          0.966445   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.796325                  0.182454               0.072155   \n",
       "1             0.840522                  0.863268               0.154771   \n",
       "2             0.817313                  0.074183               0.061950   \n",
       "3             0.913528                  0.754348               0.134878   \n",
       "4             0.846378                  0.245598               0.088157   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.572666             0.910298  \n",
       "1                        0.126434             0.880270  \n",
       "2                        0.685571             0.900184  \n",
       "3                        0.721599             0.920241  \n",
       "4                        0.584843             0.911222  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5029.186975</td>\n",
       "      <td>0.880082</td>\n",
       "      <td>0.565640</td>\n",
       "      <td>0.046040</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.772579</td>\n",
       "      <td>0.822321</td>\n",
       "      <td>0.572125</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.229375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774739</td>\n",
       "      <td>0.925437</td>\n",
       "      <td>0.649030</td>\n",
       "      <td>0.959959</td>\n",
       "      <td>0.967547</td>\n",
       "      <td>0.852783</td>\n",
       "      <td>0.547811</td>\n",
       "      <td>0.142185</td>\n",
       "      <td>0.493564</td>\n",
       "      <td>0.898709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2812.670060</td>\n",
       "      <td>0.044536</td>\n",
       "      <td>0.125915</td>\n",
       "      <td>0.080256</td>\n",
       "      <td>0.106314</td>\n",
       "      <td>0.107068</td>\n",
       "      <td>0.145776</td>\n",
       "      <td>0.042381</td>\n",
       "      <td>0.070214</td>\n",
       "      <td>0.114863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088676</td>\n",
       "      <td>0.026616</td>\n",
       "      <td>0.033178</td>\n",
       "      <td>0.015922</td>\n",
       "      <td>0.016143</td>\n",
       "      <td>0.038170</td>\n",
       "      <td>0.310358</td>\n",
       "      <td>0.069758</td>\n",
       "      <td>0.258028</td>\n",
       "      <td>0.024344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.738347</td>\n",
       "      <td>0.351546</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.300145</td>\n",
       "      <td>0.208113</td>\n",
       "      <td>0.126220</td>\n",
       "      <td>0.458608</td>\n",
       "      <td>0.387538</td>\n",
       "      <td>0.027038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.848885</td>\n",
       "      <td>0.575671</td>\n",
       "      <td>0.892453</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.747202</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.006965</td>\n",
       "      <td>0.057667</td>\n",
       "      <td>0.810008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2572.000000</td>\n",
       "      <td>0.851341</td>\n",
       "      <td>0.460020</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.645455</td>\n",
       "      <td>0.733269</td>\n",
       "      <td>0.782991</td>\n",
       "      <td>0.543124</td>\n",
       "      <td>0.436256</td>\n",
       "      <td>0.140192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702667</td>\n",
       "      <td>0.909972</td>\n",
       "      <td>0.624035</td>\n",
       "      <td>0.950982</td>\n",
       "      <td>0.958548</td>\n",
       "      <td>0.825940</td>\n",
       "      <td>0.247999</td>\n",
       "      <td>0.091493</td>\n",
       "      <td>0.267871</td>\n",
       "      <td>0.883058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5093.000000</td>\n",
       "      <td>0.883157</td>\n",
       "      <td>0.546890</td>\n",
       "      <td>0.013182</td>\n",
       "      <td>0.710923</td>\n",
       "      <td>0.779755</td>\n",
       "      <td>0.877838</td>\n",
       "      <td>0.565614</td>\n",
       "      <td>0.467964</td>\n",
       "      <td>0.208173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769046</td>\n",
       "      <td>0.925099</td>\n",
       "      <td>0.646220</td>\n",
       "      <td>0.961938</td>\n",
       "      <td>0.969517</td>\n",
       "      <td>0.852233</td>\n",
       "      <td>0.641285</td>\n",
       "      <td>0.141098</td>\n",
       "      <td>0.464575</td>\n",
       "      <td>0.898051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7482.000000</td>\n",
       "      <td>0.912487</td>\n",
       "      <td>0.670474</td>\n",
       "      <td>0.049429</td>\n",
       "      <td>0.769911</td>\n",
       "      <td>0.833687</td>\n",
       "      <td>0.913717</td>\n",
       "      <td>0.600468</td>\n",
       "      <td>0.525348</td>\n",
       "      <td>0.306769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852355</td>\n",
       "      <td>0.944839</td>\n",
       "      <td>0.671296</td>\n",
       "      <td>0.970488</td>\n",
       "      <td>0.979254</td>\n",
       "      <td>0.880145</td>\n",
       "      <td>0.820124</td>\n",
       "      <td>0.187412</td>\n",
       "      <td>0.702214</td>\n",
       "      <td>0.913975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9640.000000</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>0.918417</td>\n",
       "      <td>0.541884</td>\n",
       "      <td>0.904069</td>\n",
       "      <td>0.996254</td>\n",
       "      <td>0.982072</td>\n",
       "      <td>0.717620</td>\n",
       "      <td>0.718218</td>\n",
       "      <td>0.588117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975305</td>\n",
       "      <td>0.987882</td>\n",
       "      <td>0.749267</td>\n",
       "      <td>0.994463</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>0.954692</td>\n",
       "      <td>0.973299</td>\n",
       "      <td>0.353410</td>\n",
       "      <td>0.991496</td>\n",
       "      <td>0.964925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qa_id  question_asker_intent_understanding  \\\n",
       "count   476.000000                           476.000000   \n",
       "mean   5029.186975                             0.880082   \n",
       "std    2812.670060                             0.044536   \n",
       "min      39.000000                             0.738347   \n",
       "25%    2572.000000                             0.851341   \n",
       "50%    5093.000000                             0.883157   \n",
       "75%    7482.000000                             0.912487   \n",
       "max    9640.000000                             0.978410   \n",
       "\n",
       "       question_body_critical  question_conversational  \\\n",
       "count              476.000000               476.000000   \n",
       "mean                 0.565640                 0.046040   \n",
       "std                  0.125915                 0.080256   \n",
       "min                  0.351546                 0.000135   \n",
       "25%                  0.460020                 0.005412   \n",
       "50%                  0.546890                 0.013182   \n",
       "75%                  0.670474                 0.049429   \n",
       "max                  0.918417                 0.541884   \n",
       "\n",
       "       question_expect_short_answer  question_fact_seeking  \\\n",
       "count                    476.000000             476.000000   \n",
       "mean                       0.696774               0.772579   \n",
       "std                        0.106314               0.107068   \n",
       "min                        0.300145               0.208113   \n",
       "25%                        0.645455               0.733269   \n",
       "50%                        0.710923               0.779755   \n",
       "75%                        0.769911               0.833687   \n",
       "max                        0.904069               0.996254   \n",
       "\n",
       "       question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "count                             476.000000                       476.000000   \n",
       "mean                                0.822321                         0.572125   \n",
       "std                                 0.145776                         0.042381   \n",
       "min                                 0.126220                         0.458608   \n",
       "25%                                 0.782991                         0.543124   \n",
       "50%                                 0.877838                         0.565614   \n",
       "75%                                 0.913717                         0.600468   \n",
       "max                                 0.982072                         0.717620   \n",
       "\n",
       "       question_interestingness_self  question_multi_intent  ...  \\\n",
       "count                     476.000000             476.000000  ...   \n",
       "mean                        0.489072               0.229375  ...   \n",
       "std                         0.070214               0.114863  ...   \n",
       "min                         0.387538               0.027038  ...   \n",
       "25%                         0.436256               0.140192  ...   \n",
       "50%                         0.467964               0.208173  ...   \n",
       "75%                         0.525348               0.306769  ...   \n",
       "max                         0.718218               0.588117  ...   \n",
       "\n",
       "       question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "count             476.000000      476.000000                   476.000000   \n",
       "mean                0.774739        0.925437                     0.649030   \n",
       "std                 0.088676        0.026616                     0.033178   \n",
       "min                 0.598462        0.848885                     0.575671   \n",
       "25%                 0.702667        0.909972                     0.624035   \n",
       "50%                 0.769046        0.925099                     0.646220   \n",
       "75%                 0.852355        0.944839                     0.671296   \n",
       "max                 0.975305        0.987882                     0.749267   \n",
       "\n",
       "       answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "count        476.000000        476.000000           476.000000   \n",
       "mean           0.959959          0.967547             0.852783   \n",
       "std            0.015922          0.016143             0.038170   \n",
       "min            0.892453          0.912698             0.747202   \n",
       "25%            0.950982          0.958548             0.825940   \n",
       "50%            0.961938          0.969517             0.852233   \n",
       "75%            0.970488          0.979254             0.880145   \n",
       "max            0.994463          0.997522             0.954692   \n",
       "\n",
       "       answer_type_instructions  answer_type_procedure  \\\n",
       "count                476.000000             476.000000   \n",
       "mean                   0.547811               0.142185   \n",
       "std                    0.310358               0.069758   \n",
       "min                    0.002302               0.006965   \n",
       "25%                    0.247999               0.091493   \n",
       "50%                    0.641285               0.141098   \n",
       "75%                    0.820124               0.187412   \n",
       "max                    0.973299               0.353410   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                      476.000000           476.000000  \n",
       "mean                         0.493564             0.898709  \n",
       "std                          0.258028             0.024344  \n",
       "min                          0.057667             0.810008  \n",
       "25%                          0.267871             0.883058  \n",
       "50%                          0.464575             0.898051  \n",
       "75%                          0.702214             0.913975  \n",
       "max                          0.991496             0.964925  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "submission[target_cols] = Y_test\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "display(submission.head())\n",
    "display(submission.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
